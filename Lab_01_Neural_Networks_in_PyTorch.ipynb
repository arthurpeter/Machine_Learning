{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthurpeter/Machine_Learning/blob/main/Lab_01_Neural_Networks_in_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1 - Introduction to PyTorch"
      ],
      "metadata": {
        "id": "6d-6DC2Dof61"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additional Resources for learning about PyTorch and working with neural networks:\n",
        "- [PyTorch official tutorials](https://pytorch.org/tutorials/)\n",
        "- [Deep Learning with PyTorch: A 60 Minute Blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
        "- [Neural Networks: Zero to Hero by Andrej Karpathy](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ)\n",
        "- [Learn PyTorch for deep learning in a day by Daniel Bourke](https://www.youtube.com/watch?v=Z_ikDlimN6A)"
      ],
      "metadata": {
        "id": "mjBzyO7wweAi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this lab is to offer a short introduction to the PyTorch library and to help you construct and train a neural network.\n",
        "\n",
        "You should be familiar with numpy basics. Here is a short [tutorial](https://numpy.org/devdocs/user/quickstart.html) on numpy operations."
      ],
      "metadata": {
        "id": "vAdMzV81omQm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We import the necessary libraries."
      ],
      "metadata": {
        "id": "pCmah8dG6yUQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WuWk21oSoVIJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensors\n",
        "\n",
        "PyTorch Tensors are similar to Numpy arrays, but have support for GPU acceleration and gradient computation.\n",
        "\n",
        "A tensor is a generalization of data structures that you are familiar with.\n",
        "\n",
        "For example a vector is a 1D tensor, and a matrix is a 2D tensor. Most operations with torch tensors are similar to those of Numpy arrays."
      ],
      "metadata": {
        "id": "fukChWP6p83z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Initialization"
      ],
      "metadata": {
        "id": "oFodaKIXrZQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating an empty tensor"
      ],
      "metadata": {
        "id": "wQEYDBZaE7xe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([])\n",
        "print(a)"
      ],
      "metadata": {
        "id": "EiLd2AHsrc5Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b14b5ee-0ceb-4477-a599-e2a0f80ba35b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a tensor with specific size"
      ],
      "metadata": {
        "id": "v4wtOdUXFAF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.empty((3, 4))  # Creates a tensor of size 3x4 filled with uninitialized values\n",
        "print(b)"
      ],
      "metadata": {
        "id": "XfWTqKx0r5Iv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "862a8bb8-0b5e-4642-a831-c4288b1805f4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 7.7052e+31, 7.2148e+22],\n",
            "        [1.5766e-19, 1.0256e-08, 6.4456e-10, 3.0957e+12]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a tensor from a list"
      ],
      "metadata": {
        "id": "D6YLaO3SFGYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c = torch.tensor([[1, 2], [3, 4]])\n",
        "print(c)"
      ],
      "metadata": {
        "id": "X4E9P0f3r-at",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a211ee0c-65a4-414f-9fee-28aa8e51b113"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting a NumPy array to a tensor"
      ],
      "metadata": {
        "id": "Xt3PDMosFKNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array_data = np.array([1, 2, 3, 4, 5])\n",
        "d = torch.from_numpy(array_data)\n",
        "print(d)"
      ],
      "metadata": {
        "id": "ZF7NCseAsCG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b1d2027-7a07-41e7-c041-ae03e5e2eb62"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a tensor with random values between 0 and 1 with specific shape"
      ],
      "metadata": {
        "id": "9qDXl4DzFNzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "e = torch.rand(2, 2) * 100\n",
        "print(e)"
      ],
      "metadata": {
        "id": "Il9OwnevsXMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fbde967-3757-4833-fbe2-a418f9f55ae1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[37.4397, 83.4720],\n",
            "        [22.5773, 60.8909]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Shape of tensor"
      ],
      "metadata": {
        "id": "w_5DNlL4svEu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dimensions of a tensor can be checked with `.shape` attribute or `.size()` function."
      ],
      "metadata": {
        "id": "uIDrC8xYFVEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(5,3,2)\n",
        "\n",
        "shape = x.shape\n",
        "print(\"Shape:\", x.shape)\n",
        "\n",
        "size = x.size()\n",
        "print(\"Size:\", size)\n",
        "\n",
        "dim1, dim2, dim3 = x.size()\n",
        "print(\"Size:\", dim1, dim2, dim3)\n",
        "\n",
        "print(x)"
      ],
      "metadata": {
        "id": "FRVu_8GKstA9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34392225-9332-4640-945f-e8ad588461cb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: torch.Size([5, 3, 2])\n",
            "Size: torch.Size([5, 3, 2])\n",
            "Size: 5 3 2\n",
            "tensor([[[0.9715, 0.7015],\n",
            "         [0.9933, 0.3218],\n",
            "         [0.9986, 0.7039]],\n",
            "\n",
            "        [[0.0526, 0.8329],\n",
            "         [0.6842, 0.3299],\n",
            "         [0.9910, 0.7248]],\n",
            "\n",
            "        [[0.0282, 0.8774],\n",
            "         [0.4074, 0.9494],\n",
            "         [0.0338, 0.8680]],\n",
            "\n",
            "        [[0.3678, 0.4801],\n",
            "         [0.2708, 0.8870],\n",
            "         [0.0527, 0.7854]],\n",
            "\n",
            "        [[0.2472, 0.6880],\n",
            "         [0.2294, 0.4490],\n",
            "         [0.2136, 0.8597]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Operations with tensors"
      ],
      "metadata": {
        "id": "kYiujLGYtM0l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors support most mathematical operations, similar to numpy arrays"
      ],
      "metadata": {
        "id": "6-02igpQFfyE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Addition"
      ],
      "metadata": {
        "id": "vyaVRCTnFte3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[1,2], [3,4], [5,6]])\n",
        "b = torch.rand(3,2)\n",
        "\n",
        "c = a + b\n",
        "\n",
        "print(\"a\", a)\n",
        "print(\"b\", b)\n",
        "print(\"c\", c)"
      ],
      "metadata": {
        "id": "98dWnk_JtPve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9ba547a-4fdd-4460-fa13-ae9cf9423da7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "b tensor([[0.8106, 0.8891],\n",
            "        [0.4191, 0.5668],\n",
            "        [0.4917, 0.4611]])\n",
            "c tensor([[1.8106, 2.8891],\n",
            "        [3.4191, 4.5668],\n",
            "        [5.4917, 6.4611]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elementwise Multiplication"
      ],
      "metadata": {
        "id": "mbmJvO6_FwCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = a * b\n",
        "print(d)"
      ],
      "metadata": {
        "id": "18JkwMVztzUn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "883f2016-ac47-4ba1-a1d2-b250a526427b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8106, 1.7782],\n",
            "        [1.2572, 2.2673],\n",
            "        [2.4587, 2.7667]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changing shape of tensor"
      ],
      "metadata": {
        "id": "Upa4riBXF0Km"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Always check the shape of the tensors when performing complex operations. It's very useful for debugging."
      ],
      "metadata": {
        "id": "NIcduRE68Q7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "e = torch.arange(6)\n",
        "print(\"Before:\")\n",
        "print(\"Shape\", e.shape)\n",
        "print(\"Tensor\", e)\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Changing shape operation\n",
        "e = e.view(2,3)\n",
        "\n",
        "print(\"After:\")\n",
        "print(\"Shape\", e.shape)\n",
        "print(\"Tensor\", e)"
      ],
      "metadata": {
        "id": "KBLQJeAkt5PO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d95b4a28-3bc4-44ff-8803-db7deb3b1e54"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before:\n",
            "Shape torch.Size([6])\n",
            "Tensor tensor([0, 1, 2, 3, 4, 5])\n",
            "------------------------------\n",
            "After:\n",
            "Shape torch.Size([2, 3])\n",
            "Tensor tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matrix Multiplication"
      ],
      "metadata": {
        "id": "1f5AI37ZF4iS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(a.shape)\n",
        "print(e.shape)\n",
        "\n",
        "# 3x2 matrix multiplied with 2x3 matrix should result in a 3x3 matrix\n",
        "\n",
        "f = torch.matmul(a,e)\n",
        "\n",
        "print(f.shape)\n",
        "print(f)"
      ],
      "metadata": {
        "id": "1UvJwP72uRoa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d2fa399-e920-40fe-dc19-68b3595ccd91"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 2])\n",
            "torch.Size([2, 3])\n",
            "torch.Size([3, 3])\n",
            "tensor([[ 6,  9, 12],\n",
            "        [12, 19, 26],\n",
            "        [18, 29, 40]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indexing"
      ],
      "metadata": {
        "id": "4mJKjFzt9dgw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we create a 2x2x4 tensor to see how we can access different parts of the tensor"
      ],
      "metadata": {
        "id": "GOBrQfvy9flA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(16)\n",
        "x = x.view(2, 2, 4)\n",
        "print(x)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "id": "621D1c36uwrl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a101062c-6b21-4420-c780-b5203ac1180b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0,  1,  2,  3],\n",
            "         [ 4,  5,  6,  7]],\n",
            "\n",
            "        [[ 8,  9, 10, 11],\n",
            "         [12, 13, 14, 15]]])\n",
            "torch.Size([2, 2, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What does shape (2, 2, 4) mean exactly?\n",
        "\n",
        "We have:\n",
        "- 2 elements along the first dimension - 2 2D matrices;\n",
        "- 2 elements along the second dimension - 2 rows for each matrix;\n",
        "- 4 elements along the third dimension - 4 columns.\n"
      ],
      "metadata": {
        "id": "HJTcivu9_S3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting the first element from the first dimension -> the first 2D matrix\n",
        "print(x[0])\n",
        "\n",
        "# ':' operator means select all elements from this dimension\n",
        "\n",
        "# Selecting all elements that have index 0 in second dimension -> first row of each 2D matrix\n",
        "print(x[:, 0])\n",
        "\n",
        "# Selecting all elements that have index 0 in third dimension -> all elements from first column\n",
        "print(x[:,:,0])\n",
        "\n",
        "# Selecting all elements that have index between 1 and 3 (excluding 3) in third dimension -> 2nd and 3rd column\n",
        "print(x[:,:,1:3])"
      ],
      "metadata": {
        "id": "QPcxb6hHvALl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0abc9985-a551-4afc-9f8f-d475176743a8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2, 3],\n",
            "        [4, 5, 6, 7]])\n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 8,  9, 10, 11]])\n",
            "tensor([[ 0,  4],\n",
            "        [ 8, 12]])\n",
            "tensor([[[ 1,  2],\n",
            "         [ 5,  6]],\n",
            "\n",
            "        [[ 9, 10],\n",
            "         [13, 14]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Play with the indexing operations to get a more intuitive understanding of what they do.\n",
        "\n",
        "For the following tensor try to obtain this result with indexing:\n",
        "\n",
        "```\n",
        "tensor([[[ 6,  7],\n",
        "         [10, 11]],\n",
        "\n",
        "        [[22, 23],\n",
        "         [26, 27]]])\n",
        "```"
      ],
      "metadata": {
        "id": "JV3aPrnuBJQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(64).view(4, 4, 4)\n",
        "print(x)\n",
        "\n",
        "# Use indexing the obtain the desired tensor"
      ],
      "metadata": {
        "id": "bdO6afoMBQeZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd565f0b-e3af-4e1e-89f5-c4143684f9a4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0,  1,  2,  3],\n",
            "         [ 4,  5,  6,  7],\n",
            "         [ 8,  9, 10, 11],\n",
            "         [12, 13, 14, 15]],\n",
            "\n",
            "        [[16, 17, 18, 19],\n",
            "         [20, 21, 22, 23],\n",
            "         [24, 25, 26, 27],\n",
            "         [28, 29, 30, 31]],\n",
            "\n",
            "        [[32, 33, 34, 35],\n",
            "         [36, 37, 38, 39],\n",
            "         [40, 41, 42, 43],\n",
            "         [44, 45, 46, 47]],\n",
            "\n",
            "        [[48, 49, 50, 51],\n",
            "         [52, 53, 54, 55],\n",
            "         [56, 57, 58, 59],\n",
            "         [60, 61, 62, 63]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Computation Graph"
      ],
      "metadata": {
        "id": "dmelWkWBv1c5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient tracking refers to the ability to automatically compute gradients of a function with respect to its inputs or parameters."
      ],
      "metadata": {
        "id": "JAa2AbTIxHFh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, tensors do not keep track of gradients. This can be checked with the `requires_grad` attribute."
      ],
      "metadata": {
        "id": "10HcIM1PxUEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([2.0, 3.0])\n",
        "x.requires_grad"
      ],
      "metadata": {
        "id": "i_KOCJqHv4Qe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cf639d3-78f5-4bc6-b304-a1307e6cc363"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can change this by setting `requires_grad` to `True`"
      ],
      "metadata": {
        "id": "xBtzmFp0xik4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting requires_grad to True\n",
        "x.requires_grad_(True)\n",
        "print(x.requires_grad)\n",
        "\n",
        "# Initializing tensor with requires_grad True\n",
        "y = torch.tensor([3.0, 4.0], requires_grad=True)\n",
        "print(y.requires_grad)"
      ],
      "metadata": {
        "id": "QAn1M1cOxqKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f635c610-809f-41d6-a962-66766ab15e1d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the `grad_fn` attribute. It saves the last function that was performed on that tensor so it can compute its gradient (derivative)."
      ],
      "metadata": {
        "id": "cVtM5SIsyzms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = x + y\n",
        "print(z)\n",
        "\n",
        "z = x * y\n",
        "print(z)\n",
        "\n",
        "z = x ** 2\n",
        "print(z)\n",
        "\n",
        "z = x.mean()\n",
        "print(z)"
      ],
      "metadata": {
        "id": "rUg5r_VoydgK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac910788-337a-4300-d3de-a109905545d4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5., 7.], grad_fn=<AddBackward0>)\n",
            "tensor([ 6., 12.], grad_fn=<MulBackward0>)\n",
            "tensor([4., 9.], grad_fn=<PowBackward0>)\n",
            "tensor(2.5000, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can compute gradients using the `backward()` function. We can check the gradients with the `.grad` attribute."
      ],
      "metadata": {
        "id": "z8Z-RjmAzIv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([2.0, 3.0], requires_grad=True)\n",
        "print(x)\n",
        "\n",
        "y = x + 2\n",
        "print(y)\n",
        "\n",
        "z = y * y * 3\n",
        "z = z.mean()\n",
        "print(z)\n",
        "\n",
        "z.backward() # dz/dx\n",
        "print(\"Gradients of z with respect to x: \", x.grad)"
      ],
      "metadata": {
        "id": "eaVtALpAzFWM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51380b4e-2736-4313-c39f-1deaaf507aba"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 3.], requires_grad=True)\n",
            "tensor([4., 5.], grad_fn=<AddBackward0>)\n",
            "tensor(61.5000, grad_fn=<MeanBackward0>)\n",
            "Gradients of z with respect to x:  tensor([12., 15.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GPU"
      ],
      "metadata": {
        "id": "dqF49xpJ0Gji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this part you need to select Runtime -> Change Runtime type -> Hardware accelerator: GPU and press save. You will need to rerun all the cells."
      ],
      "metadata": {
        "id": "TQrqrDIP0IuA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep learning involves many operations that can be parallelized when working with tensors. Because of this, executing the computation on GPU leads to significantly faster processing."
      ],
      "metadata": {
        "id": "pAYo2TZf_W_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can check that GPU acceleration is available with the following command:"
      ],
      "metadata": {
        "id": "5Vd_DPl20zye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "9AgRT70s0371",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f457d45-f6bc-4ede-c30f-246a70304ad0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can specify the device on which all operations are done with the following command:"
      ],
      "metadata": {
        "id": "p08-re0F1M8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If GPU (cuda) is available then we use it, otherwise use CPU (not recommended)\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "9ZcoV4kr1WFg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "859f2c63-8cd3-47ff-8140-a488b65e08ef"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pushing a tensor on the GPU device is simply done with the `.to(...)` or `.cuda()` functions.\n",
        "\n",
        "All the operations performed with these tensors will be computed on the GPU."
      ],
      "metadata": {
        "id": "7Z0srxh01ctr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([2.0, 3.0])\n",
        "x = x.to(device)\n",
        "print(x)\n",
        "\n",
        "y = torch.tensor([5.0, 1.0]).to(device)\n",
        "print(y)\n",
        "\n",
        "z = x + y\n",
        "print(z)"
      ],
      "metadata": {
        "id": "3UkQcqB210tT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8414254-4aac-4dde-bfc1-f030d9cef912"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 3.], device='cuda:0')\n",
            "tensor([5., 1.], device='cuda:0')\n",
            "tensor([7., 4.], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2 - Training Neural Networks"
      ],
      "metadata": {
        "id": "ixUgxdA03Z0D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Gradient Descent"
      ],
      "metadata": {
        "id": "AmLYgM667h3H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient descent is an optimization algorithm used to iteratively adjust model parameters based on the computed gradients, moving in the direction of steepest descent to find the optimal values that minimize the loss function.\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/faq/gradient-optimization/ball.png\" width=400px>"
      ],
      "metadata": {
        "id": "FDw0Wq2G8E1X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient descent can be described by the following formula:\n",
        "\n",
        "<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20200611183120/1406-7.png\">\n",
        "\n",
        "where $\\theta$ are the weights (trainable parameters) of the model, $\\alpha$ is the learning rate and $J(\\theta)$ is the cost function (loss).\n",
        "\n",
        "The weights are updated in the opposite direction of the derivative (gradient) of the cost function. This basically slightly **modifies the parameters so that the loss decreases.**\n",
        "\n",
        "Remember that PyTorch can automatically track the gradients for us, which means we do not have to compute derivatives manually."
      ],
      "metadata": {
        "id": "Msv4hWK1HtLJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The steps of training a neural network are the following:\n",
        "\n",
        "1. Initialize parameters.\n",
        "2. Compute loss.\n",
        "3. Calculate gradients of loss with respect to the parameters.\n",
        "4. Update parameters by moving in the opposite direction of the gradients.\n",
        "5. Repeat steps 2-4 for multiple epochs.\n",
        "6. Stop when a stopping condition is met (reaching a desired loss or number of epochs).\n",
        "\n"
      ],
      "metadata": {
        "id": "6nZm1REx9Ojk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training a Linear Model"
      ],
      "metadata": {
        "id": "YQ2QAXZUIUO1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will train a very simple linear model to learn the simple function $f(x) = 2*x$ using gradient descent in order to get familiar with the training pipeline.\n",
        "\n",
        "The model will have a single parameter $w \\in R$ and the output of the model will be $pred(x) = w * x$.\n",
        "\n",
        "The model should learn that $w = 2$ if we show it enough examples."
      ],
      "metadata": {
        "id": "Y57hYixT-zIn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create a few examples that the model will see. $x$ is the input and $y$ is the ground truth."
      ],
      "metadata": {
        "id": "36uQusRGI7yU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy dataset\n",
        "x = torch.tensor([1,2,3,4,5], dtype=torch.float32)\n",
        "y = torch.tensor([2,4,6,8,10], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "7-H7GxCeJFWs"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define the **hyperparameters** of training the model. Hyperparameters are chosen by the developer and can be changed to obtain better results."
      ],
      "metadata": {
        "id": "q7Tgjd2RJII1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "learning_rate = 0.00004565\n",
        "epochs = 50000"
      ],
      "metadata": {
        "id": "bWx5qSLCJS5b"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We initialize the weights of the model ($w=0$) and define the forward function (how the model obtains the output based on the input)."
      ],
      "metadata": {
        "id": "I00SV5-jJWLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Initialize parameters\n",
        "weights = torch.tensor(0.0, requires_grad=True)\n",
        "\n",
        "# Define forward function for linear model - how the input is processed to obtain the prediction\n",
        "def forward(x):\n",
        "  return weights * x"
      ],
      "metadata": {
        "id": "XBRw1i1qJs6A"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define the loss function $J$. This should tell us how close the model's predictions are to the ground truth.\n",
        "\n",
        "We choose mean absolute error as it is intuitive, but there are other loss functions. Most of them are already available in pytorch and we don't need to manually define them. You can check them [here](https://pytorch.org/docs/stable/nn.html#loss-functions)."
      ],
      "metadata": {
        "id": "wmAuJnuyJxYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the custom loss (mean absolute error)\n",
        "def custom_loss(pred, ground_truth):\n",
        "  return torch.abs(pred - ground_truth).mean()"
      ],
      "metadata": {
        "id": "BdHnupniKXwq"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to see if the model will be able to predict the correct answer even for unseen samples. For example, $6$ is not in the samples in $x$. Right now, as the model has not been trained, its prediction is bad."
      ],
      "metadata": {
        "id": "slxVRv3RKvTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  print(f\"Prediction before training: f(6) = {forward(6)}\")"
      ],
      "metadata": {
        "id": "AsPMP-x_LIIQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd9b008b-4f76-45a5-e079-325402547c9d"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(6) = 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We perform the training loop:\n",
        "* we obtain the model's prediction\n",
        "* we see how good the predictions are based on the loss\n",
        "* we update the model's weights in the direction that minimizes the loss."
      ],
      "metadata": {
        "id": "Ix3QustTLJlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "\n",
        "  # Obtain prediction\n",
        "  pred = forward(x)\n",
        "\n",
        "  # 2. Compute loss\n",
        "  loss = custom_loss(pred, y)\n",
        "\n",
        "  # 3. Compute gradients\n",
        "  loss.backward()\n",
        "\n",
        "  # Gradient of loss with respect to weights\n",
        "  dw = weights.grad\n",
        "\n",
        "  # 4. Update parameters\n",
        "  # torch.no_grad tells it to not save gradients so it does not mess with gradient computation - this will be removed later when working with torch optimizers, so don't worry about it\n",
        "  with torch.no_grad():\n",
        "    weights -= (learning_rate * dw)\n",
        "\n",
        "  # Set gradient to 0 for next computation - they are not reset by default and will add up if you don't set them to 0\n",
        "  weights.grad.zero_()\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"Epoch: {epoch}, weights = {weights}, loss = {loss}\")\n",
        "\n",
        "print(f\"Prediction after training: f(6) = {forward(6)}\")\n"
      ],
      "metadata": {
        "id": "GwCRoRqD-ZxY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b06e424-de89-44f8-b4b3-b57b22c24faa"
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: 10, weights = 0.0015064501203596592, loss = 5.995891571044922\n",
            "Epoch: 20, weights = 0.002875950653105974, loss = 5.991783142089844\n",
            "Epoch: 30, weights = 0.004245451185852289, loss = 5.987674713134766\n",
            "Epoch: 40, weights = 0.005614951718598604, loss = 5.983565807342529\n",
            "Epoch: 50, weights = 0.006984452251344919, loss = 5.979457378387451\n",
            "Epoch: 60, weights = 0.008353952318429947, loss = 5.975348949432373\n",
            "Epoch: 70, weights = 0.009723452851176262, loss = 5.971240520477295\n",
            "Epoch: 80, weights = 0.011092953383922577, loss = 5.967131614685059\n",
            "Epoch: 90, weights = 0.012462453916668892, loss = 5.9630231857299805\n",
            "Epoch: 100, weights = 0.013831954449415207, loss = 5.958914756774902\n",
            "Epoch: 110, weights = 0.015201454982161522, loss = 5.954806327819824\n",
            "Epoch: 120, weights = 0.01657094992697239, loss = 5.950697898864746\n",
            "Epoch: 130, weights = 0.017940441146492958, loss = 5.946589469909668\n",
            "Epoch: 140, weights = 0.019309932366013527, loss = 5.94248104095459\n",
            "Epoch: 150, weights = 0.020679423585534096, loss = 5.938372611999512\n",
            "Epoch: 160, weights = 0.022048914805054665, loss = 5.934264183044434\n",
            "Epoch: 170, weights = 0.023418406024575233, loss = 5.9301557540893555\n",
            "Epoch: 180, weights = 0.024787897244095802, loss = 5.926047325134277\n",
            "Epoch: 190, weights = 0.02615738846361637, loss = 5.921938896179199\n",
            "Epoch: 200, weights = 0.02752687968313694, loss = 5.917830467224121\n",
            "Epoch: 210, weights = 0.02889637090265751, loss = 5.913722038269043\n",
            "Epoch: 220, weights = 0.030265862122178078, loss = 5.909613609313965\n",
            "Epoch: 230, weights = 0.031635355204343796, loss = 5.905505180358887\n",
            "Epoch: 240, weights = 0.033004846423864365, loss = 5.901396751403809\n",
            "Epoch: 250, weights = 0.034374337643384933, loss = 5.897287845611572\n",
            "Epoch: 260, weights = 0.0357438288629055, loss = 5.893179416656494\n",
            "Epoch: 270, weights = 0.03711332008242607, loss = 5.889070987701416\n",
            "Epoch: 280, weights = 0.03848281130194664, loss = 5.884962558746338\n",
            "Epoch: 290, weights = 0.03985230252146721, loss = 5.88085412979126\n",
            "Epoch: 300, weights = 0.04122179374098778, loss = 5.876745223999023\n",
            "Epoch: 310, weights = 0.04259128496050835, loss = 5.872636795043945\n",
            "Epoch: 320, weights = 0.043960776180028915, loss = 5.868528366088867\n",
            "Epoch: 330, weights = 0.045330267399549484, loss = 5.864419937133789\n",
            "Epoch: 340, weights = 0.04669975861907005, loss = 5.860311508178711\n",
            "Epoch: 350, weights = 0.04806924983859062, loss = 5.856203079223633\n",
            "Epoch: 360, weights = 0.04943874105811119, loss = 5.852094650268555\n",
            "Epoch: 370, weights = 0.05080823227763176, loss = 5.847985744476318\n",
            "Epoch: 380, weights = 0.05217772349715233, loss = 5.84387731552124\n",
            "Epoch: 390, weights = 0.0535472147166729, loss = 5.839768886566162\n",
            "Epoch: 400, weights = 0.054916705936193466, loss = 5.835660457611084\n",
            "Epoch: 410, weights = 0.056286197155714035, loss = 5.831552028656006\n",
            "Epoch: 420, weights = 0.057655688375234604, loss = 5.827443599700928\n",
            "Epoch: 430, weights = 0.05902517959475517, loss = 5.82333517074585\n",
            "Epoch: 440, weights = 0.06039467081427574, loss = 5.8192267417907715\n",
            "Epoch: 450, weights = 0.06176416203379631, loss = 5.815117835998535\n",
            "Epoch: 460, weights = 0.06313365697860718, loss = 5.811009407043457\n",
            "Epoch: 470, weights = 0.06450314819812775, loss = 5.806900978088379\n",
            "Epoch: 480, weights = 0.06587263941764832, loss = 5.802792549133301\n",
            "Epoch: 490, weights = 0.06724213063716888, loss = 5.798684120178223\n",
            "Epoch: 500, weights = 0.06861162185668945, loss = 5.7945756912231445\n",
            "Epoch: 510, weights = 0.06998111307621002, loss = 5.790467262268066\n",
            "Epoch: 520, weights = 0.07135060429573059, loss = 5.786358833312988\n",
            "Epoch: 530, weights = 0.07272009551525116, loss = 5.78225040435791\n",
            "Epoch: 540, weights = 0.07408958673477173, loss = 5.778141975402832\n",
            "Epoch: 550, weights = 0.0754590779542923, loss = 5.774033546447754\n",
            "Epoch: 560, weights = 0.07682856917381287, loss = 5.769925117492676\n",
            "Epoch: 570, weights = 0.07819806039333344, loss = 5.765816688537598\n",
            "Epoch: 580, weights = 0.079567551612854, loss = 5.7617082595825195\n",
            "Epoch: 590, weights = 0.08093704283237457, loss = 5.757599830627441\n",
            "Epoch: 600, weights = 0.08230653405189514, loss = 5.753491401672363\n",
            "Epoch: 610, weights = 0.08367602527141571, loss = 5.749382972717285\n",
            "Epoch: 620, weights = 0.08504551649093628, loss = 5.745274543762207\n",
            "Epoch: 630, weights = 0.08641500771045685, loss = 5.741166114807129\n",
            "Epoch: 640, weights = 0.08778449892997742, loss = 5.737057685852051\n",
            "Epoch: 650, weights = 0.08915399014949799, loss = 5.732949256896973\n",
            "Epoch: 660, weights = 0.09052348136901855, loss = 5.7288408279418945\n",
            "Epoch: 670, weights = 0.09189297258853912, loss = 5.724732398986816\n",
            "Epoch: 680, weights = 0.09326246380805969, loss = 5.720623970031738\n",
            "Epoch: 690, weights = 0.09463195502758026, loss = 5.716514587402344\n",
            "Epoch: 700, weights = 0.09600144624710083, loss = 5.712406158447266\n",
            "Epoch: 710, weights = 0.0973709374666214, loss = 5.7082977294921875\n",
            "Epoch: 720, weights = 0.09874042868614197, loss = 5.704189300537109\n",
            "Epoch: 730, weights = 0.10010991990566254, loss = 5.700080871582031\n",
            "Epoch: 740, weights = 0.1014794111251831, loss = 5.695972442626953\n",
            "Epoch: 750, weights = 0.10284890234470367, loss = 5.691864013671875\n",
            "Epoch: 760, weights = 0.10421839356422424, loss = 5.687755584716797\n",
            "Epoch: 770, weights = 0.10558788478374481, loss = 5.6836466789245605\n",
            "Epoch: 780, weights = 0.10695737600326538, loss = 5.679538249969482\n",
            "Epoch: 790, weights = 0.10832686722278595, loss = 5.675429821014404\n",
            "Epoch: 800, weights = 0.10969635844230652, loss = 5.671321392059326\n",
            "Epoch: 810, weights = 0.11106584966182709, loss = 5.667212963104248\n",
            "Epoch: 820, weights = 0.11243534088134766, loss = 5.66310453414917\n",
            "Epoch: 830, weights = 0.11380483210086823, loss = 5.658996105194092\n",
            "Epoch: 840, weights = 0.1151743233203888, loss = 5.654887676239014\n",
            "Epoch: 850, weights = 0.11654381453990936, loss = 5.6507792472839355\n",
            "Epoch: 860, weights = 0.11791330575942993, loss = 5.646670818328857\n",
            "Epoch: 870, weights = 0.1192827969789505, loss = 5.642562389373779\n",
            "Epoch: 880, weights = 0.12065228819847107, loss = 5.638453960418701\n",
            "Epoch: 890, weights = 0.12202177941799164, loss = 5.634345054626465\n",
            "Epoch: 900, weights = 0.12339127063751221, loss = 5.630236625671387\n",
            "Epoch: 910, weights = 0.12476076185703278, loss = 5.626128196716309\n",
            "Epoch: 920, weights = 0.12613031268119812, loss = 5.6220197677612305\n",
            "Epoch: 930, weights = 0.12749987840652466, loss = 5.617910861968994\n",
            "Epoch: 940, weights = 0.1288694441318512, loss = 5.613802433013916\n",
            "Epoch: 950, weights = 0.13023900985717773, loss = 5.609694004058838\n",
            "Epoch: 960, weights = 0.13160857558250427, loss = 5.605585098266602\n",
            "Epoch: 970, weights = 0.1329781413078308, loss = 5.601476669311523\n",
            "Epoch: 980, weights = 0.13434770703315735, loss = 5.597367763519287\n",
            "Epoch: 990, weights = 0.1357172727584839, loss = 5.593259334564209\n",
            "Epoch: 1000, weights = 0.13708683848381042, loss = 5.589150428771973\n",
            "Epoch: 1010, weights = 0.13845640420913696, loss = 5.5850419998168945\n",
            "Epoch: 1020, weights = 0.1398259699344635, loss = 5.580933094024658\n",
            "Epoch: 1030, weights = 0.14119553565979004, loss = 5.57682466506958\n",
            "Epoch: 1040, weights = 0.14256510138511658, loss = 5.572715759277344\n",
            "Epoch: 1050, weights = 0.14393466711044312, loss = 5.568606376647949\n",
            "Epoch: 1060, weights = 0.14530423283576965, loss = 5.564497947692871\n",
            "Epoch: 1070, weights = 0.1466737985610962, loss = 5.560389518737793\n",
            "Epoch: 1080, weights = 0.14804336428642273, loss = 5.556281089782715\n",
            "Epoch: 1090, weights = 0.14941293001174927, loss = 5.5521721839904785\n",
            "Epoch: 1100, weights = 0.1507824957370758, loss = 5.5480637550354\n",
            "Epoch: 1110, weights = 0.15215206146240234, loss = 5.543954849243164\n",
            "Epoch: 1120, weights = 0.15352162718772888, loss = 5.539845943450928\n",
            "Epoch: 1130, weights = 0.15489119291305542, loss = 5.535737037658691\n",
            "Epoch: 1140, weights = 0.15626075863838196, loss = 5.531628608703613\n",
            "Epoch: 1150, weights = 0.1576303243637085, loss = 5.527520179748535\n",
            "Epoch: 1160, weights = 0.15899989008903503, loss = 5.523411273956299\n",
            "Epoch: 1170, weights = 0.16036945581436157, loss = 5.5193023681640625\n",
            "Epoch: 1180, weights = 0.1617390215396881, loss = 5.515193939208984\n",
            "Epoch: 1190, weights = 0.16310858726501465, loss = 5.511085033416748\n",
            "Epoch: 1200, weights = 0.1644781529903412, loss = 5.506976127624512\n",
            "Epoch: 1210, weights = 0.16584771871566772, loss = 5.502867698669434\n",
            "Epoch: 1220, weights = 0.16721728444099426, loss = 5.4987592697143555\n",
            "Epoch: 1230, weights = 0.1685868501663208, loss = 5.494650363922119\n",
            "Epoch: 1240, weights = 0.16995641589164734, loss = 5.490541458129883\n",
            "Epoch: 1250, weights = 0.17132598161697388, loss = 5.4864325523376465\n",
            "Epoch: 1260, weights = 0.17269554734230042, loss = 5.482324123382568\n",
            "Epoch: 1270, weights = 0.17406511306762695, loss = 5.478215217590332\n",
            "Epoch: 1280, weights = 0.1754346787929535, loss = 5.474106788635254\n",
            "Epoch: 1290, weights = 0.17680424451828003, loss = 5.469998359680176\n",
            "Epoch: 1300, weights = 0.17817381024360657, loss = 5.465889930725098\n",
            "Epoch: 1310, weights = 0.1795433759689331, loss = 5.461780548095703\n",
            "Epoch: 1320, weights = 0.18091294169425964, loss = 5.457671642303467\n",
            "Epoch: 1330, weights = 0.18228250741958618, loss = 5.453563213348389\n",
            "Epoch: 1340, weights = 0.18365207314491272, loss = 5.449454307556152\n",
            "Epoch: 1350, weights = 0.18502163887023926, loss = 5.445345878601074\n",
            "Epoch: 1360, weights = 0.1863912045955658, loss = 5.441236972808838\n",
            "Epoch: 1370, weights = 0.18776077032089233, loss = 5.43712854385376\n",
            "Epoch: 1380, weights = 0.18913033604621887, loss = 5.433019638061523\n",
            "Epoch: 1390, weights = 0.1904999017715454, loss = 5.428911209106445\n",
            "Epoch: 1400, weights = 0.19186946749687195, loss = 5.424802303314209\n",
            "Epoch: 1410, weights = 0.1932390332221985, loss = 5.420693874359131\n",
            "Epoch: 1420, weights = 0.19460859894752502, loss = 5.416585445404053\n",
            "Epoch: 1430, weights = 0.19597816467285156, loss = 5.412476539611816\n",
            "Epoch: 1440, weights = 0.1973477303981781, loss = 5.408368110656738\n",
            "Epoch: 1450, weights = 0.19871729612350464, loss = 5.404259204864502\n",
            "Epoch: 1460, weights = 0.20008686184883118, loss = 5.400150775909424\n",
            "Epoch: 1470, weights = 0.20145642757415771, loss = 5.3960418701171875\n",
            "Epoch: 1480, weights = 0.20282599329948425, loss = 5.391932487487793\n",
            "Epoch: 1490, weights = 0.2041955590248108, loss = 5.387824058532715\n",
            "Epoch: 1500, weights = 0.20556512475013733, loss = 5.383715629577637\n",
            "Epoch: 1510, weights = 0.20693469047546387, loss = 5.379607200622559\n",
            "Epoch: 1520, weights = 0.2083042562007904, loss = 5.375498294830322\n",
            "Epoch: 1530, weights = 0.20967382192611694, loss = 5.371389389038086\n",
            "Epoch: 1540, weights = 0.21104338765144348, loss = 5.367280960083008\n",
            "Epoch: 1550, weights = 0.21241295337677002, loss = 5.363171577453613\n",
            "Epoch: 1560, weights = 0.21378251910209656, loss = 5.359063148498535\n",
            "Epoch: 1570, weights = 0.2151520848274231, loss = 5.354954719543457\n",
            "Epoch: 1580, weights = 0.21652165055274963, loss = 5.350846290588379\n",
            "Epoch: 1590, weights = 0.21789121627807617, loss = 5.346736907958984\n",
            "Epoch: 1600, weights = 0.2192607820034027, loss = 5.342628479003906\n",
            "Epoch: 1610, weights = 0.22063034772872925, loss = 5.338520050048828\n",
            "Epoch: 1620, weights = 0.2219999134540558, loss = 5.334411144256592\n",
            "Epoch: 1630, weights = 0.22336947917938232, loss = 5.3303022384643555\n",
            "Epoch: 1640, weights = 0.22473904490470886, loss = 5.326193809509277\n",
            "Epoch: 1650, weights = 0.2261086106300354, loss = 5.322085380554199\n",
            "Epoch: 1660, weights = 0.22747817635536194, loss = 5.317976474761963\n",
            "Epoch: 1670, weights = 0.22884774208068848, loss = 5.313867568969727\n",
            "Epoch: 1680, weights = 0.23021730780601501, loss = 5.30975866317749\n",
            "Epoch: 1690, weights = 0.23158687353134155, loss = 5.305649757385254\n",
            "Epoch: 1700, weights = 0.2329564392566681, loss = 5.301541328430176\n",
            "Epoch: 1710, weights = 0.23432600498199463, loss = 5.297432899475098\n",
            "Epoch: 1720, weights = 0.23569557070732117, loss = 5.2933244705200195\n",
            "Epoch: 1730, weights = 0.2370651364326477, loss = 5.289215087890625\n",
            "Epoch: 1740, weights = 0.23843470215797424, loss = 5.285106658935547\n",
            "Epoch: 1750, weights = 0.23980426788330078, loss = 5.2809977531433105\n",
            "Epoch: 1760, weights = 0.24117383360862732, loss = 5.276889324188232\n",
            "Epoch: 1770, weights = 0.24254339933395386, loss = 5.272780418395996\n",
            "Epoch: 1780, weights = 0.2439129650592804, loss = 5.268671989440918\n",
            "Epoch: 1790, weights = 0.24528253078460693, loss = 5.264563083648682\n",
            "Epoch: 1800, weights = 0.24665209650993347, loss = 5.2604546546936035\n",
            "Epoch: 1810, weights = 0.24802166223526, loss = 5.256345748901367\n",
            "Epoch: 1820, weights = 0.24939122796058655, loss = 5.252237319946289\n",
            "Epoch: 1830, weights = 0.2507607042789459, loss = 5.248128890991211\n",
            "Epoch: 1840, weights = 0.2521301209926605, loss = 5.244020462036133\n",
            "Epoch: 1850, weights = 0.2534995377063751, loss = 5.239912033081055\n",
            "Epoch: 1860, weights = 0.2548689544200897, loss = 5.235804080963135\n",
            "Epoch: 1870, weights = 0.2562383711338043, loss = 5.231695652008057\n",
            "Epoch: 1880, weights = 0.2576077878475189, loss = 5.2275872230529785\n",
            "Epoch: 1890, weights = 0.2589772045612335, loss = 5.2234787940979\n",
            "Epoch: 1900, weights = 0.2603466212749481, loss = 5.2193708419799805\n",
            "Epoch: 1910, weights = 0.2617160379886627, loss = 5.215262413024902\n",
            "Epoch: 1920, weights = 0.2630854547023773, loss = 5.211153984069824\n",
            "Epoch: 1930, weights = 0.2644548714160919, loss = 5.207046031951904\n",
            "Epoch: 1940, weights = 0.2658242881298065, loss = 5.202937602996826\n",
            "Epoch: 1950, weights = 0.2671937048435211, loss = 5.198829650878906\n",
            "Epoch: 1960, weights = 0.2685631215572357, loss = 5.194721221923828\n",
            "Epoch: 1970, weights = 0.2699325382709503, loss = 5.19061279296875\n",
            "Epoch: 1980, weights = 0.2713019549846649, loss = 5.186505317687988\n",
            "Epoch: 1990, weights = 0.2726713716983795, loss = 5.18239688873291\n",
            "Epoch: 2000, weights = 0.2740407884120941, loss = 5.178288459777832\n",
            "Epoch: 2010, weights = 0.2754102051258087, loss = 5.174180030822754\n",
            "Epoch: 2020, weights = 0.2767796218395233, loss = 5.170071601867676\n",
            "Epoch: 2030, weights = 0.2781490385532379, loss = 5.165963649749756\n",
            "Epoch: 2040, weights = 0.2795184552669525, loss = 5.161855220794678\n",
            "Epoch: 2050, weights = 0.2808878719806671, loss = 5.1577467918396\n",
            "Epoch: 2060, weights = 0.2822572886943817, loss = 5.15363883972168\n",
            "Epoch: 2070, weights = 0.2836267054080963, loss = 5.14953088760376\n",
            "Epoch: 2080, weights = 0.2849961221218109, loss = 5.14542293548584\n",
            "Epoch: 2090, weights = 0.2863655388355255, loss = 5.141314506530762\n",
            "Epoch: 2100, weights = 0.2877349555492401, loss = 5.137206077575684\n",
            "Epoch: 2110, weights = 0.2891043722629547, loss = 5.1330976486206055\n",
            "Epoch: 2120, weights = 0.2904737889766693, loss = 5.128989219665527\n",
            "Epoch: 2130, weights = 0.2918432056903839, loss = 5.124880790710449\n",
            "Epoch: 2140, weights = 0.2932126224040985, loss = 5.120772838592529\n",
            "Epoch: 2150, weights = 0.2945820391178131, loss = 5.116664886474609\n",
            "Epoch: 2160, weights = 0.2959514558315277, loss = 5.112556457519531\n",
            "Epoch: 2170, weights = 0.2973208725452423, loss = 5.108448028564453\n",
            "Epoch: 2180, weights = 0.2986902892589569, loss = 5.104340076446533\n",
            "Epoch: 2190, weights = 0.3000597059726715, loss = 5.100232124328613\n",
            "Epoch: 2200, weights = 0.3014291226863861, loss = 5.096123695373535\n",
            "Epoch: 2210, weights = 0.3027985394001007, loss = 5.092015266418457\n",
            "Epoch: 2220, weights = 0.3041679561138153, loss = 5.087906837463379\n",
            "Epoch: 2230, weights = 0.3055373728275299, loss = 5.083798408508301\n",
            "Epoch: 2240, weights = 0.3069067895412445, loss = 5.079689979553223\n",
            "Epoch: 2250, weights = 0.3082762062549591, loss = 5.075582027435303\n",
            "Epoch: 2260, weights = 0.3096456229686737, loss = 5.071474075317383\n",
            "Epoch: 2270, weights = 0.3110150396823883, loss = 5.067366123199463\n",
            "Epoch: 2280, weights = 0.3123844563961029, loss = 5.063257694244385\n",
            "Epoch: 2290, weights = 0.3137538731098175, loss = 5.059149265289307\n",
            "Epoch: 2300, weights = 0.3151232898235321, loss = 5.055041313171387\n",
            "Epoch: 2310, weights = 0.3164927065372467, loss = 5.050932884216309\n",
            "Epoch: 2320, weights = 0.3178621232509613, loss = 5.0468244552612305\n",
            "Epoch: 2330, weights = 0.3192315399646759, loss = 5.042716026306152\n",
            "Epoch: 2340, weights = 0.3206009566783905, loss = 5.038607597351074\n",
            "Epoch: 2350, weights = 0.3219703733921051, loss = 5.0345001220703125\n",
            "Epoch: 2360, weights = 0.3233397901058197, loss = 5.030391693115234\n",
            "Epoch: 2370, weights = 0.3247092068195343, loss = 5.026283264160156\n",
            "Epoch: 2380, weights = 0.3260786235332489, loss = 5.022175312042236\n",
            "Epoch: 2390, weights = 0.3274480402469635, loss = 5.018066883087158\n",
            "Epoch: 2400, weights = 0.3288174569606781, loss = 5.013958930969238\n",
            "Epoch: 2410, weights = 0.3301868736743927, loss = 5.00985050201416\n",
            "Epoch: 2420, weights = 0.3315562903881073, loss = 5.005742073059082\n",
            "Epoch: 2430, weights = 0.3329257071018219, loss = 5.001634120941162\n",
            "Epoch: 2440, weights = 0.3342951238155365, loss = 4.997525691986084\n",
            "Epoch: 2450, weights = 0.3356645405292511, loss = 4.993417263031006\n",
            "Epoch: 2460, weights = 0.3370339572429657, loss = 4.989308834075928\n",
            "Epoch: 2470, weights = 0.3384033739566803, loss = 4.985200881958008\n",
            "Epoch: 2480, weights = 0.3397727906703949, loss = 4.98109245300293\n",
            "Epoch: 2490, weights = 0.3411422073841095, loss = 4.976984024047852\n",
            "Epoch: 2500, weights = 0.3425116240978241, loss = 4.972876071929932\n",
            "Epoch: 2510, weights = 0.3438810408115387, loss = 4.9687676429748535\n",
            "Epoch: 2520, weights = 0.3452504575252533, loss = 4.964659214019775\n",
            "Epoch: 2530, weights = 0.3466198742389679, loss = 4.960550785064697\n",
            "Epoch: 2540, weights = 0.3479892909526825, loss = 4.956442832946777\n",
            "Epoch: 2550, weights = 0.3493587076663971, loss = 4.952334403991699\n",
            "Epoch: 2560, weights = 0.3507281243801117, loss = 4.948225975036621\n",
            "Epoch: 2570, weights = 0.3520975410938263, loss = 4.944118022918701\n",
            "Epoch: 2580, weights = 0.3534669578075409, loss = 4.940009593963623\n",
            "Epoch: 2590, weights = 0.3548363745212555, loss = 4.935901641845703\n",
            "Epoch: 2600, weights = 0.3562057912349701, loss = 4.931793212890625\n",
            "Epoch: 2610, weights = 0.3575752079486847, loss = 4.927684783935547\n",
            "Epoch: 2620, weights = 0.3589446246623993, loss = 4.923577308654785\n",
            "Epoch: 2630, weights = 0.3603140413761139, loss = 4.919468879699707\n",
            "Epoch: 2640, weights = 0.3616834580898285, loss = 4.915360450744629\n",
            "Epoch: 2650, weights = 0.3630528748035431, loss = 4.911252021789551\n",
            "Epoch: 2660, weights = 0.3644222915172577, loss = 4.907143592834473\n",
            "Epoch: 2670, weights = 0.3657917082309723, loss = 4.903035640716553\n",
            "Epoch: 2680, weights = 0.3671611249446869, loss = 4.898927211761475\n",
            "Epoch: 2690, weights = 0.3685305416584015, loss = 4.8948187828063965\n",
            "Epoch: 2700, weights = 0.3698999583721161, loss = 4.890710830688477\n",
            "Epoch: 2710, weights = 0.3712693750858307, loss = 4.886602401733398\n",
            "Epoch: 2720, weights = 0.3726387917995453, loss = 4.882494926452637\n",
            "Epoch: 2730, weights = 0.3740082085132599, loss = 4.878386497497559\n",
            "Epoch: 2740, weights = 0.3753776252269745, loss = 4.8742780685424805\n",
            "Epoch: 2750, weights = 0.3767470419406891, loss = 4.870169639587402\n",
            "Epoch: 2760, weights = 0.3781164586544037, loss = 4.866061210632324\n",
            "Epoch: 2770, weights = 0.3794858753681183, loss = 4.861952781677246\n",
            "Epoch: 2780, weights = 0.3808552920818329, loss = 4.857844829559326\n",
            "Epoch: 2790, weights = 0.3822247087955475, loss = 4.853736877441406\n",
            "Epoch: 2800, weights = 0.3835941255092621, loss = 4.849628448486328\n",
            "Epoch: 2810, weights = 0.3849635422229767, loss = 4.84552001953125\n",
            "Epoch: 2820, weights = 0.3863329589366913, loss = 4.84141206741333\n",
            "Epoch: 2830, weights = 0.3877023756504059, loss = 4.83730411529541\n",
            "Epoch: 2840, weights = 0.3890717923641205, loss = 4.833195686340332\n",
            "Epoch: 2850, weights = 0.3904412090778351, loss = 4.829087257385254\n",
            "Epoch: 2860, weights = 0.3918106257915497, loss = 4.824978828430176\n",
            "Epoch: 2870, weights = 0.3931800425052643, loss = 4.820870399475098\n",
            "Epoch: 2880, weights = 0.3945494592189789, loss = 4.8167619705200195\n",
            "Epoch: 2890, weights = 0.3959188759326935, loss = 4.812654495239258\n",
            "Epoch: 2900, weights = 0.3972882926464081, loss = 4.80854606628418\n",
            "Epoch: 2910, weights = 0.3986577093601227, loss = 4.80443811416626\n",
            "Epoch: 2920, weights = 0.4000271260738373, loss = 4.800329685211182\n",
            "Epoch: 2930, weights = 0.4013965427875519, loss = 4.7962212562561035\n",
            "Epoch: 2940, weights = 0.4027659595012665, loss = 4.792113304138184\n",
            "Epoch: 2950, weights = 0.4041353762149811, loss = 4.7880048751831055\n",
            "Epoch: 2960, weights = 0.4055047929286957, loss = 4.783896446228027\n",
            "Epoch: 2970, weights = 0.4068742096424103, loss = 4.779788017272949\n",
            "Epoch: 2980, weights = 0.4082436263561249, loss = 4.775679588317871\n",
            "Epoch: 2990, weights = 0.4096130430698395, loss = 4.771572113037109\n",
            "Epoch: 3000, weights = 0.4109824597835541, loss = 4.767463684082031\n",
            "Epoch: 3010, weights = 0.4123518764972687, loss = 4.763355255126953\n",
            "Epoch: 3020, weights = 0.4137212932109833, loss = 4.759247303009033\n",
            "Epoch: 3030, weights = 0.4150907099246979, loss = 4.755138874053955\n",
            "Epoch: 3040, weights = 0.4164601266384125, loss = 4.751030445098877\n",
            "Epoch: 3050, weights = 0.4178295433521271, loss = 4.746922492980957\n",
            "Epoch: 3060, weights = 0.4191989600658417, loss = 4.742814064025879\n",
            "Epoch: 3070, weights = 0.4205683767795563, loss = 4.738706111907959\n",
            "Epoch: 3080, weights = 0.4219377934932709, loss = 4.734597682952881\n",
            "Epoch: 3090, weights = 0.4233072102069855, loss = 4.730489253997803\n",
            "Epoch: 3100, weights = 0.4246766269207001, loss = 4.726380825042725\n",
            "Epoch: 3110, weights = 0.4260460436344147, loss = 4.722272872924805\n",
            "Epoch: 3120, weights = 0.4274154603481293, loss = 4.718164443969727\n",
            "Epoch: 3130, weights = 0.42878487706184387, loss = 4.714056015014648\n",
            "Epoch: 3140, weights = 0.43015429377555847, loss = 4.7099480628967285\n",
            "Epoch: 3150, weights = 0.43152371048927307, loss = 4.70583963394165\n",
            "Epoch: 3160, weights = 0.43289312720298767, loss = 4.701731204986572\n",
            "Epoch: 3170, weights = 0.43426254391670227, loss = 4.697622776031494\n",
            "Epoch: 3180, weights = 0.43563196063041687, loss = 4.693514823913574\n",
            "Epoch: 3190, weights = 0.43700137734413147, loss = 4.689406394958496\n",
            "Epoch: 3200, weights = 0.43837079405784607, loss = 4.685298442840576\n",
            "Epoch: 3210, weights = 0.43974021077156067, loss = 4.681190013885498\n",
            "Epoch: 3220, weights = 0.44110962748527527, loss = 4.67708158493042\n",
            "Epoch: 3230, weights = 0.44247904419898987, loss = 4.6729736328125\n",
            "Epoch: 3240, weights = 0.44384846091270447, loss = 4.668865203857422\n",
            "Epoch: 3250, weights = 0.44521787762641907, loss = 4.664756774902344\n",
            "Epoch: 3260, weights = 0.44658729434013367, loss = 4.660649299621582\n",
            "Epoch: 3270, weights = 0.44795671105384827, loss = 4.656540870666504\n",
            "Epoch: 3280, weights = 0.44932612776756287, loss = 4.652432441711426\n",
            "Epoch: 3290, weights = 0.45069554448127747, loss = 4.648324012756348\n",
            "Epoch: 3300, weights = 0.45206496119499207, loss = 4.6442155838012695\n",
            "Epoch: 3310, weights = 0.45343437790870667, loss = 4.64010763168335\n",
            "Epoch: 3320, weights = 0.45480379462242126, loss = 4.6359992027282715\n",
            "Epoch: 3330, weights = 0.45617321133613586, loss = 4.631890773773193\n",
            "Epoch: 3340, weights = 0.45754262804985046, loss = 4.627782821655273\n",
            "Epoch: 3350, weights = 0.45891204476356506, loss = 4.623674392700195\n",
            "Epoch: 3360, weights = 0.46028146147727966, loss = 4.619566440582275\n",
            "Epoch: 3370, weights = 0.46165087819099426, loss = 4.6154584884643555\n",
            "Epoch: 3380, weights = 0.46302029490470886, loss = 4.611350059509277\n",
            "Epoch: 3390, weights = 0.46438971161842346, loss = 4.607241630554199\n",
            "Epoch: 3400, weights = 0.46575912833213806, loss = 4.603133201599121\n",
            "Epoch: 3410, weights = 0.46712854504585266, loss = 4.599024772644043\n",
            "Epoch: 3420, weights = 0.46849796175956726, loss = 4.594916820526123\n",
            "Epoch: 3430, weights = 0.46986737847328186, loss = 4.590808868408203\n",
            "Epoch: 3440, weights = 0.47123679518699646, loss = 4.586700439453125\n",
            "Epoch: 3450, weights = 0.47260621190071106, loss = 4.582592010498047\n",
            "Epoch: 3460, weights = 0.47397562861442566, loss = 4.578484058380127\n",
            "Epoch: 3470, weights = 0.47534504532814026, loss = 4.574376106262207\n",
            "Epoch: 3480, weights = 0.47671446204185486, loss = 4.570267677307129\n",
            "Epoch: 3490, weights = 0.47808387875556946, loss = 4.566159248352051\n",
            "Epoch: 3500, weights = 0.47945329546928406, loss = 4.562050819396973\n",
            "Epoch: 3510, weights = 0.48082271218299866, loss = 4.5579423904418945\n",
            "Epoch: 3520, weights = 0.48219212889671326, loss = 4.553834438323975\n",
            "Epoch: 3530, weights = 0.48356154561042786, loss = 4.549726486206055\n",
            "Epoch: 3540, weights = 0.48493096232414246, loss = 4.545618057250977\n",
            "Epoch: 3550, weights = 0.48630037903785706, loss = 4.541510105133057\n",
            "Epoch: 3560, weights = 0.48766979575157166, loss = 4.5374016761779785\n",
            "Epoch: 3570, weights = 0.48903921246528625, loss = 4.5332932472229\n",
            "Epoch: 3580, weights = 0.49040862917900085, loss = 4.5291852951049805\n",
            "Epoch: 3590, weights = 0.49177804589271545, loss = 4.525076866149902\n",
            "Epoch: 3600, weights = 0.49314746260643005, loss = 4.520968437194824\n",
            "Epoch: 3610, weights = 0.49451687932014465, loss = 4.516860008239746\n",
            "Epoch: 3620, weights = 0.49588629603385925, loss = 4.512751579284668\n",
            "Epoch: 3630, weights = 0.49725571274757385, loss = 4.508644104003906\n",
            "Epoch: 3640, weights = 0.49862512946128845, loss = 4.504535675048828\n",
            "Epoch: 3650, weights = 0.49999454617500305, loss = 4.50042724609375\n",
            "Epoch: 3660, weights = 0.5013642311096191, loss = 4.4963178634643555\n",
            "Epoch: 3670, weights = 0.5027339458465576, loss = 4.492209434509277\n",
            "Epoch: 3680, weights = 0.5041036605834961, loss = 4.488100051879883\n",
            "Epoch: 3690, weights = 0.5054733753204346, loss = 4.483990669250488\n",
            "Epoch: 3700, weights = 0.506843090057373, loss = 4.479881763458252\n",
            "Epoch: 3710, weights = 0.5082128047943115, loss = 4.475772380828857\n",
            "Epoch: 3720, weights = 0.50958251953125, loss = 4.471663475036621\n",
            "Epoch: 3730, weights = 0.5109522342681885, loss = 4.467554092407227\n",
            "Epoch: 3740, weights = 0.512321949005127, loss = 4.463444709777832\n",
            "Epoch: 3750, weights = 0.5136916637420654, loss = 4.459336280822754\n",
            "Epoch: 3760, weights = 0.5150613784790039, loss = 4.455226421356201\n",
            "Epoch: 3770, weights = 0.5164310932159424, loss = 4.451117515563965\n",
            "Epoch: 3780, weights = 0.5178008079528809, loss = 4.4470086097717285\n",
            "Epoch: 3790, weights = 0.5191705226898193, loss = 4.442899227142334\n",
            "Epoch: 3800, weights = 0.5205402374267578, loss = 4.438790321350098\n",
            "Epoch: 3810, weights = 0.5219099521636963, loss = 4.434681415557861\n",
            "Epoch: 3820, weights = 0.5232796669006348, loss = 4.430571556091309\n",
            "Epoch: 3830, weights = 0.5246493816375732, loss = 4.4264631271362305\n",
            "Epoch: 3840, weights = 0.5260190963745117, loss = 4.422353744506836\n",
            "Epoch: 3850, weights = 0.5273888111114502, loss = 4.418244361877441\n",
            "Epoch: 3860, weights = 0.5287585258483887, loss = 4.414135456085205\n",
            "Epoch: 3870, weights = 0.5301282405853271, loss = 4.4100260734558105\n",
            "Epoch: 3880, weights = 0.5314979553222656, loss = 4.405917167663574\n",
            "Epoch: 3890, weights = 0.5328676700592041, loss = 4.40180778503418\n",
            "Epoch: 3900, weights = 0.5342373847961426, loss = 4.397698402404785\n",
            "Epoch: 3910, weights = 0.535607099533081, loss = 4.393589973449707\n",
            "Epoch: 3920, weights = 0.5369768142700195, loss = 4.389480113983154\n",
            "Epoch: 3930, weights = 0.538346529006958, loss = 4.385371208190918\n",
            "Epoch: 3940, weights = 0.5397162437438965, loss = 4.381262302398682\n",
            "Epoch: 3950, weights = 0.541085958480835, loss = 4.377152919769287\n",
            "Epoch: 3960, weights = 0.5424556732177734, loss = 4.373044013977051\n",
            "Epoch: 3970, weights = 0.5438253879547119, loss = 4.3689351081848145\n",
            "Epoch: 3980, weights = 0.5451951026916504, loss = 4.364825248718262\n",
            "Epoch: 3990, weights = 0.5465648174285889, loss = 4.360716819763184\n",
            "Epoch: 4000, weights = 0.5479345321655273, loss = 4.356607437133789\n",
            "Epoch: 4010, weights = 0.5493042469024658, loss = 4.3524980545043945\n",
            "Epoch: 4020, weights = 0.5506739616394043, loss = 4.348389148712158\n",
            "Epoch: 4030, weights = 0.5520436763763428, loss = 4.344279766082764\n",
            "Epoch: 4040, weights = 0.5534133911132812, loss = 4.340170860290527\n",
            "Epoch: 4050, weights = 0.5547831058502197, loss = 4.336061477661133\n",
            "Epoch: 4060, weights = 0.5561528205871582, loss = 4.331952095031738\n",
            "Epoch: 4070, weights = 0.5575225353240967, loss = 4.32784366607666\n",
            "Epoch: 4080, weights = 0.5588922500610352, loss = 4.323734283447266\n",
            "Epoch: 4090, weights = 0.5602619647979736, loss = 4.319624900817871\n",
            "Epoch: 4100, weights = 0.5616316795349121, loss = 4.315515995025635\n",
            "Epoch: 4110, weights = 0.5630013942718506, loss = 4.31140661239624\n",
            "Epoch: 4120, weights = 0.5643711090087891, loss = 4.307297706604004\n",
            "Epoch: 4130, weights = 0.5657408237457275, loss = 4.303188323974609\n",
            "Epoch: 4140, weights = 0.567110538482666, loss = 4.299078941345215\n",
            "Epoch: 4150, weights = 0.5684802532196045, loss = 4.294970512390137\n",
            "Epoch: 4160, weights = 0.569849967956543, loss = 4.290861129760742\n",
            "Epoch: 4170, weights = 0.5712196826934814, loss = 4.286751747131348\n",
            "Epoch: 4180, weights = 0.5725893974304199, loss = 4.282642841339111\n",
            "Epoch: 4190, weights = 0.5739591121673584, loss = 4.278533458709717\n",
            "Epoch: 4200, weights = 0.5753288269042969, loss = 4.2744245529174805\n",
            "Epoch: 4210, weights = 0.5766985416412354, loss = 4.270315170288086\n",
            "Epoch: 4220, weights = 0.5780682563781738, loss = 4.266205787658691\n",
            "Epoch: 4230, weights = 0.5794379711151123, loss = 4.262097358703613\n",
            "Epoch: 4240, weights = 0.5808076858520508, loss = 4.257987976074219\n",
            "Epoch: 4250, weights = 0.5821774005889893, loss = 4.253878593444824\n",
            "Epoch: 4260, weights = 0.5835471153259277, loss = 4.249769687652588\n",
            "Epoch: 4270, weights = 0.5849168300628662, loss = 4.245660305023193\n",
            "Epoch: 4280, weights = 0.5862865447998047, loss = 4.241551399230957\n",
            "Epoch: 4290, weights = 0.5876562595367432, loss = 4.2374420166015625\n",
            "Epoch: 4300, weights = 0.5890259742736816, loss = 4.233332633972168\n",
            "Epoch: 4310, weights = 0.5903956890106201, loss = 4.22922420501709\n",
            "Epoch: 4320, weights = 0.5917654037475586, loss = 4.225114822387695\n",
            "Epoch: 4330, weights = 0.5931351184844971, loss = 4.221005439758301\n",
            "Epoch: 4340, weights = 0.5945048332214355, loss = 4.2168965339660645\n",
            "Epoch: 4350, weights = 0.595874547958374, loss = 4.21278715133667\n",
            "Epoch: 4360, weights = 0.5972442626953125, loss = 4.208678245544434\n",
            "Epoch: 4370, weights = 0.598613977432251, loss = 4.204568862915039\n",
            "Epoch: 4380, weights = 0.5999836921691895, loss = 4.2004594802856445\n",
            "Epoch: 4390, weights = 0.6013534069061279, loss = 4.196351051330566\n",
            "Epoch: 4400, weights = 0.6027231216430664, loss = 4.192241668701172\n",
            "Epoch: 4410, weights = 0.6040928363800049, loss = 4.188132286071777\n",
            "Epoch: 4420, weights = 0.6054625511169434, loss = 4.184023380279541\n",
            "Epoch: 4430, weights = 0.6068322658538818, loss = 4.1799139976501465\n",
            "Epoch: 4440, weights = 0.6082019805908203, loss = 4.17580509185791\n",
            "Epoch: 4450, weights = 0.6095716953277588, loss = 4.171695709228516\n",
            "Epoch: 4460, weights = 0.6109414100646973, loss = 4.167586326599121\n",
            "Epoch: 4470, weights = 0.6123111248016357, loss = 4.163477897644043\n",
            "Epoch: 4480, weights = 0.6136808395385742, loss = 4.159368515014648\n",
            "Epoch: 4490, weights = 0.6150505542755127, loss = 4.155259132385254\n",
            "Epoch: 4500, weights = 0.6164202690124512, loss = 4.151150226593018\n",
            "Epoch: 4510, weights = 0.6177899837493896, loss = 4.147040843963623\n",
            "Epoch: 4520, weights = 0.6191596984863281, loss = 4.142931938171387\n",
            "Epoch: 4530, weights = 0.6205294132232666, loss = 4.138822555541992\n",
            "Epoch: 4540, weights = 0.6218991279602051, loss = 4.134713172912598\n",
            "Epoch: 4550, weights = 0.6232688426971436, loss = 4.1306047439575195\n",
            "Epoch: 4560, weights = 0.624638557434082, loss = 4.126495361328125\n",
            "Epoch: 4570, weights = 0.6260082721710205, loss = 4.1223859786987305\n",
            "Epoch: 4580, weights = 0.627377986907959, loss = 4.118277072906494\n",
            "Epoch: 4590, weights = 0.6287477016448975, loss = 4.1141676902771\n",
            "Epoch: 4600, weights = 0.6301174163818359, loss = 4.110058784484863\n",
            "Epoch: 4610, weights = 0.6314871311187744, loss = 4.105949401855469\n",
            "Epoch: 4620, weights = 0.6328568458557129, loss = 4.101840019226074\n",
            "Epoch: 4630, weights = 0.6342265605926514, loss = 4.097731590270996\n",
            "Epoch: 4640, weights = 0.6355962753295898, loss = 4.093622207641602\n",
            "Epoch: 4650, weights = 0.6369659900665283, loss = 4.089512825012207\n",
            "Epoch: 4660, weights = 0.6383357048034668, loss = 4.085403919219971\n",
            "Epoch: 4670, weights = 0.6397054195404053, loss = 4.081294536590576\n",
            "Epoch: 4680, weights = 0.6410751342773438, loss = 4.07718563079834\n",
            "Epoch: 4690, weights = 0.6424448490142822, loss = 4.073076248168945\n",
            "Epoch: 4700, weights = 0.6438145637512207, loss = 4.068966865539551\n",
            "Epoch: 4710, weights = 0.6451842784881592, loss = 4.064858436584473\n",
            "Epoch: 4720, weights = 0.6465539932250977, loss = 4.060749053955078\n",
            "Epoch: 4730, weights = 0.6479237079620361, loss = 4.056639671325684\n",
            "Epoch: 4740, weights = 0.6492934226989746, loss = 4.052530765533447\n",
            "Epoch: 4750, weights = 0.6506631374359131, loss = 4.048421382904053\n",
            "Epoch: 4760, weights = 0.6520328521728516, loss = 4.044312477111816\n",
            "Epoch: 4770, weights = 0.65340256690979, loss = 4.040203094482422\n",
            "Epoch: 4780, weights = 0.6547722816467285, loss = 4.036093711853027\n",
            "Epoch: 4790, weights = 0.656141996383667, loss = 4.031985282897949\n",
            "Epoch: 4800, weights = 0.6575117111206055, loss = 4.027875900268555\n",
            "Epoch: 4810, weights = 0.658881425857544, loss = 4.02376651763916\n",
            "Epoch: 4820, weights = 0.6602511405944824, loss = 4.019657611846924\n",
            "Epoch: 4830, weights = 0.6616208553314209, loss = 4.015548229217529\n",
            "Epoch: 4840, weights = 0.6629905700683594, loss = 4.011439323425293\n",
            "Epoch: 4850, weights = 0.6643602848052979, loss = 4.007329940795898\n",
            "Epoch: 4860, weights = 0.6657299995422363, loss = 4.003220558166504\n",
            "Epoch: 4870, weights = 0.6670997142791748, loss = 3.9991118907928467\n",
            "Epoch: 4880, weights = 0.6684694290161133, loss = 3.9950027465820312\n",
            "Epoch: 4890, weights = 0.6698391437530518, loss = 3.990893602371216\n",
            "Epoch: 4900, weights = 0.6712088584899902, loss = 3.9867844581604004\n",
            "Epoch: 4910, weights = 0.6725785732269287, loss = 3.982675075531006\n",
            "Epoch: 4920, weights = 0.6739482879638672, loss = 3.9785659313201904\n",
            "Epoch: 4930, weights = 0.6753180027008057, loss = 3.974456787109375\n",
            "Epoch: 4940, weights = 0.6766877174377441, loss = 3.9703476428985596\n",
            "Epoch: 4950, weights = 0.6780574321746826, loss = 3.9662387371063232\n",
            "Epoch: 4960, weights = 0.6794271469116211, loss = 3.962129592895508\n",
            "Epoch: 4970, weights = 0.6807968616485596, loss = 3.9580204486846924\n",
            "Epoch: 4980, weights = 0.682166576385498, loss = 3.953911304473877\n",
            "Epoch: 4990, weights = 0.6835362911224365, loss = 3.9498019218444824\n",
            "Epoch: 5000, weights = 0.684906005859375, loss = 3.945692777633667\n",
            "Epoch: 5010, weights = 0.6862757205963135, loss = 3.9415836334228516\n",
            "Epoch: 5020, weights = 0.687645435333252, loss = 3.937474489212036\n",
            "Epoch: 5030, weights = 0.6890151500701904, loss = 3.9333655834198\n",
            "Epoch: 5040, weights = 0.6903848648071289, loss = 3.9292564392089844\n",
            "Epoch: 5050, weights = 0.6917545795440674, loss = 3.925147294998169\n",
            "Epoch: 5060, weights = 0.6931242942810059, loss = 3.9210381507873535\n",
            "Epoch: 5070, weights = 0.6944940090179443, loss = 3.916928768157959\n",
            "Epoch: 5080, weights = 0.6958637237548828, loss = 3.9128196239471436\n",
            "Epoch: 5090, weights = 0.6972334384918213, loss = 3.908710479736328\n",
            "Epoch: 5100, weights = 0.6986031532287598, loss = 3.9046013355255127\n",
            "Epoch: 5110, weights = 0.6999728679656982, loss = 3.9004924297332764\n",
            "Epoch: 5120, weights = 0.7013425827026367, loss = 3.896383285522461\n",
            "Epoch: 5130, weights = 0.7027122974395752, loss = 3.8922741413116455\n",
            "Epoch: 5140, weights = 0.7040820121765137, loss = 3.88816499710083\n",
            "Epoch: 5150, weights = 0.7054517269134521, loss = 3.8840556144714355\n",
            "Epoch: 5160, weights = 0.7068214416503906, loss = 3.87994647026062\n",
            "Epoch: 5170, weights = 0.7081911563873291, loss = 3.8758373260498047\n",
            "Epoch: 5180, weights = 0.7095608711242676, loss = 3.8717281818389893\n",
            "Epoch: 5190, weights = 0.710930585861206, loss = 3.867619276046753\n",
            "Epoch: 5200, weights = 0.7123003005981445, loss = 3.8635101318359375\n",
            "Epoch: 5210, weights = 0.713670015335083, loss = 3.859400987625122\n",
            "Epoch: 5220, weights = 0.7150397300720215, loss = 3.8552918434143066\n",
            "Epoch: 5230, weights = 0.71640944480896, loss = 3.851182460784912\n",
            "Epoch: 5240, weights = 0.7177791595458984, loss = 3.8470733165740967\n",
            "Epoch: 5250, weights = 0.7191488742828369, loss = 3.8429641723632812\n",
            "Epoch: 5260, weights = 0.7205185890197754, loss = 3.838855028152466\n",
            "Epoch: 5270, weights = 0.7218883037567139, loss = 3.8347461223602295\n",
            "Epoch: 5280, weights = 0.7232580184936523, loss = 3.830636978149414\n",
            "Epoch: 5290, weights = 0.7246277332305908, loss = 3.8265278339385986\n",
            "Epoch: 5300, weights = 0.7259974479675293, loss = 3.822418689727783\n",
            "Epoch: 5310, weights = 0.7273671627044678, loss = 3.8183093070983887\n",
            "Epoch: 5320, weights = 0.7287368774414062, loss = 3.8142001628875732\n",
            "Epoch: 5330, weights = 0.7301065921783447, loss = 3.810091018676758\n",
            "Epoch: 5340, weights = 0.7314763069152832, loss = 3.8059818744659424\n",
            "Epoch: 5350, weights = 0.7328460216522217, loss = 3.801872968673706\n",
            "Epoch: 5360, weights = 0.7342157363891602, loss = 3.7977638244628906\n",
            "Epoch: 5370, weights = 0.7355854511260986, loss = 3.793654680252075\n",
            "Epoch: 5380, weights = 0.7369551658630371, loss = 3.7895455360412598\n",
            "Epoch: 5390, weights = 0.7383248805999756, loss = 3.7854361534118652\n",
            "Epoch: 5400, weights = 0.7396945953369141, loss = 3.78132700920105\n",
            "Epoch: 5410, weights = 0.7410643100738525, loss = 3.7772178649902344\n",
            "Epoch: 5420, weights = 0.742434024810791, loss = 3.773108720779419\n",
            "Epoch: 5430, weights = 0.7438037395477295, loss = 3.7689998149871826\n",
            "Epoch: 5440, weights = 0.745173454284668, loss = 3.764890670776367\n",
            "Epoch: 5450, weights = 0.7465431690216064, loss = 3.7607815265655518\n",
            "Epoch: 5460, weights = 0.7479128837585449, loss = 3.7566723823547363\n",
            "Epoch: 5470, weights = 0.7492825984954834, loss = 3.752562999725342\n",
            "Epoch: 5480, weights = 0.7506523132324219, loss = 3.7484538555145264\n",
            "Epoch: 5490, weights = 0.7520220279693604, loss = 3.744344711303711\n",
            "Epoch: 5500, weights = 0.7533917427062988, loss = 3.7402355670928955\n",
            "Epoch: 5510, weights = 0.7547614574432373, loss = 3.736126661300659\n",
            "Epoch: 5520, weights = 0.7561311721801758, loss = 3.7320175170898438\n",
            "Epoch: 5530, weights = 0.7575008869171143, loss = 3.7279083728790283\n",
            "Epoch: 5540, weights = 0.7588706016540527, loss = 3.723799228668213\n",
            "Epoch: 5550, weights = 0.7602403163909912, loss = 3.7196898460388184\n",
            "Epoch: 5560, weights = 0.7616100311279297, loss = 3.715580701828003\n",
            "Epoch: 5570, weights = 0.7629797458648682, loss = 3.7114715576171875\n",
            "Epoch: 5580, weights = 0.7643494606018066, loss = 3.707362413406372\n",
            "Epoch: 5590, weights = 0.7657191753387451, loss = 3.7032535076141357\n",
            "Epoch: 5600, weights = 0.7670888900756836, loss = 3.6991443634033203\n",
            "Epoch: 5610, weights = 0.7684586048126221, loss = 3.695035219192505\n",
            "Epoch: 5620, weights = 0.7698283195495605, loss = 3.6909260749816895\n",
            "Epoch: 5630, weights = 0.771198034286499, loss = 3.686816692352295\n",
            "Epoch: 5640, weights = 0.7725677490234375, loss = 3.6827075481414795\n",
            "Epoch: 5650, weights = 0.773937463760376, loss = 3.678598403930664\n",
            "Epoch: 5660, weights = 0.7753071784973145, loss = 3.6744892597198486\n",
            "Epoch: 5670, weights = 0.7766768932342529, loss = 3.6703803539276123\n",
            "Epoch: 5680, weights = 0.7780466079711914, loss = 3.666271209716797\n",
            "Epoch: 5690, weights = 0.7794163227081299, loss = 3.6621620655059814\n",
            "Epoch: 5700, weights = 0.7807860374450684, loss = 3.658052921295166\n",
            "Epoch: 5710, weights = 0.7821557521820068, loss = 3.6539435386657715\n",
            "Epoch: 5720, weights = 0.7835254669189453, loss = 3.649834394454956\n",
            "Epoch: 5730, weights = 0.7848951816558838, loss = 3.6457252502441406\n",
            "Epoch: 5740, weights = 0.7862648963928223, loss = 3.641616106033325\n",
            "Epoch: 5750, weights = 0.7876346111297607, loss = 3.637507200241089\n",
            "Epoch: 5760, weights = 0.7890043258666992, loss = 3.6333980560302734\n",
            "Epoch: 5770, weights = 0.7903740406036377, loss = 3.629288911819458\n",
            "Epoch: 5780, weights = 0.7917437553405762, loss = 3.6251797676086426\n",
            "Epoch: 5790, weights = 0.7931134700775146, loss = 3.621070384979248\n",
            "Epoch: 5800, weights = 0.7944831848144531, loss = 3.6169612407684326\n",
            "Epoch: 5810, weights = 0.7958528995513916, loss = 3.612852096557617\n",
            "Epoch: 5820, weights = 0.7972226142883301, loss = 3.6087429523468018\n",
            "Epoch: 5830, weights = 0.7985923290252686, loss = 3.6046340465545654\n",
            "Epoch: 5840, weights = 0.799962043762207, loss = 3.60052490234375\n",
            "Epoch: 5850, weights = 0.8013317584991455, loss = 3.5964157581329346\n",
            "Epoch: 5860, weights = 0.802701473236084, loss = 3.592306613922119\n",
            "Epoch: 5870, weights = 0.8040711879730225, loss = 3.5881972312927246\n",
            "Epoch: 5880, weights = 0.8054409027099609, loss = 3.584088087081909\n",
            "Epoch: 5890, weights = 0.8068106174468994, loss = 3.5799789428710938\n",
            "Epoch: 5900, weights = 0.8081803321838379, loss = 3.5758697986602783\n",
            "Epoch: 5910, weights = 0.8095500469207764, loss = 3.571760892868042\n",
            "Epoch: 5920, weights = 0.8109197616577148, loss = 3.5676517486572266\n",
            "Epoch: 5930, weights = 0.8122894763946533, loss = 3.563542604446411\n",
            "Epoch: 5940, weights = 0.8136591911315918, loss = 3.5594334602355957\n",
            "Epoch: 5950, weights = 0.8150289058685303, loss = 3.555324077606201\n",
            "Epoch: 5960, weights = 0.8163986206054688, loss = 3.5512149333953857\n",
            "Epoch: 5970, weights = 0.8177683353424072, loss = 3.5471057891845703\n",
            "Epoch: 5980, weights = 0.8191380500793457, loss = 3.542996644973755\n",
            "Epoch: 5990, weights = 0.8205077648162842, loss = 3.5388877391815186\n",
            "Epoch: 6000, weights = 0.8218774795532227, loss = 3.534778594970703\n",
            "Epoch: 6010, weights = 0.8232471942901611, loss = 3.5306694507598877\n",
            "Epoch: 6020, weights = 0.8246169090270996, loss = 3.5265603065490723\n",
            "Epoch: 6030, weights = 0.8259866237640381, loss = 3.5224509239196777\n",
            "Epoch: 6040, weights = 0.8273563385009766, loss = 3.5183417797088623\n",
            "Epoch: 6050, weights = 0.828726053237915, loss = 3.514232635498047\n",
            "Epoch: 6060, weights = 0.8300957679748535, loss = 3.5101234912872314\n",
            "Epoch: 6070, weights = 0.831465482711792, loss = 3.506014585494995\n",
            "Epoch: 6080, weights = 0.8328351974487305, loss = 3.5019054412841797\n",
            "Epoch: 6090, weights = 0.834204912185669, loss = 3.4977962970733643\n",
            "Epoch: 6100, weights = 0.8355746269226074, loss = 3.493687152862549\n",
            "Epoch: 6110, weights = 0.8369443416595459, loss = 3.4895777702331543\n",
            "Epoch: 6120, weights = 0.8383140563964844, loss = 3.485468626022339\n",
            "Epoch: 6130, weights = 0.8396837711334229, loss = 3.4813594818115234\n",
            "Epoch: 6140, weights = 0.8410534858703613, loss = 3.477250337600708\n",
            "Epoch: 6150, weights = 0.8424232006072998, loss = 3.4731414318084717\n",
            "Epoch: 6160, weights = 0.8437929153442383, loss = 3.4690322875976562\n",
            "Epoch: 6170, weights = 0.8451626300811768, loss = 3.464923143386841\n",
            "Epoch: 6180, weights = 0.8465323448181152, loss = 3.4608139991760254\n",
            "Epoch: 6190, weights = 0.8479020595550537, loss = 3.456704616546631\n",
            "Epoch: 6200, weights = 0.8492717742919922, loss = 3.4525954723358154\n",
            "Epoch: 6210, weights = 0.8506414890289307, loss = 3.448486328125\n",
            "Epoch: 6220, weights = 0.8520112037658691, loss = 3.4443771839141846\n",
            "Epoch: 6230, weights = 0.8533809185028076, loss = 3.4402682781219482\n",
            "Epoch: 6240, weights = 0.8547506332397461, loss = 3.436159133911133\n",
            "Epoch: 6250, weights = 0.8561203479766846, loss = 3.4320499897003174\n",
            "Epoch: 6260, weights = 0.857490062713623, loss = 3.427940845489502\n",
            "Epoch: 6270, weights = 0.8588597774505615, loss = 3.4238314628601074\n",
            "Epoch: 6280, weights = 0.8602294921875, loss = 3.419722318649292\n",
            "Epoch: 6290, weights = 0.8615992069244385, loss = 3.4156131744384766\n",
            "Epoch: 6300, weights = 0.862968921661377, loss = 3.411504030227661\n",
            "Epoch: 6310, weights = 0.8643386363983154, loss = 3.407395124435425\n",
            "Epoch: 6320, weights = 0.8657083511352539, loss = 3.4032859802246094\n",
            "Epoch: 6330, weights = 0.8670780658721924, loss = 3.399176836013794\n",
            "Epoch: 6340, weights = 0.8684477806091309, loss = 3.3950676918029785\n",
            "Epoch: 6350, weights = 0.8698174953460693, loss = 3.390958309173584\n",
            "Epoch: 6360, weights = 0.8711872100830078, loss = 3.3868491649627686\n",
            "Epoch: 6370, weights = 0.8725569248199463, loss = 3.382740020751953\n",
            "Epoch: 6380, weights = 0.8739266395568848, loss = 3.3786308765411377\n",
            "Epoch: 6390, weights = 0.8752963542938232, loss = 3.3745219707489014\n",
            "Epoch: 6400, weights = 0.8766660690307617, loss = 3.370412826538086\n",
            "Epoch: 6410, weights = 0.8780357837677002, loss = 3.3663036823272705\n",
            "Epoch: 6420, weights = 0.8794054985046387, loss = 3.362194538116455\n",
            "Epoch: 6430, weights = 0.8807752132415771, loss = 3.3580851554870605\n",
            "Epoch: 6440, weights = 0.8821449279785156, loss = 3.353976011276245\n",
            "Epoch: 6450, weights = 0.8835146427154541, loss = 3.3498668670654297\n",
            "Epoch: 6460, weights = 0.8848843574523926, loss = 3.3457577228546143\n",
            "Epoch: 6470, weights = 0.886254072189331, loss = 3.341648817062378\n",
            "Epoch: 6480, weights = 0.8876237869262695, loss = 3.3375396728515625\n",
            "Epoch: 6490, weights = 0.888993501663208, loss = 3.333430528640747\n",
            "Epoch: 6500, weights = 0.8903632164001465, loss = 3.3293213844299316\n",
            "Epoch: 6510, weights = 0.891732931137085, loss = 3.325212001800537\n",
            "Epoch: 6520, weights = 0.8931026458740234, loss = 3.3211028575897217\n",
            "Epoch: 6530, weights = 0.8944723606109619, loss = 3.3169937133789062\n",
            "Epoch: 6540, weights = 0.8958420753479004, loss = 3.312884569168091\n",
            "Epoch: 6550, weights = 0.8972117900848389, loss = 3.3087756633758545\n",
            "Epoch: 6560, weights = 0.8985815048217773, loss = 3.304666519165039\n",
            "Epoch: 6570, weights = 0.8999512195587158, loss = 3.3005573749542236\n",
            "Epoch: 6580, weights = 0.9013209342956543, loss = 3.296448230743408\n",
            "Epoch: 6590, weights = 0.9026906490325928, loss = 3.2923388481140137\n",
            "Epoch: 6600, weights = 0.9040603637695312, loss = 3.2882297039031982\n",
            "Epoch: 6610, weights = 0.9054300785064697, loss = 3.284120559692383\n",
            "Epoch: 6620, weights = 0.9067997932434082, loss = 3.2800114154815674\n",
            "Epoch: 6630, weights = 0.9081695079803467, loss = 3.275902509689331\n",
            "Epoch: 6640, weights = 0.9095392227172852, loss = 3.2717933654785156\n",
            "Epoch: 6650, weights = 0.9109089374542236, loss = 3.2676842212677\n",
            "Epoch: 6660, weights = 0.9122786521911621, loss = 3.2635750770568848\n",
            "Epoch: 6670, weights = 0.9136483669281006, loss = 3.2594656944274902\n",
            "Epoch: 6680, weights = 0.9150180816650391, loss = 3.255356550216675\n",
            "Epoch: 6690, weights = 0.9163877964019775, loss = 3.2512474060058594\n",
            "Epoch: 6700, weights = 0.917757511138916, loss = 3.247138261795044\n",
            "Epoch: 6710, weights = 0.9191272258758545, loss = 3.2430293560028076\n",
            "Epoch: 6720, weights = 0.920496940612793, loss = 3.238920211791992\n",
            "Epoch: 6730, weights = 0.9218666553497314, loss = 3.2348110675811768\n",
            "Epoch: 6740, weights = 0.9232363700866699, loss = 3.2307019233703613\n",
            "Epoch: 6750, weights = 0.9246060848236084, loss = 3.226592540740967\n",
            "Epoch: 6760, weights = 0.9259757995605469, loss = 3.2224833965301514\n",
            "Epoch: 6770, weights = 0.9273455142974854, loss = 3.218374252319336\n",
            "Epoch: 6780, weights = 0.9287152290344238, loss = 3.2142651081085205\n",
            "Epoch: 6790, weights = 0.9300849437713623, loss = 3.210156202316284\n",
            "Epoch: 6800, weights = 0.9314546585083008, loss = 3.2060470581054688\n",
            "Epoch: 6810, weights = 0.9328243732452393, loss = 3.2019379138946533\n",
            "Epoch: 6820, weights = 0.9341940879821777, loss = 3.197828769683838\n",
            "Epoch: 6830, weights = 0.9355638027191162, loss = 3.1937193870544434\n",
            "Epoch: 6840, weights = 0.9369335174560547, loss = 3.189610242843628\n",
            "Epoch: 6850, weights = 0.9383032321929932, loss = 3.1855010986328125\n",
            "Epoch: 6860, weights = 0.9396729469299316, loss = 3.181391954421997\n",
            "Epoch: 6870, weights = 0.9410426616668701, loss = 3.1772830486297607\n",
            "Epoch: 6880, weights = 0.9424123764038086, loss = 3.1731739044189453\n",
            "Epoch: 6890, weights = 0.9437820911407471, loss = 3.16906476020813\n",
            "Epoch: 6900, weights = 0.9451518058776855, loss = 3.1649556159973145\n",
            "Epoch: 6910, weights = 0.946521520614624, loss = 3.16084623336792\n",
            "Epoch: 6920, weights = 0.9478912353515625, loss = 3.1567370891571045\n",
            "Epoch: 6930, weights = 0.949260950088501, loss = 3.152627944946289\n",
            "Epoch: 6940, weights = 0.9506306648254395, loss = 3.1485188007354736\n",
            "Epoch: 6950, weights = 0.9520003795623779, loss = 3.1444098949432373\n",
            "Epoch: 6960, weights = 0.9533700942993164, loss = 3.140300750732422\n",
            "Epoch: 6970, weights = 0.9547398090362549, loss = 3.1361916065216064\n",
            "Epoch: 6980, weights = 0.9561095237731934, loss = 3.132082462310791\n",
            "Epoch: 6990, weights = 0.9574792385101318, loss = 3.1279730796813965\n",
            "Epoch: 7000, weights = 0.9588489532470703, loss = 3.123863935470581\n",
            "Epoch: 7010, weights = 0.9602186679840088, loss = 3.1197547912597656\n",
            "Epoch: 7020, weights = 0.9615883827209473, loss = 3.11564564704895\n",
            "Epoch: 7030, weights = 0.9629580974578857, loss = 3.111536741256714\n",
            "Epoch: 7040, weights = 0.9643278121948242, loss = 3.1074275970458984\n",
            "Epoch: 7050, weights = 0.9656975269317627, loss = 3.103318452835083\n",
            "Epoch: 7060, weights = 0.9670672416687012, loss = 3.0992093086242676\n",
            "Epoch: 7070, weights = 0.9684369564056396, loss = 3.095099925994873\n",
            "Epoch: 7080, weights = 0.9698066711425781, loss = 3.0909907817840576\n",
            "Epoch: 7090, weights = 0.9711763858795166, loss = 3.086881637573242\n",
            "Epoch: 7100, weights = 0.9725461006164551, loss = 3.0827724933624268\n",
            "Epoch: 7110, weights = 0.9739158153533936, loss = 3.0786635875701904\n",
            "Epoch: 7120, weights = 0.975285530090332, loss = 3.074554443359375\n",
            "Epoch: 7130, weights = 0.9766552448272705, loss = 3.0704452991485596\n",
            "Epoch: 7140, weights = 0.978024959564209, loss = 3.066336154937744\n",
            "Epoch: 7150, weights = 0.9793946743011475, loss = 3.0622267723083496\n",
            "Epoch: 7160, weights = 0.9807643890380859, loss = 3.058117628097534\n",
            "Epoch: 7170, weights = 0.9821341037750244, loss = 3.0540084838867188\n",
            "Epoch: 7180, weights = 0.9835038185119629, loss = 3.0498993396759033\n",
            "Epoch: 7190, weights = 0.9848735332489014, loss = 3.045790433883667\n",
            "Epoch: 7200, weights = 0.9862432479858398, loss = 3.0416812896728516\n",
            "Epoch: 7210, weights = 0.9876129627227783, loss = 3.037572145462036\n",
            "Epoch: 7220, weights = 0.9889826774597168, loss = 3.0334630012512207\n",
            "Epoch: 7230, weights = 0.9903523921966553, loss = 3.029353618621826\n",
            "Epoch: 7240, weights = 0.9917221069335938, loss = 3.0252444744110107\n",
            "Epoch: 7250, weights = 0.9930918216705322, loss = 3.0211353302001953\n",
            "Epoch: 7260, weights = 0.9944615364074707, loss = 3.01702618598938\n",
            "Epoch: 7270, weights = 0.9958312511444092, loss = 3.0129172801971436\n",
            "Epoch: 7280, weights = 0.9972009658813477, loss = 3.008808135986328\n",
            "Epoch: 7290, weights = 0.9985706806182861, loss = 3.0046989917755127\n",
            "Epoch: 7300, weights = 0.9999403953552246, loss = 3.0005898475646973\n",
            "Epoch: 7310, weights = 1.001310110092163, loss = 2.9964804649353027\n",
            "Epoch: 7320, weights = 1.0026798248291016, loss = 2.9923713207244873\n",
            "Epoch: 7330, weights = 1.00404953956604, loss = 2.988262176513672\n",
            "Epoch: 7340, weights = 1.0054192543029785, loss = 2.9841530323028564\n",
            "Epoch: 7350, weights = 1.006788969039917, loss = 2.98004412651062\n",
            "Epoch: 7360, weights = 1.0081586837768555, loss = 2.9759349822998047\n",
            "Epoch: 7370, weights = 1.009528398513794, loss = 2.9718258380889893\n",
            "Epoch: 7380, weights = 1.0108981132507324, loss = 2.967716693878174\n",
            "Epoch: 7390, weights = 1.012267827987671, loss = 2.9636073112487793\n",
            "Epoch: 7400, weights = 1.0136375427246094, loss = 2.959498167037964\n",
            "Epoch: 7410, weights = 1.0150072574615479, loss = 2.9553890228271484\n",
            "Epoch: 7420, weights = 1.0163769721984863, loss = 2.951279878616333\n",
            "Epoch: 7430, weights = 1.0177466869354248, loss = 2.9471709728240967\n",
            "Epoch: 7440, weights = 1.0191164016723633, loss = 2.9430618286132812\n",
            "Epoch: 7450, weights = 1.0204861164093018, loss = 2.938952684402466\n",
            "Epoch: 7460, weights = 1.0218558311462402, loss = 2.9348435401916504\n",
            "Epoch: 7470, weights = 1.0232255458831787, loss = 2.930734157562256\n",
            "Epoch: 7480, weights = 1.0245952606201172, loss = 2.9266250133514404\n",
            "Epoch: 7490, weights = 1.0259649753570557, loss = 2.922515869140625\n",
            "Epoch: 7500, weights = 1.0273346900939941, loss = 2.9184067249298096\n",
            "Epoch: 7510, weights = 1.0287044048309326, loss = 2.9142978191375732\n",
            "Epoch: 7520, weights = 1.030074119567871, loss = 2.910188674926758\n",
            "Epoch: 7530, weights = 1.0314438343048096, loss = 2.9060795307159424\n",
            "Epoch: 7540, weights = 1.032813549041748, loss = 2.901970386505127\n",
            "Epoch: 7550, weights = 1.0341832637786865, loss = 2.8978610038757324\n",
            "Epoch: 7560, weights = 1.035552978515625, loss = 2.893751859664917\n",
            "Epoch: 7570, weights = 1.0369226932525635, loss = 2.8896427154541016\n",
            "Epoch: 7580, weights = 1.038292407989502, loss = 2.885533571243286\n",
            "Epoch: 7590, weights = 1.0396621227264404, loss = 2.88142466545105\n",
            "Epoch: 7600, weights = 1.041031837463379, loss = 2.8773155212402344\n",
            "Epoch: 7610, weights = 1.0424015522003174, loss = 2.873206377029419\n",
            "Epoch: 7620, weights = 1.0437712669372559, loss = 2.8690972328186035\n",
            "Epoch: 7630, weights = 1.0451409816741943, loss = 2.864987850189209\n",
            "Epoch: 7640, weights = 1.0465106964111328, loss = 2.8608787059783936\n",
            "Epoch: 7650, weights = 1.0478804111480713, loss = 2.856769561767578\n",
            "Epoch: 7660, weights = 1.0492501258850098, loss = 2.8526604175567627\n",
            "Epoch: 7670, weights = 1.0506198406219482, loss = 2.8485515117645264\n",
            "Epoch: 7680, weights = 1.0519895553588867, loss = 2.844442367553711\n",
            "Epoch: 7690, weights = 1.0533592700958252, loss = 2.8403332233428955\n",
            "Epoch: 7700, weights = 1.0547289848327637, loss = 2.83622407913208\n",
            "Epoch: 7710, weights = 1.0560986995697021, loss = 2.8321146965026855\n",
            "Epoch: 7720, weights = 1.0574684143066406, loss = 2.82800555229187\n",
            "Epoch: 7730, weights = 1.058838129043579, loss = 2.8238964080810547\n",
            "Epoch: 7740, weights = 1.0602078437805176, loss = 2.8197872638702393\n",
            "Epoch: 7750, weights = 1.061577558517456, loss = 2.815678358078003\n",
            "Epoch: 7760, weights = 1.0629472732543945, loss = 2.8115692138671875\n",
            "Epoch: 7770, weights = 1.064316987991333, loss = 2.807460069656372\n",
            "Epoch: 7780, weights = 1.0656867027282715, loss = 2.8033509254455566\n",
            "Epoch: 7790, weights = 1.06705641746521, loss = 2.799241542816162\n",
            "Epoch: 7800, weights = 1.0684261322021484, loss = 2.7951323986053467\n",
            "Epoch: 7810, weights = 1.069795846939087, loss = 2.7910232543945312\n",
            "Epoch: 7820, weights = 1.0711655616760254, loss = 2.786914110183716\n",
            "Epoch: 7830, weights = 1.0725352764129639, loss = 2.7828052043914795\n",
            "Epoch: 7840, weights = 1.0739049911499023, loss = 2.778696060180664\n",
            "Epoch: 7850, weights = 1.0752747058868408, loss = 2.7745869159698486\n",
            "Epoch: 7860, weights = 1.0766444206237793, loss = 2.770477771759033\n",
            "Epoch: 7870, weights = 1.0780141353607178, loss = 2.7663683891296387\n",
            "Epoch: 7880, weights = 1.0793838500976562, loss = 2.7622592449188232\n",
            "Epoch: 7890, weights = 1.0807535648345947, loss = 2.758150100708008\n",
            "Epoch: 7900, weights = 1.0821232795715332, loss = 2.7540409564971924\n",
            "Epoch: 7910, weights = 1.0834929943084717, loss = 2.749932050704956\n",
            "Epoch: 7920, weights = 1.0848627090454102, loss = 2.7458229064941406\n",
            "Epoch: 7930, weights = 1.0862324237823486, loss = 2.741713762283325\n",
            "Epoch: 7940, weights = 1.087602138519287, loss = 2.7376046180725098\n",
            "Epoch: 7950, weights = 1.0889718532562256, loss = 2.7334952354431152\n",
            "Epoch: 7960, weights = 1.090341567993164, loss = 2.7293860912323\n",
            "Epoch: 7970, weights = 1.0917112827301025, loss = 2.7252769470214844\n",
            "Epoch: 7980, weights = 1.093080997467041, loss = 2.721167802810669\n",
            "Epoch: 7990, weights = 1.0944507122039795, loss = 2.7170588970184326\n",
            "Epoch: 8000, weights = 1.095820426940918, loss = 2.712949752807617\n",
            "Epoch: 8010, weights = 1.0971901416778564, loss = 2.7088406085968018\n",
            "Epoch: 8020, weights = 1.098559856414795, loss = 2.7047314643859863\n",
            "Epoch: 8030, weights = 1.0999295711517334, loss = 2.700622081756592\n",
            "Epoch: 8040, weights = 1.1012992858886719, loss = 2.6965129375457764\n",
            "Epoch: 8050, weights = 1.1026690006256104, loss = 2.692403793334961\n",
            "Epoch: 8060, weights = 1.1040387153625488, loss = 2.6882946491241455\n",
            "Epoch: 8070, weights = 1.1054084300994873, loss = 2.684185743331909\n",
            "Epoch: 8080, weights = 1.1067781448364258, loss = 2.6800765991210938\n",
            "Epoch: 8090, weights = 1.1081478595733643, loss = 2.6759674549102783\n",
            "Epoch: 8100, weights = 1.1095175743103027, loss = 2.671858310699463\n",
            "Epoch: 8110, weights = 1.1108872890472412, loss = 2.6677489280700684\n",
            "Epoch: 8120, weights = 1.1122570037841797, loss = 2.663639783859253\n",
            "Epoch: 8130, weights = 1.1136267185211182, loss = 2.6595306396484375\n",
            "Epoch: 8140, weights = 1.1149964332580566, loss = 2.655421495437622\n",
            "Epoch: 8150, weights = 1.1163661479949951, loss = 2.6513125896453857\n",
            "Epoch: 8160, weights = 1.1177358627319336, loss = 2.6472034454345703\n",
            "Epoch: 8170, weights = 1.119105577468872, loss = 2.643094301223755\n",
            "Epoch: 8180, weights = 1.1204752922058105, loss = 2.6389851570129395\n",
            "Epoch: 8190, weights = 1.121845006942749, loss = 2.634875774383545\n",
            "Epoch: 8200, weights = 1.1232147216796875, loss = 2.6307666301727295\n",
            "Epoch: 8210, weights = 1.124584436416626, loss = 2.626657485961914\n",
            "Epoch: 8220, weights = 1.1259541511535645, loss = 2.6225483417510986\n",
            "Epoch: 8230, weights = 1.127323865890503, loss = 2.6184394359588623\n",
            "Epoch: 8240, weights = 1.1286935806274414, loss = 2.614330291748047\n",
            "Epoch: 8250, weights = 1.1300632953643799, loss = 2.6102211475372314\n",
            "Epoch: 8260, weights = 1.1314330101013184, loss = 2.606112003326416\n",
            "Epoch: 8270, weights = 1.1328027248382568, loss = 2.6020026206970215\n",
            "Epoch: 8280, weights = 1.1341724395751953, loss = 2.597893476486206\n",
            "Epoch: 8290, weights = 1.1355421543121338, loss = 2.5937843322753906\n",
            "Epoch: 8300, weights = 1.1369118690490723, loss = 2.589675188064575\n",
            "Epoch: 8310, weights = 1.1382815837860107, loss = 2.585566282272339\n",
            "Epoch: 8320, weights = 1.1396512985229492, loss = 2.5814571380615234\n",
            "Epoch: 8330, weights = 1.1410210132598877, loss = 2.577347993850708\n",
            "Epoch: 8340, weights = 1.1423907279968262, loss = 2.5732388496398926\n",
            "Epoch: 8350, weights = 1.1437604427337646, loss = 2.569129467010498\n",
            "Epoch: 8360, weights = 1.1451301574707031, loss = 2.5650203227996826\n",
            "Epoch: 8370, weights = 1.1464998722076416, loss = 2.560911178588867\n",
            "Epoch: 8380, weights = 1.14786958694458, loss = 2.5568020343780518\n",
            "Epoch: 8390, weights = 1.1492393016815186, loss = 2.5526931285858154\n",
            "Epoch: 8400, weights = 1.150609016418457, loss = 2.548583984375\n",
            "Epoch: 8410, weights = 1.1519787311553955, loss = 2.5444748401641846\n",
            "Epoch: 8420, weights = 1.153348445892334, loss = 2.540365695953369\n",
            "Epoch: 8430, weights = 1.1547181606292725, loss = 2.5362563133239746\n",
            "Epoch: 8440, weights = 1.156087875366211, loss = 2.532147169113159\n",
            "Epoch: 8450, weights = 1.1574575901031494, loss = 2.5280380249023438\n",
            "Epoch: 8460, weights = 1.158827304840088, loss = 2.5239288806915283\n",
            "Epoch: 8470, weights = 1.1601970195770264, loss = 2.519819974899292\n",
            "Epoch: 8480, weights = 1.1615667343139648, loss = 2.5157108306884766\n",
            "Epoch: 8490, weights = 1.1629364490509033, loss = 2.511601686477661\n",
            "Epoch: 8500, weights = 1.1643061637878418, loss = 2.5074925422668457\n",
            "Epoch: 8510, weights = 1.1656758785247803, loss = 2.503383159637451\n",
            "Epoch: 8520, weights = 1.1670455932617188, loss = 2.4992740154266357\n",
            "Epoch: 8530, weights = 1.1684153079986572, loss = 2.4951648712158203\n",
            "Epoch: 8540, weights = 1.1697850227355957, loss = 2.491055727005005\n",
            "Epoch: 8550, weights = 1.1711547374725342, loss = 2.4869468212127686\n",
            "Epoch: 8560, weights = 1.1725244522094727, loss = 2.482837677001953\n",
            "Epoch: 8570, weights = 1.1738941669464111, loss = 2.4787285327911377\n",
            "Epoch: 8580, weights = 1.1752638816833496, loss = 2.4746193885803223\n",
            "Epoch: 8590, weights = 1.176633596420288, loss = 2.4705100059509277\n",
            "Epoch: 8600, weights = 1.1780033111572266, loss = 2.4664008617401123\n",
            "Epoch: 8610, weights = 1.179373025894165, loss = 2.462291717529297\n",
            "Epoch: 8620, weights = 1.1807427406311035, loss = 2.4581825733184814\n",
            "Epoch: 8630, weights = 1.182112455368042, loss = 2.454073667526245\n",
            "Epoch: 8640, weights = 1.1834821701049805, loss = 2.4499645233154297\n",
            "Epoch: 8650, weights = 1.184851884841919, loss = 2.4458553791046143\n",
            "Epoch: 8660, weights = 1.1862215995788574, loss = 2.441746234893799\n",
            "Epoch: 8670, weights = 1.187591314315796, loss = 2.4376368522644043\n",
            "Epoch: 8680, weights = 1.1889610290527344, loss = 2.433527708053589\n",
            "Epoch: 8690, weights = 1.1903307437896729, loss = 2.4294185638427734\n",
            "Epoch: 8700, weights = 1.1917004585266113, loss = 2.425309419631958\n",
            "Epoch: 8710, weights = 1.1930701732635498, loss = 2.4212005138397217\n",
            "Epoch: 8720, weights = 1.1944398880004883, loss = 2.4170913696289062\n",
            "Epoch: 8730, weights = 1.1958096027374268, loss = 2.412982225418091\n",
            "Epoch: 8740, weights = 1.1971793174743652, loss = 2.4088730812072754\n",
            "Epoch: 8750, weights = 1.1985490322113037, loss = 2.404763698577881\n",
            "Epoch: 8760, weights = 1.1999187469482422, loss = 2.4006545543670654\n",
            "Epoch: 8770, weights = 1.2012884616851807, loss = 2.39654541015625\n",
            "Epoch: 8780, weights = 1.2026581764221191, loss = 2.3924362659454346\n",
            "Epoch: 8790, weights = 1.2040278911590576, loss = 2.3883273601531982\n",
            "Epoch: 8800, weights = 1.205397605895996, loss = 2.384218215942383\n",
            "Epoch: 8810, weights = 1.2067673206329346, loss = 2.3801090717315674\n",
            "Epoch: 8820, weights = 1.208137035369873, loss = 2.375999927520752\n",
            "Epoch: 8830, weights = 1.2095067501068115, loss = 2.3718905448913574\n",
            "Epoch: 8840, weights = 1.21087646484375, loss = 2.367781400680542\n",
            "Epoch: 8850, weights = 1.2122461795806885, loss = 2.3636722564697266\n",
            "Epoch: 8860, weights = 1.213615894317627, loss = 2.359563112258911\n",
            "Epoch: 8870, weights = 1.2149856090545654, loss = 2.355454206466675\n",
            "Epoch: 8880, weights = 1.216355323791504, loss = 2.3513450622558594\n",
            "Epoch: 8890, weights = 1.2177250385284424, loss = 2.347235918045044\n",
            "Epoch: 8900, weights = 1.2190947532653809, loss = 2.3431267738342285\n",
            "Epoch: 8910, weights = 1.2204644680023193, loss = 2.339017391204834\n",
            "Epoch: 8920, weights = 1.2218341827392578, loss = 2.3349082469940186\n",
            "Epoch: 8930, weights = 1.2232038974761963, loss = 2.330799102783203\n",
            "Epoch: 8940, weights = 1.2245736122131348, loss = 2.3266899585723877\n",
            "Epoch: 8950, weights = 1.2259433269500732, loss = 2.3225810527801514\n",
            "Epoch: 8960, weights = 1.2273130416870117, loss = 2.318471908569336\n",
            "Epoch: 8970, weights = 1.2286827564239502, loss = 2.3143627643585205\n",
            "Epoch: 8980, weights = 1.2300524711608887, loss = 2.310253620147705\n",
            "Epoch: 8990, weights = 1.2314221858978271, loss = 2.3061442375183105\n",
            "Epoch: 9000, weights = 1.2327919006347656, loss = 2.302035093307495\n",
            "Epoch: 9010, weights = 1.234161615371704, loss = 2.2979259490966797\n",
            "Epoch: 9020, weights = 1.2355313301086426, loss = 2.2938168048858643\n",
            "Epoch: 9030, weights = 1.236901044845581, loss = 2.289707899093628\n",
            "Epoch: 9040, weights = 1.2382707595825195, loss = 2.2855987548828125\n",
            "Epoch: 9050, weights = 1.239640474319458, loss = 2.281489610671997\n",
            "Epoch: 9060, weights = 1.2410101890563965, loss = 2.2773804664611816\n",
            "Epoch: 9070, weights = 1.242379903793335, loss = 2.273271083831787\n",
            "Epoch: 9080, weights = 1.2437496185302734, loss = 2.2691619396209717\n",
            "Epoch: 9090, weights = 1.245119333267212, loss = 2.2650527954101562\n",
            "Epoch: 9100, weights = 1.2464890480041504, loss = 2.260943651199341\n",
            "Epoch: 9110, weights = 1.2478587627410889, loss = 2.2568347454071045\n",
            "Epoch: 9120, weights = 1.2492284774780273, loss = 2.252725601196289\n",
            "Epoch: 9130, weights = 1.2505981922149658, loss = 2.2486164569854736\n",
            "Epoch: 9140, weights = 1.2519679069519043, loss = 2.244507312774658\n",
            "Epoch: 9150, weights = 1.2533376216888428, loss = 2.2403979301452637\n",
            "Epoch: 9160, weights = 1.2547073364257812, loss = 2.2362887859344482\n",
            "Epoch: 9170, weights = 1.2560770511627197, loss = 2.232179641723633\n",
            "Epoch: 9180, weights = 1.2574467658996582, loss = 2.2280704975128174\n",
            "Epoch: 9190, weights = 1.2588164806365967, loss = 2.223961591720581\n",
            "Epoch: 9200, weights = 1.2601861953735352, loss = 2.2198524475097656\n",
            "Epoch: 9210, weights = 1.2615559101104736, loss = 2.21574330329895\n",
            "Epoch: 9220, weights = 1.262925624847412, loss = 2.2116341590881348\n",
            "Epoch: 9230, weights = 1.2642953395843506, loss = 2.2075247764587402\n",
            "Epoch: 9240, weights = 1.265665054321289, loss = 2.203415632247925\n",
            "Epoch: 9250, weights = 1.2670347690582275, loss = 2.1993064880371094\n",
            "Epoch: 9260, weights = 1.268404483795166, loss = 2.195197343826294\n",
            "Epoch: 9270, weights = 1.2697741985321045, loss = 2.1910884380340576\n",
            "Epoch: 9280, weights = 1.271143913269043, loss = 2.186979293823242\n",
            "Epoch: 9290, weights = 1.2725136280059814, loss = 2.1828701496124268\n",
            "Epoch: 9300, weights = 1.27388334274292, loss = 2.1787610054016113\n",
            "Epoch: 9310, weights = 1.2752530574798584, loss = 2.174651622772217\n",
            "Epoch: 9320, weights = 1.2766227722167969, loss = 2.1705424785614014\n",
            "Epoch: 9330, weights = 1.2779924869537354, loss = 2.166433334350586\n",
            "Epoch: 9340, weights = 1.2793622016906738, loss = 2.1623244285583496\n",
            "Epoch: 9350, weights = 1.2807319164276123, loss = 2.158215045928955\n",
            "Epoch: 9360, weights = 1.2821016311645508, loss = 2.1541061401367188\n",
            "Epoch: 9370, weights = 1.2834713459014893, loss = 2.1499969959259033\n",
            "Epoch: 9380, weights = 1.2848410606384277, loss = 2.145887851715088\n",
            "Epoch: 9390, weights = 1.2862107753753662, loss = 2.1417784690856934\n",
            "Epoch: 9400, weights = 1.2875804901123047, loss = 2.137669324874878\n",
            "Epoch: 9410, weights = 1.2889502048492432, loss = 2.1335601806640625\n",
            "Epoch: 9420, weights = 1.2903199195861816, loss = 2.129451274871826\n",
            "Epoch: 9430, weights = 1.2916896343231201, loss = 2.1253418922424316\n",
            "Epoch: 9440, weights = 1.2930593490600586, loss = 2.1212329864501953\n",
            "Epoch: 9450, weights = 1.294429063796997, loss = 2.11712384223938\n",
            "Epoch: 9460, weights = 1.2957987785339355, loss = 2.1130146980285645\n",
            "Epoch: 9470, weights = 1.297168493270874, loss = 2.10890531539917\n",
            "Epoch: 9480, weights = 1.2985382080078125, loss = 2.1047961711883545\n",
            "Epoch: 9490, weights = 1.299907922744751, loss = 2.100687026977539\n",
            "Epoch: 9500, weights = 1.3012776374816895, loss = 2.0965781211853027\n",
            "Epoch: 9510, weights = 1.302647352218628, loss = 2.092468738555908\n",
            "Epoch: 9520, weights = 1.3040170669555664, loss = 2.088359832763672\n",
            "Epoch: 9530, weights = 1.3053867816925049, loss = 2.0842506885528564\n",
            "Epoch: 9540, weights = 1.3067564964294434, loss = 2.080141544342041\n",
            "Epoch: 9550, weights = 1.3081262111663818, loss = 2.0760321617126465\n",
            "Epoch: 9560, weights = 1.3094959259033203, loss = 2.071923017501831\n",
            "Epoch: 9570, weights = 1.3108656406402588, loss = 2.0678138732910156\n",
            "Epoch: 9580, weights = 1.3122353553771973, loss = 2.0637049674987793\n",
            "Epoch: 9590, weights = 1.3136050701141357, loss = 2.0595955848693848\n",
            "Epoch: 9600, weights = 1.3149747848510742, loss = 2.0554866790771484\n",
            "Epoch: 9610, weights = 1.3163444995880127, loss = 2.051377534866333\n",
            "Epoch: 9620, weights = 1.3177142143249512, loss = 2.0472683906555176\n",
            "Epoch: 9630, weights = 1.3190839290618896, loss = 2.043159008026123\n",
            "Epoch: 9640, weights = 1.3204536437988281, loss = 2.0390498638153076\n",
            "Epoch: 9650, weights = 1.3218233585357666, loss = 2.034940719604492\n",
            "Epoch: 9660, weights = 1.323193073272705, loss = 2.030831813812256\n",
            "Epoch: 9670, weights = 1.3245627880096436, loss = 2.0267224311828613\n",
            "Epoch: 9680, weights = 1.325932502746582, loss = 2.022613525390625\n",
            "Epoch: 9690, weights = 1.3273022174835205, loss = 2.0185043811798096\n",
            "Epoch: 9700, weights = 1.328671932220459, loss = 2.014395236968994\n",
            "Epoch: 9710, weights = 1.3300416469573975, loss = 2.0102858543395996\n",
            "Epoch: 9720, weights = 1.331411361694336, loss = 2.006176710128784\n",
            "Epoch: 9730, weights = 1.3327810764312744, loss = 2.0020675659179688\n",
            "Epoch: 9740, weights = 1.334150791168213, loss = 1.9979585409164429\n",
            "Epoch: 9750, weights = 1.3355205059051514, loss = 1.9938493967056274\n",
            "Epoch: 9760, weights = 1.3368902206420898, loss = 1.9897403717041016\n",
            "Epoch: 9770, weights = 1.3382599353790283, loss = 1.9856312274932861\n",
            "Epoch: 9780, weights = 1.3396296501159668, loss = 1.9815219640731812\n",
            "Epoch: 9790, weights = 1.3409993648529053, loss = 1.9774128198623657\n",
            "Epoch: 9800, weights = 1.3423690795898438, loss = 1.9733035564422607\n",
            "Epoch: 9810, weights = 1.3437387943267822, loss = 1.9691944122314453\n",
            "Epoch: 9820, weights = 1.3451085090637207, loss = 1.9650853872299194\n",
            "Epoch: 9830, weights = 1.3464782238006592, loss = 1.960976243019104\n",
            "Epoch: 9840, weights = 1.3478479385375977, loss = 1.9568672180175781\n",
            "Epoch: 9850, weights = 1.3492176532745361, loss = 1.9527580738067627\n",
            "Epoch: 9860, weights = 1.3505873680114746, loss = 1.9486488103866577\n",
            "Epoch: 9870, weights = 1.351957082748413, loss = 1.9445396661758423\n",
            "Epoch: 9880, weights = 1.3533267974853516, loss = 1.9404304027557373\n",
            "Epoch: 9890, weights = 1.35469651222229, loss = 1.9363212585449219\n",
            "Epoch: 9900, weights = 1.3560662269592285, loss = 1.932212233543396\n",
            "Epoch: 9910, weights = 1.357435941696167, loss = 1.9281030893325806\n",
            "Epoch: 9920, weights = 1.3588056564331055, loss = 1.9239940643310547\n",
            "Epoch: 9930, weights = 1.360175371170044, loss = 1.9198849201202393\n",
            "Epoch: 9940, weights = 1.3615450859069824, loss = 1.9157756567001343\n",
            "Epoch: 9950, weights = 1.362914800643921, loss = 1.9116665124893188\n",
            "Epoch: 9960, weights = 1.3642845153808594, loss = 1.9075572490692139\n",
            "Epoch: 9970, weights = 1.3656542301177979, loss = 1.9034481048583984\n",
            "Epoch: 9980, weights = 1.3670239448547363, loss = 1.8993390798568726\n",
            "Epoch: 9990, weights = 1.3683936595916748, loss = 1.8952299356460571\n",
            "Epoch: 10000, weights = 1.3697633743286133, loss = 1.8911209106445312\n",
            "Epoch: 10010, weights = 1.3711330890655518, loss = 1.8870117664337158\n",
            "Epoch: 10020, weights = 1.3725028038024902, loss = 1.8829025030136108\n",
            "Epoch: 10030, weights = 1.3738725185394287, loss = 1.8787933588027954\n",
            "Epoch: 10040, weights = 1.3752422332763672, loss = 1.8746840953826904\n",
            "Epoch: 10050, weights = 1.3766119480133057, loss = 1.870574951171875\n",
            "Epoch: 10060, weights = 1.3779816627502441, loss = 1.8664659261703491\n",
            "Epoch: 10070, weights = 1.3793513774871826, loss = 1.8623567819595337\n",
            "Epoch: 10080, weights = 1.380721092224121, loss = 1.8582477569580078\n",
            "Epoch: 10090, weights = 1.3820908069610596, loss = 1.8541386127471924\n",
            "Epoch: 10100, weights = 1.383460521697998, loss = 1.8500293493270874\n",
            "Epoch: 10110, weights = 1.3848302364349365, loss = 1.845920205116272\n",
            "Epoch: 10120, weights = 1.386199951171875, loss = 1.841810941696167\n",
            "Epoch: 10130, weights = 1.3875696659088135, loss = 1.8377017974853516\n",
            "Epoch: 10140, weights = 1.388939380645752, loss = 1.8335927724838257\n",
            "Epoch: 10150, weights = 1.3903090953826904, loss = 1.8294836282730103\n",
            "Epoch: 10160, weights = 1.391678810119629, loss = 1.8253746032714844\n",
            "Epoch: 10170, weights = 1.3930485248565674, loss = 1.821265459060669\n",
            "Epoch: 10180, weights = 1.3944182395935059, loss = 1.817156195640564\n",
            "Epoch: 10190, weights = 1.3957879543304443, loss = 1.8130470514297485\n",
            "Epoch: 10200, weights = 1.3971576690673828, loss = 1.8089377880096436\n",
            "Epoch: 10210, weights = 1.3985273838043213, loss = 1.8048286437988281\n",
            "Epoch: 10220, weights = 1.3998970985412598, loss = 1.8007196187973022\n",
            "Epoch: 10230, weights = 1.4012668132781982, loss = 1.7966104745864868\n",
            "Epoch: 10240, weights = 1.4026365280151367, loss = 1.792501449584961\n",
            "Epoch: 10250, weights = 1.4040062427520752, loss = 1.7883923053741455\n",
            "Epoch: 10260, weights = 1.4053759574890137, loss = 1.7842830419540405\n",
            "Epoch: 10270, weights = 1.4067456722259521, loss = 1.780173897743225\n",
            "Epoch: 10280, weights = 1.4081153869628906, loss = 1.7760646343231201\n",
            "Epoch: 10290, weights = 1.409485101699829, loss = 1.7719554901123047\n",
            "Epoch: 10300, weights = 1.4108548164367676, loss = 1.7678464651107788\n",
            "Epoch: 10310, weights = 1.412224531173706, loss = 1.7637373208999634\n",
            "Epoch: 10320, weights = 1.4135942459106445, loss = 1.7596282958984375\n",
            "Epoch: 10330, weights = 1.414963960647583, loss = 1.755519151687622\n",
            "Epoch: 10340, weights = 1.4163336753845215, loss = 1.751409888267517\n",
            "Epoch: 10350, weights = 1.41770339012146, loss = 1.7473007440567017\n",
            "Epoch: 10360, weights = 1.4190731048583984, loss = 1.7431914806365967\n",
            "Epoch: 10370, weights = 1.420442819595337, loss = 1.7390823364257812\n",
            "Epoch: 10380, weights = 1.4218125343322754, loss = 1.7349733114242554\n",
            "Epoch: 10390, weights = 1.4231822490692139, loss = 1.73086416721344\n",
            "Epoch: 10400, weights = 1.4245519638061523, loss = 1.726755142211914\n",
            "Epoch: 10410, weights = 1.4259216785430908, loss = 1.7226459980010986\n",
            "Epoch: 10420, weights = 1.4272913932800293, loss = 1.7185367345809937\n",
            "Epoch: 10430, weights = 1.4286611080169678, loss = 1.7144275903701782\n",
            "Epoch: 10440, weights = 1.4300308227539062, loss = 1.7103183269500732\n",
            "Epoch: 10450, weights = 1.4314005374908447, loss = 1.7062091827392578\n",
            "Epoch: 10460, weights = 1.4327702522277832, loss = 1.702100157737732\n",
            "Epoch: 10470, weights = 1.4341399669647217, loss = 1.6979910135269165\n",
            "Epoch: 10480, weights = 1.4355096817016602, loss = 1.6938819885253906\n",
            "Epoch: 10490, weights = 1.4368793964385986, loss = 1.6897728443145752\n",
            "Epoch: 10500, weights = 1.438249111175537, loss = 1.6856635808944702\n",
            "Epoch: 10510, weights = 1.4396188259124756, loss = 1.6815544366836548\n",
            "Epoch: 10520, weights = 1.440988540649414, loss = 1.6774451732635498\n",
            "Epoch: 10530, weights = 1.4423582553863525, loss = 1.6733360290527344\n",
            "Epoch: 10540, weights = 1.443727970123291, loss = 1.6692270040512085\n",
            "Epoch: 10550, weights = 1.4450976848602295, loss = 1.665117859840393\n",
            "Epoch: 10560, weights = 1.446467399597168, loss = 1.6610088348388672\n",
            "Epoch: 10570, weights = 1.4478371143341064, loss = 1.6568996906280518\n",
            "Epoch: 10580, weights = 1.449206829071045, loss = 1.6527904272079468\n",
            "Epoch: 10590, weights = 1.4505765438079834, loss = 1.6486812829971313\n",
            "Epoch: 10600, weights = 1.4519462585449219, loss = 1.6445720195770264\n",
            "Epoch: 10610, weights = 1.4533159732818604, loss = 1.640462875366211\n",
            "Epoch: 10620, weights = 1.4546856880187988, loss = 1.636353850364685\n",
            "Epoch: 10630, weights = 1.4560554027557373, loss = 1.6322447061538696\n",
            "Epoch: 10640, weights = 1.4574251174926758, loss = 1.6281356811523438\n",
            "Epoch: 10650, weights = 1.4587948322296143, loss = 1.6240265369415283\n",
            "Epoch: 10660, weights = 1.4601645469665527, loss = 1.6199172735214233\n",
            "Epoch: 10670, weights = 1.4615342617034912, loss = 1.615808129310608\n",
            "Epoch: 10680, weights = 1.4629039764404297, loss = 1.611698865890503\n",
            "Epoch: 10690, weights = 1.4642736911773682, loss = 1.6075897216796875\n",
            "Epoch: 10700, weights = 1.4656434059143066, loss = 1.6034806966781616\n",
            "Epoch: 10710, weights = 1.4670131206512451, loss = 1.5993715524673462\n",
            "Epoch: 10720, weights = 1.4683828353881836, loss = 1.5952624082565308\n",
            "Epoch: 10730, weights = 1.469752550125122, loss = 1.5911532640457153\n",
            "Epoch: 10740, weights = 1.4711222648620605, loss = 1.5870441198349\n",
            "Epoch: 10750, weights = 1.472491979598999, loss = 1.5829349756240845\n",
            "Epoch: 10760, weights = 1.4738616943359375, loss = 1.578825831413269\n",
            "Epoch: 10770, weights = 1.475231409072876, loss = 1.5747166872024536\n",
            "Epoch: 10780, weights = 1.4766011238098145, loss = 1.5706075429916382\n",
            "Epoch: 10790, weights = 1.477970838546753, loss = 1.5664983987808228\n",
            "Epoch: 10800, weights = 1.4793405532836914, loss = 1.5623892545700073\n",
            "Epoch: 10810, weights = 1.4807102680206299, loss = 1.558280110359192\n",
            "Epoch: 10820, weights = 1.4820799827575684, loss = 1.5541709661483765\n",
            "Epoch: 10830, weights = 1.4834496974945068, loss = 1.550061821937561\n",
            "Epoch: 10840, weights = 1.4848194122314453, loss = 1.5459526777267456\n",
            "Epoch: 10850, weights = 1.4861891269683838, loss = 1.5418435335159302\n",
            "Epoch: 10860, weights = 1.4875588417053223, loss = 1.5377343893051147\n",
            "Epoch: 10870, weights = 1.4889285564422607, loss = 1.5336252450942993\n",
            "Epoch: 10880, weights = 1.4902982711791992, loss = 1.5295161008834839\n",
            "Epoch: 10890, weights = 1.4916679859161377, loss = 1.5254069566726685\n",
            "Epoch: 10900, weights = 1.4930377006530762, loss = 1.521297812461853\n",
            "Epoch: 10910, weights = 1.4944074153900146, loss = 1.5171886682510376\n",
            "Epoch: 10920, weights = 1.4957771301269531, loss = 1.5130795240402222\n",
            "Epoch: 10930, weights = 1.4971468448638916, loss = 1.5089703798294067\n",
            "Epoch: 10940, weights = 1.49851655960083, loss = 1.5048612356185913\n",
            "Epoch: 10950, weights = 1.4998862743377686, loss = 1.5007520914077759\n",
            "Epoch: 10960, weights = 1.501255989074707, loss = 1.4966429471969604\n",
            "Epoch: 10970, weights = 1.5026257038116455, loss = 1.492533802986145\n",
            "Epoch: 10980, weights = 1.503995418548584, loss = 1.48842453956604\n",
            "Epoch: 10990, weights = 1.5053651332855225, loss = 1.4843156337738037\n",
            "Epoch: 11000, weights = 1.506734848022461, loss = 1.4802063703536987\n",
            "Epoch: 11010, weights = 1.5081045627593994, loss = 1.4760972261428833\n",
            "Epoch: 11020, weights = 1.509474277496338, loss = 1.4719879627227783\n",
            "Epoch: 11030, weights = 1.5108439922332764, loss = 1.467879056930542\n",
            "Epoch: 11040, weights = 1.5122137069702148, loss = 1.463769793510437\n",
            "Epoch: 11050, weights = 1.5135834217071533, loss = 1.4596606492996216\n",
            "Epoch: 11060, weights = 1.5149531364440918, loss = 1.4555513858795166\n",
            "Epoch: 11070, weights = 1.5163228511810303, loss = 1.4514424800872803\n",
            "Epoch: 11080, weights = 1.5176925659179688, loss = 1.4473332166671753\n",
            "Epoch: 11090, weights = 1.5190622806549072, loss = 1.4432240724563599\n",
            "Epoch: 11100, weights = 1.5204319953918457, loss = 1.4391148090362549\n",
            "Epoch: 11110, weights = 1.5218017101287842, loss = 1.4350059032440186\n",
            "Epoch: 11120, weights = 1.5231714248657227, loss = 1.4308966398239136\n",
            "Epoch: 11130, weights = 1.5245411396026611, loss = 1.4267874956130981\n",
            "Epoch: 11140, weights = 1.5259108543395996, loss = 1.4226782321929932\n",
            "Epoch: 11150, weights = 1.527280569076538, loss = 1.4185693264007568\n",
            "Epoch: 11160, weights = 1.5286502838134766, loss = 1.4144600629806519\n",
            "Epoch: 11170, weights = 1.530019998550415, loss = 1.4103509187698364\n",
            "Epoch: 11180, weights = 1.5313897132873535, loss = 1.4062416553497314\n",
            "Epoch: 11190, weights = 1.532759428024292, loss = 1.4021327495574951\n",
            "Epoch: 11200, weights = 1.5341291427612305, loss = 1.3980234861373901\n",
            "Epoch: 11210, weights = 1.535498857498169, loss = 1.3939143419265747\n",
            "Epoch: 11220, weights = 1.5368685722351074, loss = 1.3898050785064697\n",
            "Epoch: 11230, weights = 1.538238286972046, loss = 1.3856961727142334\n",
            "Epoch: 11240, weights = 1.5396080017089844, loss = 1.3815869092941284\n",
            "Epoch: 11250, weights = 1.5409777164459229, loss = 1.377477765083313\n",
            "Epoch: 11260, weights = 1.5423474311828613, loss = 1.373368501663208\n",
            "Epoch: 11270, weights = 1.5437171459197998, loss = 1.3692595958709717\n",
            "Epoch: 11280, weights = 1.5450868606567383, loss = 1.3651503324508667\n",
            "Epoch: 11290, weights = 1.5464565753936768, loss = 1.3610411882400513\n",
            "Epoch: 11300, weights = 1.5478262901306152, loss = 1.3569319248199463\n",
            "Epoch: 11310, weights = 1.5491960048675537, loss = 1.35282301902771\n",
            "Epoch: 11320, weights = 1.5505657196044922, loss = 1.348713755607605\n",
            "Epoch: 11330, weights = 1.5519354343414307, loss = 1.3446046113967896\n",
            "Epoch: 11340, weights = 1.5533051490783691, loss = 1.3404953479766846\n",
            "Epoch: 11350, weights = 1.5546748638153076, loss = 1.3363864421844482\n",
            "Epoch: 11360, weights = 1.556044578552246, loss = 1.3322771787643433\n",
            "Epoch: 11370, weights = 1.5574142932891846, loss = 1.3281680345535278\n",
            "Epoch: 11380, weights = 1.558784008026123, loss = 1.3240587711334229\n",
            "Epoch: 11390, weights = 1.5601537227630615, loss = 1.3199498653411865\n",
            "Epoch: 11400, weights = 1.5615234375, loss = 1.3158406019210815\n",
            "Epoch: 11410, weights = 1.5628931522369385, loss = 1.3117314577102661\n",
            "Epoch: 11420, weights = 1.564262866973877, loss = 1.3076221942901611\n",
            "Epoch: 11430, weights = 1.5656325817108154, loss = 1.3035132884979248\n",
            "Epoch: 11440, weights = 1.567002296447754, loss = 1.2994040250778198\n",
            "Epoch: 11450, weights = 1.5683720111846924, loss = 1.2952948808670044\n",
            "Epoch: 11460, weights = 1.5697417259216309, loss = 1.2911856174468994\n",
            "Epoch: 11470, weights = 1.5711114406585693, loss = 1.287076711654663\n",
            "Epoch: 11480, weights = 1.5724811553955078, loss = 1.282967448234558\n",
            "Epoch: 11490, weights = 1.5738508701324463, loss = 1.2788583040237427\n",
            "Epoch: 11500, weights = 1.5752205848693848, loss = 1.2747490406036377\n",
            "Epoch: 11510, weights = 1.5765902996063232, loss = 1.2706401348114014\n",
            "Epoch: 11520, weights = 1.5779600143432617, loss = 1.2665308713912964\n",
            "Epoch: 11530, weights = 1.5793297290802002, loss = 1.262421727180481\n",
            "Epoch: 11540, weights = 1.5806994438171387, loss = 1.258312463760376\n",
            "Epoch: 11550, weights = 1.5820691585540771, loss = 1.2542035579681396\n",
            "Epoch: 11560, weights = 1.5834388732910156, loss = 1.2500942945480347\n",
            "Epoch: 11570, weights = 1.584808588027954, loss = 1.2459851503372192\n",
            "Epoch: 11580, weights = 1.5861783027648926, loss = 1.2418758869171143\n",
            "Epoch: 11590, weights = 1.587548017501831, loss = 1.237766981124878\n",
            "Epoch: 11600, weights = 1.5889177322387695, loss = 1.233657717704773\n",
            "Epoch: 11610, weights = 1.590287446975708, loss = 1.2295485734939575\n",
            "Epoch: 11620, weights = 1.5916571617126465, loss = 1.2254393100738525\n",
            "Epoch: 11630, weights = 1.593026876449585, loss = 1.2213304042816162\n",
            "Epoch: 11640, weights = 1.5943965911865234, loss = 1.2172211408615112\n",
            "Epoch: 11650, weights = 1.595766305923462, loss = 1.2131119966506958\n",
            "Epoch: 11660, weights = 1.5971360206604004, loss = 1.2090027332305908\n",
            "Epoch: 11670, weights = 1.5985057353973389, loss = 1.2048938274383545\n",
            "Epoch: 11680, weights = 1.5998754501342773, loss = 1.2007845640182495\n",
            "Epoch: 11690, weights = 1.6012451648712158, loss = 1.196675419807434\n",
            "Epoch: 11700, weights = 1.6026148796081543, loss = 1.1925663948059082\n",
            "Epoch: 11710, weights = 1.6039845943450928, loss = 1.1884570121765137\n",
            "Epoch: 11720, weights = 1.6053543090820312, loss = 1.1843479871749878\n",
            "Epoch: 11730, weights = 1.6067240238189697, loss = 1.1802388429641724\n",
            "Epoch: 11740, weights = 1.6080937385559082, loss = 1.1761298179626465\n",
            "Epoch: 11750, weights = 1.6094634532928467, loss = 1.172020435333252\n",
            "Epoch: 11760, weights = 1.6108331680297852, loss = 1.167911410331726\n",
            "Epoch: 11770, weights = 1.6122028827667236, loss = 1.1638022661209106\n",
            "Epoch: 11780, weights = 1.613572597503662, loss = 1.1596932411193848\n",
            "Epoch: 11790, weights = 1.6149423122406006, loss = 1.1555838584899902\n",
            "Epoch: 11800, weights = 1.616312026977539, loss = 1.1514748334884644\n",
            "Epoch: 11810, weights = 1.6176817417144775, loss = 1.147365689277649\n",
            "Epoch: 11820, weights = 1.619051456451416, loss = 1.143256664276123\n",
            "Epoch: 11830, weights = 1.6204211711883545, loss = 1.1391472816467285\n",
            "Epoch: 11840, weights = 1.621790885925293, loss = 1.1350382566452026\n",
            "Epoch: 11850, weights = 1.6231606006622314, loss = 1.1309291124343872\n",
            "Epoch: 11860, weights = 1.62453031539917, loss = 1.1268200874328613\n",
            "Epoch: 11870, weights = 1.6259000301361084, loss = 1.1227107048034668\n",
            "Epoch: 11880, weights = 1.6272697448730469, loss = 1.118601679801941\n",
            "Epoch: 11890, weights = 1.6286394596099854, loss = 1.1144925355911255\n",
            "Epoch: 11900, weights = 1.6300091743469238, loss = 1.1103835105895996\n",
            "Epoch: 11910, weights = 1.6313788890838623, loss = 1.106274127960205\n",
            "Epoch: 11920, weights = 1.6327486038208008, loss = 1.1021651029586792\n",
            "Epoch: 11930, weights = 1.6341183185577393, loss = 1.0980559587478638\n",
            "Epoch: 11940, weights = 1.6354880332946777, loss = 1.093946933746338\n",
            "Epoch: 11950, weights = 1.6368577480316162, loss = 1.089837670326233\n",
            "Epoch: 11960, weights = 1.6382274627685547, loss = 1.085728406906128\n",
            "Epoch: 11970, weights = 1.6395971775054932, loss = 1.0816195011138916\n",
            "Epoch: 11980, weights = 1.6409668922424316, loss = 1.0775102376937866\n",
            "Epoch: 11990, weights = 1.6423366069793701, loss = 1.0734010934829712\n",
            "Epoch: 12000, weights = 1.6437063217163086, loss = 1.0692918300628662\n",
            "Epoch: 12010, weights = 1.645076036453247, loss = 1.0651829242706299\n",
            "Epoch: 12020, weights = 1.6464457511901855, loss = 1.061073660850525\n",
            "Epoch: 12030, weights = 1.647815465927124, loss = 1.0569645166397095\n",
            "Epoch: 12040, weights = 1.6491851806640625, loss = 1.0528552532196045\n",
            "Epoch: 12050, weights = 1.650554895401001, loss = 1.0487463474273682\n",
            "Epoch: 12060, weights = 1.6519246101379395, loss = 1.0446370840072632\n",
            "Epoch: 12070, weights = 1.653294324874878, loss = 1.0405279397964478\n",
            "Epoch: 12080, weights = 1.6546640396118164, loss = 1.0364186763763428\n",
            "Epoch: 12090, weights = 1.6560337543487549, loss = 1.0323097705841064\n",
            "Epoch: 12100, weights = 1.6574034690856934, loss = 1.0282005071640015\n",
            "Epoch: 12110, weights = 1.6587731838226318, loss = 1.024091362953186\n",
            "Epoch: 12120, weights = 1.6601428985595703, loss = 1.019982099533081\n",
            "Epoch: 12130, weights = 1.6615126132965088, loss = 1.0158731937408447\n",
            "Epoch: 12140, weights = 1.6628823280334473, loss = 1.0117639303207397\n",
            "Epoch: 12150, weights = 1.6642520427703857, loss = 1.0076547861099243\n",
            "Epoch: 12160, weights = 1.6656217575073242, loss = 1.0035455226898193\n",
            "Epoch: 12170, weights = 1.6669914722442627, loss = 0.9994364976882935\n",
            "Epoch: 12180, weights = 1.6683611869812012, loss = 0.9953274726867676\n",
            "Epoch: 12190, weights = 1.6697309017181396, loss = 0.991218090057373\n",
            "Epoch: 12200, weights = 1.6711006164550781, loss = 0.9871090650558472\n",
            "Epoch: 12210, weights = 1.6724703311920166, loss = 0.9829999208450317\n",
            "Epoch: 12220, weights = 1.673840045928955, loss = 0.9788908958435059\n",
            "Epoch: 12230, weights = 1.6752097606658936, loss = 0.9747815132141113\n",
            "Epoch: 12240, weights = 1.676579475402832, loss = 0.9706724882125854\n",
            "Epoch: 12250, weights = 1.6779491901397705, loss = 0.96656334400177\n",
            "Epoch: 12260, weights = 1.679318904876709, loss = 0.9624543190002441\n",
            "Epoch: 12270, weights = 1.6806886196136475, loss = 0.9583449363708496\n",
            "Epoch: 12280, weights = 1.682058334350586, loss = 0.9542359113693237\n",
            "Epoch: 12290, weights = 1.6834280490875244, loss = 0.9501267671585083\n",
            "Epoch: 12300, weights = 1.684797763824463, loss = 0.9460177421569824\n",
            "Epoch: 12310, weights = 1.6861674785614014, loss = 0.9419083595275879\n",
            "Epoch: 12320, weights = 1.6875371932983398, loss = 0.937799334526062\n",
            "Epoch: 12330, weights = 1.6889069080352783, loss = 0.9336901903152466\n",
            "Epoch: 12340, weights = 1.6902766227722168, loss = 0.9295811653137207\n",
            "Epoch: 12350, weights = 1.6916463375091553, loss = 0.9254717826843262\n",
            "Epoch: 12360, weights = 1.6930160522460938, loss = 0.9213627576828003\n",
            "Epoch: 12370, weights = 1.6943857669830322, loss = 0.9172536134719849\n",
            "Epoch: 12380, weights = 1.6957554817199707, loss = 0.913144588470459\n",
            "Epoch: 12390, weights = 1.6971251964569092, loss = 0.9090352058410645\n",
            "Epoch: 12400, weights = 1.6984949111938477, loss = 0.9049261808395386\n",
            "Epoch: 12410, weights = 1.6998646259307861, loss = 0.9008170366287231\n",
            "Epoch: 12420, weights = 1.7012343406677246, loss = 0.8967080116271973\n",
            "Epoch: 12430, weights = 1.702604055404663, loss = 0.8925986289978027\n",
            "Epoch: 12440, weights = 1.7039737701416016, loss = 0.8884896039962769\n",
            "Epoch: 12450, weights = 1.70534348487854, loss = 0.8843804597854614\n",
            "Epoch: 12460, weights = 1.7067131996154785, loss = 0.8802714347839355\n",
            "Epoch: 12470, weights = 1.708082914352417, loss = 0.876162052154541\n",
            "Epoch: 12480, weights = 1.7094526290893555, loss = 0.8720530271530151\n",
            "Epoch: 12490, weights = 1.710822343826294, loss = 0.8679438829421997\n",
            "Epoch: 12500, weights = 1.7121920585632324, loss = 0.8638348579406738\n",
            "Epoch: 12510, weights = 1.713561773300171, loss = 0.8597254753112793\n",
            "Epoch: 12520, weights = 1.7149314880371094, loss = 0.8556164503097534\n",
            "Epoch: 12530, weights = 1.7163012027740479, loss = 0.851507306098938\n",
            "Epoch: 12540, weights = 1.7176709175109863, loss = 0.8473982810974121\n",
            "Epoch: 12550, weights = 1.7190406322479248, loss = 0.8432888984680176\n",
            "Epoch: 12560, weights = 1.7204103469848633, loss = 0.8391798734664917\n",
            "Epoch: 12570, weights = 1.7217800617218018, loss = 0.8350707292556763\n",
            "Epoch: 12580, weights = 1.7231497764587402, loss = 0.8309617042541504\n",
            "Epoch: 12590, weights = 1.7245194911956787, loss = 0.8268523216247559\n",
            "Epoch: 12600, weights = 1.7258892059326172, loss = 0.82274329662323\n",
            "Epoch: 12610, weights = 1.7272589206695557, loss = 0.8186341524124146\n",
            "Epoch: 12620, weights = 1.7286286354064941, loss = 0.8145251274108887\n",
            "Epoch: 12630, weights = 1.7299983501434326, loss = 0.8104157447814941\n",
            "Epoch: 12640, weights = 1.731368064880371, loss = 0.8063067197799683\n",
            "Epoch: 12650, weights = 1.7327377796173096, loss = 0.8021975755691528\n",
            "Epoch: 12660, weights = 1.734107494354248, loss = 0.798088550567627\n",
            "Epoch: 12670, weights = 1.7354772090911865, loss = 0.7939791679382324\n",
            "Epoch: 12680, weights = 1.736846923828125, loss = 0.7898701429367065\n",
            "Epoch: 12690, weights = 1.7382166385650635, loss = 0.7857609987258911\n",
            "Epoch: 12700, weights = 1.739586353302002, loss = 0.7816519737243652\n",
            "Epoch: 12710, weights = 1.7409560680389404, loss = 0.7775425910949707\n",
            "Epoch: 12720, weights = 1.742325782775879, loss = 0.7734335660934448\n",
            "Epoch: 12730, weights = 1.7436954975128174, loss = 0.7693244218826294\n",
            "Epoch: 12740, weights = 1.7450652122497559, loss = 0.7652153968811035\n",
            "Epoch: 12750, weights = 1.7464349269866943, loss = 0.761106014251709\n",
            "Epoch: 12760, weights = 1.7478046417236328, loss = 0.7569969892501831\n",
            "Epoch: 12770, weights = 1.7491743564605713, loss = 0.7528878450393677\n",
            "Epoch: 12780, weights = 1.7505440711975098, loss = 0.7487788200378418\n",
            "Epoch: 12790, weights = 1.7519137859344482, loss = 0.7446694374084473\n",
            "Epoch: 12800, weights = 1.7532835006713867, loss = 0.7405604124069214\n",
            "Epoch: 12810, weights = 1.7546532154083252, loss = 0.736451268196106\n",
            "Epoch: 12820, weights = 1.7560229301452637, loss = 0.7323422431945801\n",
            "Epoch: 12830, weights = 1.7573926448822021, loss = 0.7282328605651855\n",
            "Epoch: 12840, weights = 1.7587623596191406, loss = 0.7241238355636597\n",
            "Epoch: 12850, weights = 1.760132074356079, loss = 0.7200146913528442\n",
            "Epoch: 12860, weights = 1.7615017890930176, loss = 0.7159056663513184\n",
            "Epoch: 12870, weights = 1.762871503829956, loss = 0.7117962837219238\n",
            "Epoch: 12880, weights = 1.7642412185668945, loss = 0.707687258720398\n",
            "Epoch: 12890, weights = 1.765610933303833, loss = 0.7035781145095825\n",
            "Epoch: 12900, weights = 1.7669806480407715, loss = 0.6994690895080566\n",
            "Epoch: 12910, weights = 1.76835036277771, loss = 0.6953597068786621\n",
            "Epoch: 12920, weights = 1.7697200775146484, loss = 0.6912506818771362\n",
            "Epoch: 12930, weights = 1.771089792251587, loss = 0.6871415376663208\n",
            "Epoch: 12940, weights = 1.7724595069885254, loss = 0.6830325126647949\n",
            "Epoch: 12950, weights = 1.7738292217254639, loss = 0.6789231300354004\n",
            "Epoch: 12960, weights = 1.7751989364624023, loss = 0.6748141050338745\n",
            "Epoch: 12970, weights = 1.7765686511993408, loss = 0.6707049608230591\n",
            "Epoch: 12980, weights = 1.7779383659362793, loss = 0.6665959358215332\n",
            "Epoch: 12990, weights = 1.7793080806732178, loss = 0.6624865531921387\n",
            "Epoch: 13000, weights = 1.7806777954101562, loss = 0.6583775281906128\n",
            "Epoch: 13010, weights = 1.7820475101470947, loss = 0.6542683839797974\n",
            "Epoch: 13020, weights = 1.7834172248840332, loss = 0.6501593589782715\n",
            "Epoch: 13030, weights = 1.7847869396209717, loss = 0.646049976348877\n",
            "Epoch: 13040, weights = 1.7861566543579102, loss = 0.6419409513473511\n",
            "Epoch: 13050, weights = 1.7875263690948486, loss = 0.6378318071365356\n",
            "Epoch: 13060, weights = 1.788896083831787, loss = 0.6337227821350098\n",
            "Epoch: 13070, weights = 1.7902657985687256, loss = 0.6296133995056152\n",
            "Epoch: 13080, weights = 1.791635513305664, loss = 0.6255043745040894\n",
            "Epoch: 13090, weights = 1.7930052280426025, loss = 0.6213952302932739\n",
            "Epoch: 13100, weights = 1.794374942779541, loss = 0.617286205291748\n",
            "Epoch: 13110, weights = 1.7957446575164795, loss = 0.6131768226623535\n",
            "Epoch: 13120, weights = 1.797114372253418, loss = 0.6090677976608276\n",
            "Epoch: 13130, weights = 1.7984840869903564, loss = 0.6049586534500122\n",
            "Epoch: 13140, weights = 1.799853801727295, loss = 0.6008496284484863\n",
            "Epoch: 13150, weights = 1.8012235164642334, loss = 0.5967402458190918\n",
            "Epoch: 13160, weights = 1.8025932312011719, loss = 0.5926312208175659\n",
            "Epoch: 13170, weights = 1.8039629459381104, loss = 0.5885220766067505\n",
            "Epoch: 13180, weights = 1.8053326606750488, loss = 0.5844130516052246\n",
            "Epoch: 13190, weights = 1.8067023754119873, loss = 0.5803036689758301\n",
            "Epoch: 13200, weights = 1.8080720901489258, loss = 0.5761946439743042\n",
            "Epoch: 13210, weights = 1.8094418048858643, loss = 0.5720854997634888\n",
            "Epoch: 13220, weights = 1.8108115196228027, loss = 0.5679764747619629\n",
            "Epoch: 13230, weights = 1.8121812343597412, loss = 0.5638670921325684\n",
            "Epoch: 13240, weights = 1.8135509490966797, loss = 0.5597580671310425\n",
            "Epoch: 13250, weights = 1.8149206638336182, loss = 0.555648922920227\n",
            "Epoch: 13260, weights = 1.8162903785705566, loss = 0.5515398979187012\n",
            "Epoch: 13270, weights = 1.8176600933074951, loss = 0.5474305152893066\n",
            "Epoch: 13280, weights = 1.8190298080444336, loss = 0.5433214902877808\n",
            "Epoch: 13290, weights = 1.820399522781372, loss = 0.5392123460769653\n",
            "Epoch: 13300, weights = 1.8217692375183105, loss = 0.5351033210754395\n",
            "Epoch: 13310, weights = 1.823138952255249, loss = 0.5309939384460449\n",
            "Epoch: 13320, weights = 1.8245086669921875, loss = 0.526884913444519\n",
            "Epoch: 13330, weights = 1.825878381729126, loss = 0.5227757692337036\n",
            "Epoch: 13340, weights = 1.8272480964660645, loss = 0.5186667442321777\n",
            "Epoch: 13350, weights = 1.828617811203003, loss = 0.5145573616027832\n",
            "Epoch: 13360, weights = 1.8299875259399414, loss = 0.5104483366012573\n",
            "Epoch: 13370, weights = 1.8313572406768799, loss = 0.5063391923904419\n",
            "Epoch: 13380, weights = 1.8327269554138184, loss = 0.502230167388916\n",
            "Epoch: 13390, weights = 1.8340966701507568, loss = 0.4981207847595215\n",
            "Epoch: 13400, weights = 1.8354663848876953, loss = 0.494011789560318\n",
            "Epoch: 13410, weights = 1.8368360996246338, loss = 0.4899025857448578\n",
            "Epoch: 13420, weights = 1.8382058143615723, loss = 0.4857935905456543\n",
            "Epoch: 13430, weights = 1.8395755290985107, loss = 0.48168420791625977\n",
            "Epoch: 13440, weights = 1.8409452438354492, loss = 0.4775752127170563\n",
            "Epoch: 13450, weights = 1.8423149585723877, loss = 0.47346600890159607\n",
            "Epoch: 13460, weights = 1.8436846733093262, loss = 0.4693570137023926\n",
            "Epoch: 13470, weights = 1.8450543880462646, loss = 0.46524763107299805\n",
            "Epoch: 13480, weights = 1.8464241027832031, loss = 0.46113863587379456\n",
            "Epoch: 13490, weights = 1.8477938175201416, loss = 0.45702943205833435\n",
            "Epoch: 13500, weights = 1.84916353225708, loss = 0.45292043685913086\n",
            "Epoch: 13510, weights = 1.8505332469940186, loss = 0.44881105422973633\n",
            "Epoch: 13520, weights = 1.851902961730957, loss = 0.44470205903053284\n",
            "Epoch: 13530, weights = 1.8532726764678955, loss = 0.44059285521507263\n",
            "Epoch: 13540, weights = 1.854642391204834, loss = 0.43648386001586914\n",
            "Epoch: 13550, weights = 1.8560121059417725, loss = 0.4323744773864746\n",
            "Epoch: 13560, weights = 1.857381820678711, loss = 0.4282654821872711\n",
            "Epoch: 13570, weights = 1.8587515354156494, loss = 0.4241562783718109\n",
            "Epoch: 13580, weights = 1.860121250152588, loss = 0.4200472831726074\n",
            "Epoch: 13590, weights = 1.8614909648895264, loss = 0.4159379005432129\n",
            "Epoch: 13600, weights = 1.8628606796264648, loss = 0.4118289053440094\n",
            "Epoch: 13610, weights = 1.8642303943634033, loss = 0.4077197015285492\n",
            "Epoch: 13620, weights = 1.8656001091003418, loss = 0.4036107063293457\n",
            "Epoch: 13630, weights = 1.8669698238372803, loss = 0.39950135350227356\n",
            "Epoch: 13640, weights = 1.8683395385742188, loss = 0.3953922986984253\n",
            "Epoch: 13650, weights = 1.8697092533111572, loss = 0.39128315448760986\n",
            "Epoch: 13660, weights = 1.8710789680480957, loss = 0.3871740996837616\n",
            "Epoch: 13670, weights = 1.8724486827850342, loss = 0.38306477665901184\n",
            "Epoch: 13680, weights = 1.8738183975219727, loss = 0.3789557218551636\n",
            "Epoch: 13690, weights = 1.8751881122589111, loss = 0.37484657764434814\n",
            "Epoch: 13700, weights = 1.8765578269958496, loss = 0.3707375228404999\n",
            "Epoch: 13710, weights = 1.877927541732788, loss = 0.3666281998157501\n",
            "Epoch: 13720, weights = 1.8792972564697266, loss = 0.36251914501190186\n",
            "Epoch: 13730, weights = 1.880666971206665, loss = 0.3584100008010864\n",
            "Epoch: 13740, weights = 1.8820366859436035, loss = 0.35430094599723816\n",
            "Epoch: 13750, weights = 1.883406400680542, loss = 0.3501916229724884\n",
            "Epoch: 13760, weights = 1.8847761154174805, loss = 0.34608256816864014\n",
            "Epoch: 13770, weights = 1.886145830154419, loss = 0.3419734239578247\n",
            "Epoch: 13780, weights = 1.8875155448913574, loss = 0.33786436915397644\n",
            "Epoch: 13790, weights = 1.888885259628296, loss = 0.3337550461292267\n",
            "Epoch: 13800, weights = 1.8902549743652344, loss = 0.3296459913253784\n",
            "Epoch: 13810, weights = 1.8916246891021729, loss = 0.325536847114563\n",
            "Epoch: 13820, weights = 1.8929944038391113, loss = 0.3214277923107147\n",
            "Epoch: 13830, weights = 1.8943641185760498, loss = 0.31731846928596497\n",
            "Epoch: 13840, weights = 1.8957338333129883, loss = 0.3132094144821167\n",
            "Epoch: 13850, weights = 1.8971035480499268, loss = 0.30910027027130127\n",
            "Epoch: 13860, weights = 1.8984732627868652, loss = 0.304991215467453\n",
            "Epoch: 13870, weights = 1.8998429775238037, loss = 0.30088189244270325\n",
            "Epoch: 13880, weights = 1.9012126922607422, loss = 0.296772837638855\n",
            "Epoch: 13890, weights = 1.9025824069976807, loss = 0.29266369342803955\n",
            "Epoch: 13900, weights = 1.9039521217346191, loss = 0.2885546386241913\n",
            "Epoch: 13910, weights = 1.9053218364715576, loss = 0.28444531559944153\n",
            "Epoch: 13920, weights = 1.906691551208496, loss = 0.28033626079559326\n",
            "Epoch: 13930, weights = 1.9080612659454346, loss = 0.27622711658477783\n",
            "Epoch: 13940, weights = 1.909430980682373, loss = 0.27211806178092957\n",
            "Epoch: 13950, weights = 1.9108006954193115, loss = 0.2680087387561798\n",
            "Epoch: 13960, weights = 1.91217041015625, loss = 0.26389968395233154\n",
            "Epoch: 13970, weights = 1.9135401248931885, loss = 0.2597905397415161\n",
            "Epoch: 13980, weights = 1.914909839630127, loss = 0.25568148493766785\n",
            "Epoch: 13990, weights = 1.9162795543670654, loss = 0.2515721619129181\n",
            "Epoch: 14000, weights = 1.917649269104004, loss = 0.24746310710906982\n",
            "Epoch: 14010, weights = 1.9190189838409424, loss = 0.2433539628982544\n",
            "Epoch: 14020, weights = 1.9203886985778809, loss = 0.23924490809440613\n",
            "Epoch: 14030, weights = 1.9217584133148193, loss = 0.23513558506965637\n",
            "Epoch: 14040, weights = 1.9231281280517578, loss = 0.2310265302658081\n",
            "Epoch: 14050, weights = 1.9244978427886963, loss = 0.22691738605499268\n",
            "Epoch: 14060, weights = 1.9258675575256348, loss = 0.2228083312511444\n",
            "Epoch: 14070, weights = 1.9272372722625732, loss = 0.21869900822639465\n",
            "Epoch: 14080, weights = 1.9286069869995117, loss = 0.2145899534225464\n",
            "Epoch: 14090, weights = 1.9299767017364502, loss = 0.21048080921173096\n",
            "Epoch: 14100, weights = 1.9313464164733887, loss = 0.2063717544078827\n",
            "Epoch: 14110, weights = 1.9327161312103271, loss = 0.20226243138313293\n",
            "Epoch: 14120, weights = 1.9340858459472656, loss = 0.19815337657928467\n",
            "Epoch: 14130, weights = 1.935455560684204, loss = 0.19404423236846924\n",
            "Epoch: 14140, weights = 1.9368252754211426, loss = 0.18993517756462097\n",
            "Epoch: 14150, weights = 1.938194990158081, loss = 0.18582585453987122\n",
            "Epoch: 14160, weights = 1.9395647048950195, loss = 0.18171679973602295\n",
            "Epoch: 14170, weights = 1.940934419631958, loss = 0.17760765552520752\n",
            "Epoch: 14180, weights = 1.9423041343688965, loss = 0.17349860072135925\n",
            "Epoch: 14190, weights = 1.943673849105835, loss = 0.1693892776966095\n",
            "Epoch: 14200, weights = 1.9450435638427734, loss = 0.16528022289276123\n",
            "Epoch: 14210, weights = 1.946413278579712, loss = 0.1611710786819458\n",
            "Epoch: 14220, weights = 1.9477829933166504, loss = 0.15706202387809753\n",
            "Epoch: 14230, weights = 1.9491527080535889, loss = 0.15295270085334778\n",
            "Epoch: 14240, weights = 1.9505224227905273, loss = 0.1488436460494995\n",
            "Epoch: 14250, weights = 1.9518921375274658, loss = 0.14473450183868408\n",
            "Epoch: 14260, weights = 1.9532618522644043, loss = 0.14062544703483582\n",
            "Epoch: 14270, weights = 1.9546315670013428, loss = 0.13651612401008606\n",
            "Epoch: 14280, weights = 1.9560012817382812, loss = 0.1324070692062378\n",
            "Epoch: 14290, weights = 1.9573709964752197, loss = 0.12829792499542236\n",
            "Epoch: 14300, weights = 1.9587407112121582, loss = 0.1241888776421547\n",
            "Epoch: 14310, weights = 1.9601104259490967, loss = 0.12007953971624374\n",
            "Epoch: 14320, weights = 1.9614801406860352, loss = 0.11597049236297607\n",
            "Epoch: 14330, weights = 1.9628498554229736, loss = 0.11186134815216064\n",
            "Epoch: 14340, weights = 1.964219570159912, loss = 0.10775230079889297\n",
            "Epoch: 14350, weights = 1.9655892848968506, loss = 0.10364296287298203\n",
            "Epoch: 14360, weights = 1.966958999633789, loss = 0.09953391551971436\n",
            "Epoch: 14370, weights = 1.9683287143707275, loss = 0.09542477130889893\n",
            "Epoch: 14380, weights = 1.969698429107666, loss = 0.09131572395563126\n",
            "Epoch: 14390, weights = 1.9710681438446045, loss = 0.0872063860297203\n",
            "Epoch: 14400, weights = 1.972437858581543, loss = 0.08309733867645264\n",
            "Epoch: 14410, weights = 1.9738075733184814, loss = 0.07898819446563721\n",
            "Epoch: 14420, weights = 1.97517728805542, loss = 0.07487914711236954\n",
            "Epoch: 14430, weights = 1.9765470027923584, loss = 0.07076980918645859\n",
            "Epoch: 14440, weights = 1.9779167175292969, loss = 0.06666076183319092\n",
            "Epoch: 14450, weights = 1.9792864322662354, loss = 0.06255161762237549\n",
            "Epoch: 14460, weights = 1.9806561470031738, loss = 0.05844257026910782\n",
            "Epoch: 14470, weights = 1.9820258617401123, loss = 0.05433323234319687\n",
            "Epoch: 14480, weights = 1.9833955764770508, loss = 0.0502241849899292\n",
            "Epoch: 14490, weights = 1.9847652912139893, loss = 0.04611504077911377\n",
            "Epoch: 14500, weights = 1.9861350059509277, loss = 0.0420059934258461\n",
            "Epoch: 14510, weights = 1.9875047206878662, loss = 0.03789665549993515\n",
            "Epoch: 14520, weights = 1.9888744354248047, loss = 0.03378760814666748\n",
            "Epoch: 14530, weights = 1.9902441501617432, loss = 0.02967846393585205\n",
            "Epoch: 14540, weights = 1.9916138648986816, loss = 0.025569414719939232\n",
            "Epoch: 14550, weights = 1.9929835796356201, loss = 0.02146008051931858\n",
            "Epoch: 14560, weights = 1.9943532943725586, loss = 0.01735103130340576\n",
            "Epoch: 14570, weights = 1.995723009109497, loss = 0.013241887092590332\n",
            "Epoch: 14580, weights = 1.9970927238464355, loss = 0.009132837876677513\n",
            "Epoch: 14590, weights = 1.998462438583374, loss = 0.005023503210395575\n",
            "Epoch: 14600, weights = 1.9998321533203125, loss = 0.000914454460144043\n",
            "Epoch: 14610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 14990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 15990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 16990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 17990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 18990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 19990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 20990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 21990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 22990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 23990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 24990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 25990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 26990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 27990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 28990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 29990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 30990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 31990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 32990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 33990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 34990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 35990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 36990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 37990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 38990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 39990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 40990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 41990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 42990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 43990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 44990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 45990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 46990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 47990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 48990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49000, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49010, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49020, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49030, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49040, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49050, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49060, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49070, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49080, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49090, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49100, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49110, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49120, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49130, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49140, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49150, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49160, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49170, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49180, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49190, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49200, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49210, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49220, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49230, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49240, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49250, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49260, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49270, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49280, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49290, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49300, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49310, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49320, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49330, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49340, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49350, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49360, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49370, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49380, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49390, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49400, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49410, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49420, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49430, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49440, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49450, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49460, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49470, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49480, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49490, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49500, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49510, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49520, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49530, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49540, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49550, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49560, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49570, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49580, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49590, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49600, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49610, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49620, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49630, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49640, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49650, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49660, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49670, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49680, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49690, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49700, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49710, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49720, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49730, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49740, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49750, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49760, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49770, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49780, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49790, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49800, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49810, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49820, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49830, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49840, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49850, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49860, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49870, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49880, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49890, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49900, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49910, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49920, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49930, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49940, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49950, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49960, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49970, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49980, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Epoch: 49990, weights = 2.0001060962677, loss = 9.262561798095703e-05\n",
            "Prediction after training: f(6) = 11.999814987182617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the final weight $w$ is not exactly equal to 2 but is very close.\n",
        "\n",
        "This can be improved with a smaller learning rate and maybe more training epochs.\n",
        "\n",
        "However, in machine learning we don't expect perfect solutions."
      ],
      "metadata": {
        "id": "U9Xx90LgLk4u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 1** - for the simple model above, change the hyperparameters and observe how the progress of weights changes. See if you can exactly obtain $w=2$."
      ],
      "metadata": {
        "id": "ucfPVuHuE-4g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Rewriting the code with modules from torch library"
      ],
      "metadata": {
        "id": "cXkqxcYOIh2f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luckily we do not have to manually perform the updates of the model.\n",
        "\n",
        "We can do this by defining the `optimizer = optim.SGD(...)` which does the gradient descent updates for us.\n",
        "\n",
        "Also, we do not need to manually define the weights. We can use `nn.Module` class and `nn.Linear(...)` for this."
      ],
      "metadata": {
        "id": "EfWyZHSCFkWj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We construct a simple linear model by inheriting from `nn.Module` class.\n",
        "\n",
        "All neural networks you will build will inherit from this class. It's good to get familiar with it. You can check more details about it [here](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)."
      ],
      "metadata": {
        "id": "eFal4_O1IaN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LinearModel, self).__init__()\n",
        "    # One input neuron and one output neuron\n",
        "    self.weights = nn.Linear(in_features=1, out_features=1, bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.weights(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "aykgJBFUIfiE"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We initialize the model and define the hyperparameters"
      ],
      "metadata": {
        "id": "MqR_NrriNJ1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Initialize parameters\n",
        "model = LinearModel()\n",
        "print(model)\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate = 0.01\n",
        "epochs = 100"
      ],
      "metadata": {
        "id": "f-f5SbfbNPBA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86e4bdfa-7739-4e8f-b71c-716f64774cb4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearModel(\n",
            "  (weights): Linear(in_features=1, out_features=1, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We initialize the optimizer. We will use `optim.SGD` which stands for Stochastic Gradient Descent. In the PyTorch library there are optimizers that may work better than Stochastic Gradient Descent (for example `optim.Adam` which is very commonly used). You can check them [here](https://pytorch.org/docs/stable/optim.html)"
      ],
      "metadata": {
        "id": "N6yY8S9HNSuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This will perform Gradient Descent for us\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "OwsqZpdrNu7_"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The new model expects the samples to come in batches. We will add an extra dimension to our $x$ and $y$ tensors. The first dimension of these tensors will be the batch size."
      ],
      "metadata": {
        "id": "M8CUNRJBNx6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.shape, y.shape)\n",
        "# Add extra dimension for batch:\n",
        "x = x.unsqueeze(1)\n",
        "y = y.unsqueeze(1)\n",
        "print(x.shape, y.shape)\n",
        "\n",
        "# Define testing sample\n",
        "testing_sample = torch.tensor([[6.0]])"
      ],
      "metadata": {
        "id": "TL8wqhRlN7DN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82bebca3-f4a0-4689-cee0-96b7b5b0fc83"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5]) torch.Size([5])\n",
            "torch.Size([5, 1]) torch.Size([5, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction on unseen sample before training"
      ],
      "metadata": {
        "id": "cdEJFhHcOL63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  print(f\"Prediction before training: f(6) = {model(testing_sample)}\")"
      ],
      "metadata": {
        "id": "NSnpilYJOOJX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a8567ac-431a-4aa2-bfab-2d5235742233"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(6) = tensor([[3.6496]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the training loop looks like this:"
      ],
      "metadata": {
        "id": "LIwPHcEuIxob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "\n",
        "  # Obtain prediction\n",
        "\n",
        "  pred = model(x)\n",
        "\n",
        "  # 2. Compute loss\n",
        "  loss = custom_loss(pred, y)\n",
        "\n",
        "  # 3. Compute gradients\n",
        "  loss.backward()\n",
        "\n",
        "  # 4. Update parameters\n",
        "  optimizer.step()\n",
        "\n",
        "  # Set gradient to 0 for next computation\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"Epoch: {epoch}, loss = {loss}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "  print(f\"Prediction after training: f(6) = {model(testing_sample)}\")\n"
      ],
      "metadata": {
        "id": "xh_8eTWzHM5z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e98d31c-1b30-4bf1-dc4d-5657b6a92f92"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, loss = 4.1752119064331055\n",
            "Epoch: 10, loss = 3.2752127647399902\n",
            "Epoch: 20, loss = 2.375213623046875\n",
            "Epoch: 30, loss = 1.4752147197723389\n",
            "Epoch: 40, loss = 0.5752154588699341\n",
            "Epoch: 50, loss = 0.03521561622619629\n",
            "Epoch: 60, loss = 0.03521561622619629\n",
            "Epoch: 70, loss = 0.03521561622619629\n",
            "Epoch: 80, loss = 0.03521561622619629\n",
            "Epoch: 90, loss = 0.03521561622619629\n",
            "Prediction after training: f(6) = tensor([[11.9296]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Neural Network on Circle Dataset"
      ],
      "metadata": {
        "id": "zhJaWFMMdAF4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to create more complex models - a single parameter model is very limited.\n",
        "\n",
        "We will build the following Neural Network with 2 input neurons, 3 neurons in the hidden layer and two output neurons:\n",
        "\n",
        "<img src=\"https://www.researchgate.net/publication/289479445/figure/fig1/AS:614019022991383@1523404951564/Example-for-an-artificial-neural-network-with-two-input-neurons-two-hidden-neurons-and.png\" width=300px>"
      ],
      "metadata": {
        "id": "5CnMuzE_3ftJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each neuron in the neural network is just a linear model + an activation function (which adds nonlinearity).\n",
        "\n",
        "All the neurons in a previous layer are connected to all the layers in the current layer.\n",
        "\n",
        "This means that the output of a neuron will be computed based on all the outputs of the neurons in the previous layer."
      ],
      "metadata": {
        "id": "50859qDqOVck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "\n",
        "    # This defines the connections from input layer to hidden layer - 2 neruons to 3 neurons\n",
        "    self.fc1 = nn.Linear(in_features=2, out_features=3)\n",
        "\n",
        "    # This defines the connections from hidden layer to output layer - 3 neruons to 2 neurons\n",
        "    self.fc2 = nn.Linear(in_features=3, out_features=2)\n",
        "\n",
        "    # This is a commonly used nonlinearity\n",
        "    self.activation = nn.ReLU()\n",
        "\n",
        "    # Activation functions which are more recent:\n",
        "    # self.activation = nn.GELU() - very popular, widely utilized in transformers\n",
        "    # self.activation = nn.Mish()\n",
        "    # self.activation = nn.ELU()\n",
        "\n",
        "    # Other activation functions (only used in specific cases):\n",
        "    # self.activation = nn.Tanh()\n",
        "    # self.activation = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    # We pass through the hidden layer\n",
        "    x = self.fc1(x)\n",
        "\n",
        "    # We add nonlinearity\n",
        "    x = self.activation(x)\n",
        "\n",
        "    # We pass through output layer\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "2FIvJ9geJ_FH"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will train it to classify samples consisting of points inside or outside a circle. We will have 2 classes: $inside=0$ and $outside=1$.\n",
        "\n"
      ],
      "metadata": {
        "id": "_a7G7fD03uzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the code that generates the samples - you can ignore it\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Define the circle parameters\n",
        "radius = 5\n",
        "center = (0, 0)\n",
        "\n",
        "# Generate the dataset\n",
        "num_samples = 2000\n",
        "\n",
        "# Generate random x, y points within a square\n",
        "x = torch.rand(num_samples) * 2 * radius - radius\n",
        "y = torch.rand(num_samples) * 2 * radius - radius\n",
        "\n",
        "# Calculate the Euclidean distance from each point to the center\n",
        "distances = torch.sqrt((x - center[0]) ** 2 + (y - center[1]) ** 2)\n",
        "\n",
        "# Assign labels based on whether points are inside or outside the circle\n",
        "labels = torch.where(distances <= radius, torch.zeros_like(distances), torch.ones_like(distances))\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "labels_train, labels_test = train_test_split(labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Plot the training and testing datasets\n",
        "plt.scatter(x_train[labels_train == 0], y_train[labels_train == 0], color='blue', label='Inside Circle (Train)')\n",
        "plt.scatter(x_train[labels_train == 1], y_train[labels_train == 1], color='red', label='Outside Circle (Train)')\n",
        "plt.scatter(x_test[labels_test == 0], y_test[labels_test == 0], color='cyan', label='Inside Circle (Test)')\n",
        "plt.scatter(x_test[labels_test == 1], y_test[labels_test == 1], color='orange', label='Outside Circle (Test)')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title('Dataset')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q8Ho7_M4MwcR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "2a503592-e9dd-4380-b56d-b9022a076de3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Dataset class which stores samples and their labels."
      ],
      "metadata": {
        "id": "6aHk-uIMOEfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class CircleDataset(Dataset):\n",
        "    def __init__(self, x, y, labels):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    # Each sample will have the coords (2D vector) and a class label (inside or outside the circle)\n",
        "    def __getitem__(self, idx):\n",
        "        sample = {\n",
        "            'coords': torch.tensor([self.x[idx], self.y[idx]]),\n",
        "            'label': self.labels[idx].long()\n",
        "        }\n",
        "\n",
        "        return sample"
      ],
      "metadata": {
        "id": "59Uq__pFODXf"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Dataset class in PyTorch represents a collection of data samples and labels. It is needed for the DataLoader class.\n",
        "\n",
        "The DataLoader class efficiently loads and manages the data during training or inference by providing features like batching and shuffling. These classes are commonly used in PyTorch. You can read more about them [here](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)."
      ],
      "metadata": {
        "id": "N2WPr9DIQFf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CircleDataset(x_train, y_train, labels_train)\n",
        "test_dataset = CircleDataset(x_test, y_test, labels_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "W4PNm0VVOo-o"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will define an evaluation function which calculates the accuracy on the test set. This function will be used in the training loop in order to keep track of the evolution of the model on unseen data.\n",
        "\n",
        "We compute the accuracy manually for educational purposes. However, this is not necessary. There are already functions for computing evaluation metrics in the sklearn library. You can check them [here](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics). See [accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score) and [F1 score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score)."
      ],
      "metadata": {
        "id": "chKFjo9rtOEn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additional Note: Notice that when evaluating we do not keep track of gradients. We only want to keep track of gradients when training"
      ],
      "metadata": {
        "id": "1U8zc2bGKIvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model):\n",
        "  # Put model in evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  # For keeping track of number of correct predictions and total predictions\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for data in test_loader:\n",
        "      coords = data['coords'].to(device)\n",
        "      ground_truth = data['label'].to(device)\n",
        "\n",
        "      # We do not need to keep track of gradients while testing\n",
        "      with torch.no_grad():\n",
        "        pred = model(coords)\n",
        "\n",
        "      # For each sample the model predicts 2 values - score for inside class and score for outside class\n",
        "      # We keep the prediction that has the highest score\n",
        "      _, predicted = torch.max(pred, 1)\n",
        "\n",
        "      # We count all the predictions which match the ground truth to get number of correct predictions\n",
        "      correct += (predicted == ground_truth).sum().item()\n",
        "      total += coords.shape[0]\n",
        "\n",
        "  accuracy = np.round(100 * correct / total, 2)\n",
        "\n",
        "  print(f\"Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "EVPsSeVys_D9"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training loop will look very similar to the previous example.\n",
        "\n",
        "However, now we also iterate through the data loader which returns batches of random samples and their labels."
      ],
      "metadata": {
        "id": "kmWo5gO6dMaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross Entropy Loss - commonly used for classification\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate = 0.0005\n",
        "epochs = 10\n",
        "\n",
        "# 1. Initialize parameters\n",
        "model = Net()\n",
        "\n",
        "# Push model on device\n",
        "model.to(device)\n",
        "print(model)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  epoch_loss = 0\n",
        "  for data in train_loader:\n",
        "    # Put model in training mode\n",
        "    model.train()\n",
        "\n",
        "    coords = data['coords'].to(device)\n",
        "    ground_truth = data['label'].to(device)\n",
        "    pred = model(coords)\n",
        "\n",
        "    # 2. Compute loss\n",
        "    loss = criterion(pred, ground_truth)\n",
        "\n",
        "    # 3. Compute gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # 4. Update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # Set gradient to 0 for next computation\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    epoch_loss += loss\n",
        "\n",
        "  print(f\"Epoch: {epoch}, Training loss = {epoch_loss}\")\n",
        "  evaluate(model)\n"
      ],
      "metadata": {
        "id": "j-0Hp2cuQStQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d367ee6-c88d-457e-88f0-fd7a759f567c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=2, out_features=3, bias=True)\n",
            "  (fc2): Linear(in_features=3, out_features=2, bias=True)\n",
            "  (activation): ReLU()\n",
            ")\n",
            "Epoch: 0, Training loss = 18.737619400024414\n",
            "Test Accuracy: 27.25\n",
            "Epoch: 1, Training loss = 18.572174072265625\n",
            "Test Accuracy: 30.25\n",
            "Epoch: 2, Training loss = 18.414506912231445\n",
            "Test Accuracy: 31.75\n",
            "Epoch: 3, Training loss = 18.263975143432617\n",
            "Test Accuracy: 34.5\n",
            "Epoch: 4, Training loss = 18.120424270629883\n",
            "Test Accuracy: 37.0\n",
            "Epoch: 5, Training loss = 17.983551025390625\n",
            "Test Accuracy: 38.75\n",
            "Epoch: 6, Training loss = 17.852811813354492\n",
            "Test Accuracy: 41.0\n",
            "Epoch: 7, Training loss = 17.728139877319336\n",
            "Test Accuracy: 41.5\n",
            "Epoch: 8, Training loss = 17.609094619750977\n",
            "Test Accuracy: 42.5\n",
            "Epoch: 9, Training loss = 17.49540138244629\n",
            "Test Accuracy: 43.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 2** - Play with the hyperparameters (learning rate, number of epochs) and with the structure of the model (add more neurons in the hidden layer, add more layers) and see if you can improve the results. Maybe also change the optimizer.\n",
        "\n",
        "Try to apply only one change at a time and test it to see what improves the results and what decreases performance.\n",
        "\n",
        "Do not perform many changes at once as you will not know what caused a change in performance."
      ],
      "metadata": {
        "id": "9Jp-fa2qaxzS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Neural Network for classification on the Iris Dataset"
      ],
      "metadata": {
        "id": "-vt-0U8eUoes"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 3** - Train a Neural Network for classification on the iris dataset.\n",
        "\n",
        "The iris dataset consists of measurements of sepal and petal lengths and widths for three different species of iris flowers: setosa, versicolor, and virginica. See more details about the dataset [here](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html) and [here](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n",
        "\n",
        "Your input to the model will be all these measurements (features) and you will have 3 flower classes."
      ],
      "metadata": {
        "id": "5dxIzyT_iXlB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code imports the dataset and creates the dataloaders that you need"
      ],
      "metadata": {
        "id": "bTTtByaoi6Ut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "data = iris.data\n",
        "labels = iris.target\n",
        "feature_names = iris.feature_names\n",
        "target_names = iris.target_names\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "T0d55VnkdWat"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the dataset"
      ],
      "metadata": {
        "id": "Roc52UG3kIor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create plots for different feature combinations\n",
        "feature_combinations = [(0, 1), (0, 2), (0, 3), (1, 2), (1, 3), (2, 3)]\n",
        "num_plots = len(feature_combinations)\n",
        "num_rows = (num_plots + 1) // 3  # Calculate the number of rows required for the subplot grid\n",
        "\n",
        "# Create the subplot grid\n",
        "fig, axs = plt.subplots(num_rows, 3, figsize=(10, num_rows * 3))\n",
        "\n",
        "# Plotting the dataset for each feature combination\n",
        "for i, (feat_idx1, feat_idx2) in enumerate(feature_combinations):\n",
        "    row = i // 3  # Determine the row index in the subplot grid\n",
        "    col = i % 3   # Determine the column index in the subplot grid\n",
        "    axs[row, col].scatter(data[:, feat_idx1], data[:, feat_idx2], c=labels, cmap='viridis')\n",
        "    axs[row, col].set_xlabel(feature_names[feat_idx1])\n",
        "    axs[row, col].set_ylabel(feature_names[feat_idx2])\n",
        "    axs[row, col].set_title(f\"{feature_names[feat_idx1]} vs {feature_names[feat_idx2]}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lBFMs_FRkHA9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "1405e2fa-762d-4e83-d583-2fc64ac32d1f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create the Dataset class"
      ],
      "metadata": {
        "id": "hnydQ49XSg_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IrisDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = {\n",
        "            'features': torch.tensor(self.features[idx], dtype=torch.float32),\n",
        "            'label': torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        }\n",
        "        return sample"
      ],
      "metadata": {
        "id": "SRMstEb5SfBp"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create the dataloaders for training set and testing set"
      ],
      "metadata": {
        "id": "Xnt1h_2MSoqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train and test datasets\n",
        "iris_train_dataset = IrisDataset(x_train, y_train)\n",
        "iris_test_dataset = IrisDataset(x_test, y_test)\n",
        "\n",
        "# Create train and test data loaders\n",
        "iris_train_loader = DataLoader(iris_train_dataset, batch_size=64, shuffle=True)\n",
        "iris_test_loader = DataLoader(iris_test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "mK2s5-EhSanq"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out some samples from the dataset\n",
        "print(iris_train_dataset[0])\n",
        "print(iris_train_dataset[50])\n",
        "print(iris_train_dataset[110])"
      ],
      "metadata": {
        "id": "RjGmYSRGOdXe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dab44d8-7323-402a-af26-3bac726ab83b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'features': tensor([4.6000, 3.6000, 1.0000, 0.2000]), 'label': tensor(0)}\n",
            "{'features': tensor([6.4000, 2.7000, 5.3000, 1.9000]), 'label': tensor(2)}\n",
            "{'features': tensor([6.3000, 2.3000, 4.4000, 1.3000]), 'label': tensor(1)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your job is to construct the neural network and write the training and evaluation.\n",
        "\n",
        "Play with the number of hidden layers and their size (number of neurons) to see what configuration is best.\n",
        "\n",
        "Some things to keep in mind:\n",
        "- What is the dimensionality of the input? This will tell you the number of input neurons for first layer\n",
        "- What is the number of classes? This will tell you the number of output neurons for final layer\n",
        "- When adding multiple hidden layers the in_features (number of neurons) of current layer should match the out_features of the previous layer\n",
        "- Do not forget about using activation functions after each layer (except output)"
      ],
      "metadata": {
        "id": "1Svg0tNyjD1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MyNet, self).__init__()\n",
        "    # TODO - Write the layers of the network\n",
        "    self.fc1 = nn.Linear(in_features=4, out_features=4)\n",
        "\n",
        "    # This defines the connections from hidden layer to output layer - 3 neruons to 2 neurons\n",
        "    self.fc2 = nn.Linear(in_features=4, out_features=3)\n",
        "\n",
        "    self.fc3 = nn.Linear(in_features=3, out_features=3)\n",
        "\n",
        "    self.activation = nn.GELU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    # TODO - Write the forward function - pass through each layer - do not forget about activation functions\n",
        "    x = self.fc1(x)\n",
        "\n",
        "    # We add nonlinearity\n",
        "    x = self.activation(x)\n",
        "\n",
        "    # We pass through output layer\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    x = self.activation(x)\n",
        "\n",
        "    x = self.fc3(x)\n",
        "\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "xI75fFt4drSt"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the training loop and the evaluation:\n",
        "\n",
        "* Define the hyperparameters\n",
        "* Define the loss function (criterion) - You can use already existing ones.\n",
        "* Define the optimizer\n",
        "* Initialize the model and train it\n",
        "* Evaluate the model's accuracy\n",
        "\n",
        "You can take inspiration from the previous example."
      ],
      "metadata": {
        "id": "ib7Km8EejG5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO - Write the training loop and evaluation code on the test set\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate = 0.0005\n",
        "epochs = 1700\n",
        "\n",
        "# 1. Initialize parameters\n",
        "model = MyNet()\n",
        "\n",
        "# Push model on device\n",
        "model.to(device)\n",
        "print(model)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  epoch_loss = 0\n",
        "  for data in iris_train_loader:\n",
        "    # Put model in training mode\n",
        "    model.train()\n",
        "\n",
        "    features = data['features'].to(device)\n",
        "    ground_truth = data['label'].to(device)\n",
        "    pred = model(features)\n",
        "\n",
        "    # 2. Compute loss\n",
        "    loss = criterion(pred, ground_truth)\n",
        "\n",
        "    # 3. Compute gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # 4. Update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # Set gradient to 0 for next computation\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    epoch_loss += loss\n",
        "\n",
        "  print(f\"Epoch: {epoch}, Training loss = {epoch_loss}\")\n",
        "  # Need to update the evaluate function to use the iris_test_loader\n",
        "  def evaluate_iris(model):\n",
        "    # Put model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # For keeping track of number of correct predictions and total predictions\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for data in iris_test_loader: # Changed from test_loader to iris_test_loader\n",
        "        features = data['features'].to(device)\n",
        "        ground_truth = data['label'].to(device)\n",
        "\n",
        "        # We do not need to keep track of gradients while testing\n",
        "        with torch.no_grad():\n",
        "          pred = model(features)\n",
        "\n",
        "        # For each sample the model predicts 3 values (for 3 classes) - score for each class\n",
        "        # We keep the prediction that has the highest score\n",
        "        _, predicted = torch.max(pred, 1)\n",
        "\n",
        "        # We count all the predictions which match the ground truth to get number of correct predictions\n",
        "        correct += (predicted == ground_truth).sum().item()\n",
        "        total += features.shape[0]\n",
        "\n",
        "    accuracy = np.round(100 * correct / total, 2)\n",
        "\n",
        "    print(f\"Test Accuracy: {accuracy}\")\n",
        "\n",
        "  evaluate_iris(model) # Changed from evaluate to evaluate_iris"
      ],
      "metadata": {
        "id": "K_YFJE7SeB97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45e4c36e-1743-4f58-a61b-fe88d3c8871e"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyNet(\n",
            "  (fc1): Linear(in_features=4, out_features=4, bias=True)\n",
            "  (fc2): Linear(in_features=4, out_features=3, bias=True)\n",
            "  (fc3): Linear(in_features=3, out_features=3, bias=True)\n",
            "  (activation): GELU(approximate='none')\n",
            ")\n",
            "Epoch: 0, Training loss = 2.2284631729125977\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 1, Training loss = 2.234354257583618\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 2, Training loss = 2.2280168533325195\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 3, Training loss = 2.2284231185913086\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 4, Training loss = 2.2284164428710938\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 5, Training loss = 2.223238468170166\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 6, Training loss = 2.224815845489502\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 7, Training loss = 2.2246880531311035\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 8, Training loss = 2.2197272777557373\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 9, Training loss = 2.2224488258361816\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 10, Training loss = 2.2251522541046143\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 11, Training loss = 2.2204997539520264\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 12, Training loss = 2.2196946144104004\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 13, Training loss = 2.2231221199035645\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 14, Training loss = 2.2217044830322266\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 15, Training loss = 2.218386650085449\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 16, Training loss = 2.2124123573303223\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 17, Training loss = 2.2177629470825195\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 18, Training loss = 2.2165024280548096\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 19, Training loss = 2.2177538871765137\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 20, Training loss = 2.2149620056152344\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 21, Training loss = 2.2108240127563477\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 22, Training loss = 2.209465265274048\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 23, Training loss = 2.211540699005127\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 24, Training loss = 2.2140026092529297\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 25, Training loss = 2.2064313888549805\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 26, Training loss = 2.2126572132110596\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 27, Training loss = 2.2086181640625\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 28, Training loss = 2.2070329189300537\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 29, Training loss = 2.2053442001342773\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 30, Training loss = 2.2066290378570557\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 31, Training loss = 2.2057700157165527\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 32, Training loss = 2.204925537109375\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 33, Training loss = 2.199934959411621\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 34, Training loss = 2.2027297019958496\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 35, Training loss = 2.2044565677642822\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 36, Training loss = 2.202751636505127\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 37, Training loss = 2.2022788524627686\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 38, Training loss = 2.202322006225586\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 39, Training loss = 2.200308322906494\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 40, Training loss = 2.201324462890625\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 41, Training loss = 2.1957130432128906\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 42, Training loss = 2.1980059146881104\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 43, Training loss = 2.1951699256896973\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 44, Training loss = 2.196589469909668\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 45, Training loss = 2.1890225410461426\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 46, Training loss = 2.193406581878662\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 47, Training loss = 2.189042091369629\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 48, Training loss = 2.189692974090576\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 49, Training loss = 2.189265251159668\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 50, Training loss = 2.1903491020202637\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 51, Training loss = 2.1900458335876465\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 52, Training loss = 2.1859335899353027\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 53, Training loss = 2.1879920959472656\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 54, Training loss = 2.1879115104675293\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 55, Training loss = 2.187730312347412\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 56, Training loss = 2.181063652038574\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 57, Training loss = 2.184614896774292\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 58, Training loss = 2.182511568069458\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 59, Training loss = 2.182650327682495\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 60, Training loss = 2.17668080329895\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 61, Training loss = 2.1741995811462402\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 62, Training loss = 2.1801414489746094\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 63, Training loss = 2.176785707473755\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 64, Training loss = 2.1714863777160645\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 65, Training loss = 2.17319393157959\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 66, Training loss = 2.1700363159179688\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 67, Training loss = 2.1711955070495605\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 68, Training loss = 2.171461582183838\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 69, Training loss = 2.171257972717285\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 70, Training loss = 2.1689703464508057\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 71, Training loss = 2.167823314666748\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 72, Training loss = 2.1654553413391113\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 73, Training loss = 2.164217472076416\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 74, Training loss = 2.1658220291137695\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 75, Training loss = 2.1626205444335938\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 76, Training loss = 2.1642446517944336\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 77, Training loss = 2.1603615283966064\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 78, Training loss = 2.162186622619629\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 79, Training loss = 2.160045623779297\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 80, Training loss = 2.1599745750427246\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 81, Training loss = 2.157780647277832\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 82, Training loss = 2.1572306156158447\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 83, Training loss = 2.1570706367492676\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 84, Training loss = 2.1542820930480957\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 85, Training loss = 2.15305757522583\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 86, Training loss = 2.152374267578125\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 87, Training loss = 2.151798725128174\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 88, Training loss = 2.147522449493408\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 89, Training loss = 2.1483445167541504\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 90, Training loss = 2.1502532958984375\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 91, Training loss = 2.14664363861084\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 92, Training loss = 2.1458537578582764\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 93, Training loss = 2.1424736976623535\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 94, Training loss = 2.144773006439209\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 95, Training loss = 2.1404953002929688\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 96, Training loss = 2.1422019004821777\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 97, Training loss = 2.1388401985168457\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 98, Training loss = 2.140409469604492\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 99, Training loss = 2.140829086303711\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 100, Training loss = 2.1356070041656494\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 101, Training loss = 2.1308600902557373\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 102, Training loss = 2.1349599361419678\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 103, Training loss = 2.1296579837799072\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 104, Training loss = 2.1324081420898438\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 105, Training loss = 2.1285324096679688\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 106, Training loss = 2.1302099227905273\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 107, Training loss = 2.128727436065674\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 108, Training loss = 2.128979206085205\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 109, Training loss = 2.1258506774902344\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 110, Training loss = 2.122253894805908\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 111, Training loss = 2.1222033500671387\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 112, Training loss = 2.122457981109619\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 113, Training loss = 2.1182615756988525\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 114, Training loss = 2.11861515045166\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 115, Training loss = 2.1174426078796387\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 116, Training loss = 2.115365982055664\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 117, Training loss = 2.114739418029785\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 118, Training loss = 2.1142849922180176\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 119, Training loss = 2.113193988800049\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 120, Training loss = 2.1108996868133545\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 121, Training loss = 2.112699508666992\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 122, Training loss = 2.10860538482666\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 123, Training loss = 2.1073033809661865\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 124, Training loss = 2.1065616607666016\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 125, Training loss = 2.103896379470825\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 126, Training loss = 2.103813648223877\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 127, Training loss = 2.1039257049560547\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 128, Training loss = 2.0996222496032715\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 129, Training loss = 2.097842216491699\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 130, Training loss = 2.0994977951049805\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 131, Training loss = 2.095750331878662\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 132, Training loss = 2.093487024307251\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 133, Training loss = 2.0918831825256348\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 134, Training loss = 2.091245174407959\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 135, Training loss = 2.0925731658935547\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 136, Training loss = 2.0883517265319824\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 137, Training loss = 2.0869946479797363\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 138, Training loss = 2.088148593902588\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 139, Training loss = 2.0840978622436523\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 140, Training loss = 2.080319404602051\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 141, Training loss = 2.079791307449341\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 142, Training loss = 2.078111171722412\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 143, Training loss = 2.078632354736328\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 144, Training loss = 2.0767440795898438\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 145, Training loss = 2.0757317543029785\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 146, Training loss = 2.0730366706848145\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 147, Training loss = 2.0722460746765137\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 148, Training loss = 2.0715675354003906\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 149, Training loss = 2.067873239517212\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 150, Training loss = 2.066509485244751\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 151, Training loss = 2.0659666061401367\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 152, Training loss = 2.0650076866149902\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 153, Training loss = 2.062922477722168\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 154, Training loss = 2.061790704727173\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 155, Training loss = 2.05953049659729\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 156, Training loss = 2.0587501525878906\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 157, Training loss = 2.0545530319213867\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 158, Training loss = 2.056079149246216\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 159, Training loss = 2.0538811683654785\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 160, Training loss = 2.052004098892212\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 161, Training loss = 2.0493202209472656\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 162, Training loss = 2.047520637512207\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 163, Training loss = 2.0444259643554688\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 164, Training loss = 2.0441231727600098\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 165, Training loss = 2.0432515144348145\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 166, Training loss = 2.0408620834350586\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 167, Training loss = 2.039299964904785\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 168, Training loss = 2.036606788635254\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 169, Training loss = 2.035132884979248\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 170, Training loss = 2.034396171569824\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 171, Training loss = 2.0327274799346924\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 172, Training loss = 2.031867504119873\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 173, Training loss = 2.029356002807617\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 174, Training loss = 2.0275826454162598\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 175, Training loss = 2.0256404876708984\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 176, Training loss = 2.021104335784912\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 177, Training loss = 2.0205509662628174\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 178, Training loss = 2.0191850662231445\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 179, Training loss = 2.017998218536377\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 180, Training loss = 2.0157361030578613\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 181, Training loss = 2.014880657196045\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 182, Training loss = 2.0131852626800537\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 183, Training loss = 2.009465217590332\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 184, Training loss = 2.0085017681121826\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 185, Training loss = 2.006112575531006\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 186, Training loss = 2.004805564880371\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 187, Training loss = 2.001908779144287\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 188, Training loss = 2.001065731048584\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 189, Training loss = 1.9987566471099854\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 190, Training loss = 1.997593641281128\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 191, Training loss = 1.9960004091262817\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 192, Training loss = 1.9944157600402832\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 193, Training loss = 1.991853952407837\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 194, Training loss = 1.990360140800476\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 195, Training loss = 1.9880523681640625\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 196, Training loss = 1.9869699478149414\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 197, Training loss = 1.983640432357788\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 198, Training loss = 1.9823484420776367\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 199, Training loss = 1.9824544191360474\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 200, Training loss = 1.980032205581665\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 201, Training loss = 1.97674560546875\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 202, Training loss = 1.9759695529937744\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 203, Training loss = 1.9733552932739258\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 204, Training loss = 1.9712121486663818\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 205, Training loss = 1.9683548212051392\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 206, Training loss = 1.9673230648040771\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 207, Training loss = 1.9654629230499268\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 208, Training loss = 1.9648027420043945\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 209, Training loss = 1.961693286895752\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 210, Training loss = 1.9580683708190918\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 211, Training loss = 1.9569988250732422\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 212, Training loss = 1.9554939270019531\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 213, Training loss = 1.95285964012146\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 214, Training loss = 1.951108694076538\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 215, Training loss = 1.9492547512054443\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 216, Training loss = 1.9480867385864258\n",
            "Test Accuracy: 30.0\n",
            "Epoch: 217, Training loss = 1.9455699920654297\n",
            "Test Accuracy: 43.33\n",
            "Epoch: 218, Training loss = 1.9434118270874023\n",
            "Test Accuracy: 43.33\n",
            "Epoch: 219, Training loss = 1.9414359331130981\n",
            "Test Accuracy: 46.67\n",
            "Epoch: 220, Training loss = 1.9389060735702515\n",
            "Test Accuracy: 56.67\n",
            "Epoch: 221, Training loss = 1.937525749206543\n",
            "Test Accuracy: 56.67\n",
            "Epoch: 222, Training loss = 1.935791254043579\n",
            "Test Accuracy: 56.67\n",
            "Epoch: 223, Training loss = 1.9323208332061768\n",
            "Test Accuracy: 60.0\n",
            "Epoch: 224, Training loss = 1.9313099384307861\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 225, Training loss = 1.9284946918487549\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 226, Training loss = 1.9269113540649414\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 227, Training loss = 1.924715518951416\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 228, Training loss = 1.923501968383789\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 229, Training loss = 1.9205503463745117\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 230, Training loss = 1.9190783500671387\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 231, Training loss = 1.916722059249878\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 232, Training loss = 1.9143855571746826\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 233, Training loss = 1.9123778343200684\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 234, Training loss = 1.910210371017456\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 235, Training loss = 1.908055067062378\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 236, Training loss = 1.906248927116394\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 237, Training loss = 1.9038453102111816\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 238, Training loss = 1.901874303817749\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 239, Training loss = 1.8999433517456055\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 240, Training loss = 1.8979578018188477\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 241, Training loss = 1.896070957183838\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 242, Training loss = 1.892716646194458\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 243, Training loss = 1.891752004623413\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 244, Training loss = 1.8892455101013184\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 245, Training loss = 1.8878628015518188\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 246, Training loss = 1.884761929512024\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 247, Training loss = 1.8826383352279663\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 248, Training loss = 1.8802872896194458\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 249, Training loss = 1.8786225318908691\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 250, Training loss = 1.8758795261383057\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 251, Training loss = 1.8743224143981934\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 252, Training loss = 1.8723833560943604\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 253, Training loss = 1.8701746463775635\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 254, Training loss = 1.8684784173965454\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 255, Training loss = 1.8660061359405518\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 256, Training loss = 1.863959789276123\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 257, Training loss = 1.8610153198242188\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 258, Training loss = 1.8591333627700806\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 259, Training loss = 1.8573288917541504\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 260, Training loss = 1.8546828031539917\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 261, Training loss = 1.8532346487045288\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 262, Training loss = 1.8508483171463013\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 263, Training loss = 1.847947359085083\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 264, Training loss = 1.8465245962142944\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 265, Training loss = 1.8444628715515137\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 266, Training loss = 1.8421785831451416\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 267, Training loss = 1.8395929336547852\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 268, Training loss = 1.837592601776123\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 269, Training loss = 1.8356587886810303\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 270, Training loss = 1.8329538106918335\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 271, Training loss = 1.8306889533996582\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 272, Training loss = 1.8290112018585205\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 273, Training loss = 1.8264029026031494\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 274, Training loss = 1.824768304824829\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 275, Training loss = 1.8220198154449463\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 276, Training loss = 1.8200349807739258\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 277, Training loss = 1.8174235820770264\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 278, Training loss = 1.8155021667480469\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 279, Training loss = 1.813286542892456\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 280, Training loss = 1.8110946416854858\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 281, Training loss = 1.808915138244629\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 282, Training loss = 1.807015299797058\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 283, Training loss = 1.8044630289077759\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 284, Training loss = 1.8023107051849365\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 285, Training loss = 1.8002097606658936\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 286, Training loss = 1.7980681657791138\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 287, Training loss = 1.7958180904388428\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 288, Training loss = 1.7936127185821533\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 289, Training loss = 1.7914626598358154\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 290, Training loss = 1.789167881011963\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 291, Training loss = 1.787109613418579\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 292, Training loss = 1.7849867343902588\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 293, Training loss = 1.782827377319336\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 294, Training loss = 1.7806355953216553\n",
            "Test Accuracy: 63.33\n",
            "Epoch: 295, Training loss = 1.778350591659546\n",
            "Test Accuracy: 70.0\n",
            "Epoch: 296, Training loss = 1.7762072086334229\n",
            "Test Accuracy: 70.0\n",
            "Epoch: 297, Training loss = 1.7740323543548584\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 298, Training loss = 1.7717012166976929\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 299, Training loss = 1.7697901725769043\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 300, Training loss = 1.767153263092041\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 301, Training loss = 1.765247106552124\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 302, Training loss = 1.7630664110183716\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 303, Training loss = 1.7608251571655273\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 304, Training loss = 1.7589492797851562\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 305, Training loss = 1.7563645839691162\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 306, Training loss = 1.7544357776641846\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 307, Training loss = 1.7523488998413086\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 308, Training loss = 1.7499281167984009\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 309, Training loss = 1.7477614879608154\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 310, Training loss = 1.7455813884735107\n",
            "Test Accuracy: 83.33\n",
            "Epoch: 311, Training loss = 1.7434022426605225\n",
            "Test Accuracy: 83.33\n",
            "Epoch: 312, Training loss = 1.7414453029632568\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 313, Training loss = 1.739011526107788\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 314, Training loss = 1.7369122505187988\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 315, Training loss = 1.7350752353668213\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 316, Training loss = 1.7325669527053833\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 317, Training loss = 1.7308144569396973\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 318, Training loss = 1.728346824645996\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 319, Training loss = 1.7266002893447876\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 320, Training loss = 1.7241322994232178\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 321, Training loss = 1.721868872642517\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 322, Training loss = 1.7196571826934814\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 323, Training loss = 1.7177619934082031\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 324, Training loss = 1.7154338359832764\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 325, Training loss = 1.713327407836914\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 326, Training loss = 1.7108339071273804\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 327, Training loss = 1.709043025970459\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 328, Training loss = 1.7069814205169678\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 329, Training loss = 1.7048120498657227\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 330, Training loss = 1.7026429176330566\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 331, Training loss = 1.7006826400756836\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 332, Training loss = 1.6981983184814453\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 333, Training loss = 1.6960158348083496\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 334, Training loss = 1.6940444707870483\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 335, Training loss = 1.6922129392623901\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 336, Training loss = 1.6896569728851318\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 337, Training loss = 1.6879968643188477\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 338, Training loss = 1.685956597328186\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 339, Training loss = 1.6835882663726807\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 340, Training loss = 1.681726098060608\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 341, Training loss = 1.6791893243789673\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 342, Training loss = 1.6772750616073608\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 343, Training loss = 1.6753404140472412\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 344, Training loss = 1.6734178066253662\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 345, Training loss = 1.6711891889572144\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 346, Training loss = 1.6687805652618408\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 347, Training loss = 1.6667687892913818\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 348, Training loss = 1.664853811264038\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 349, Training loss = 1.6628782749176025\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 350, Training loss = 1.6604933738708496\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 351, Training loss = 1.6585923433303833\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 352, Training loss = 1.657055377960205\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 353, Training loss = 1.654370903968811\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 354, Training loss = 1.6522681713104248\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 355, Training loss = 1.6505992412567139\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 356, Training loss = 1.6479332447052002\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 357, Training loss = 1.6458245515823364\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 358, Training loss = 1.6439321041107178\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 359, Training loss = 1.6419346332550049\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 360, Training loss = 1.639915108680725\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 361, Training loss = 1.6383241415023804\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 362, Training loss = 1.6361160278320312\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 363, Training loss = 1.634361982345581\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 364, Training loss = 1.631988763809204\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 365, Training loss = 1.630233645439148\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 366, Training loss = 1.6276808977127075\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 367, Training loss = 1.6260926723480225\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 368, Training loss = 1.6239635944366455\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 369, Training loss = 1.6218808889389038\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 370, Training loss = 1.6195755004882812\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 371, Training loss = 1.6182353496551514\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 372, Training loss = 1.6161595582962036\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 373, Training loss = 1.6146957874298096\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 374, Training loss = 1.6117677688598633\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 375, Training loss = 1.611168384552002\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 376, Training loss = 1.607696533203125\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 377, Training loss = 1.6066393852233887\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 378, Training loss = 1.6055470705032349\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 379, Training loss = 1.6015887260437012\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 380, Training loss = 1.6001508235931396\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 381, Training loss = 1.597776174545288\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 382, Training loss = 1.5964488983154297\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 383, Training loss = 1.594240427017212\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 384, Training loss = 1.5926055908203125\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 385, Training loss = 1.5913398265838623\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 386, Training loss = 1.5893055200576782\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 387, Training loss = 1.5866162776947021\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 388, Training loss = 1.585050344467163\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 389, Training loss = 1.583451509475708\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 390, Training loss = 1.5812798738479614\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 391, Training loss = 1.5792882442474365\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 392, Training loss = 1.5785317420959473\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 393, Training loss = 1.5746533870697021\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 394, Training loss = 1.5733668804168701\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 395, Training loss = 1.5714666843414307\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 396, Training loss = 1.5695970058441162\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 397, Training loss = 1.568304419517517\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 398, Training loss = 1.5664209127426147\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 399, Training loss = 1.5631086826324463\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 400, Training loss = 1.563685417175293\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 401, Training loss = 1.5600244998931885\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 402, Training loss = 1.5582551956176758\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 403, Training loss = 1.557887315750122\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 404, Training loss = 1.5550305843353271\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 405, Training loss = 1.5543274879455566\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 406, Training loss = 1.5508360862731934\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 407, Training loss = 1.5495333671569824\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 408, Training loss = 1.547784447669983\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 409, Training loss = 1.5459201335906982\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 410, Training loss = 1.544603705406189\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 411, Training loss = 1.5439128875732422\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 412, Training loss = 1.5403990745544434\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 413, Training loss = 1.5399140119552612\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 414, Training loss = 1.5384063720703125\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 415, Training loss = 1.53517484664917\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 416, Training loss = 1.5332872867584229\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 417, Training loss = 1.5318326950073242\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 418, Training loss = 1.5304312705993652\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 419, Training loss = 1.5279812812805176\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 420, Training loss = 1.526977300643921\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 421, Training loss = 1.5238925218582153\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 422, Training loss = 1.5227066278457642\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 423, Training loss = 1.5211080312728882\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 424, Training loss = 1.5197824239730835\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 425, Training loss = 1.518552541732788\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 426, Training loss = 1.516448974609375\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 427, Training loss = 1.5147099494934082\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 428, Training loss = 1.5138680934906006\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 429, Training loss = 1.5116522312164307\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 430, Training loss = 1.509099006652832\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 431, Training loss = 1.5069518089294434\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 432, Training loss = 1.5066028833389282\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 433, Training loss = 1.504652500152588\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 434, Training loss = 1.5019910335540771\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 435, Training loss = 1.5008423328399658\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 436, Training loss = 1.4992212057113647\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 437, Training loss = 1.4980196952819824\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 438, Training loss = 1.4968284368515015\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 439, Training loss = 1.4958593845367432\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 440, Training loss = 1.4935870170593262\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 441, Training loss = 1.4905022382736206\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 442, Training loss = 1.4899156093597412\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 443, Training loss = 1.4885886907577515\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 444, Training loss = 1.4860115051269531\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 445, Training loss = 1.486567497253418\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 446, Training loss = 1.484832763671875\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 447, Training loss = 1.482601284980774\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 448, Training loss = 1.4789798259735107\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 449, Training loss = 1.478676438331604\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 450, Training loss = 1.477354645729065\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 451, Training loss = 1.475005865097046\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 452, Training loss = 1.4724338054656982\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 453, Training loss = 1.4717258214950562\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 454, Training loss = 1.4691507816314697\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 455, Training loss = 1.4675735235214233\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 456, Training loss = 1.4661426544189453\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 457, Training loss = 1.4660251140594482\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 458, Training loss = 1.4645216464996338\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 459, Training loss = 1.4617516994476318\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 460, Training loss = 1.4622416496276855\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 461, Training loss = 1.460533618927002\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 462, Training loss = 1.4565412998199463\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 463, Training loss = 1.4573273658752441\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 464, Training loss = 1.4552361965179443\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 465, Training loss = 1.4529917240142822\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 466, Training loss = 1.4522602558135986\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 467, Training loss = 1.4498848915100098\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 468, Training loss = 1.4487037658691406\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 469, Training loss = 1.4458884000778198\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 470, Training loss = 1.44527268409729\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 471, Training loss = 1.4456069469451904\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 472, Training loss = 1.443297028541565\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 473, Training loss = 1.4432228803634644\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 474, Training loss = 1.4413282871246338\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 475, Training loss = 1.4388492107391357\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 476, Training loss = 1.4378492832183838\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 477, Training loss = 1.434861660003662\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 478, Training loss = 1.4359955787658691\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 479, Training loss = 1.4333081245422363\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 480, Training loss = 1.4309831857681274\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 481, Training loss = 1.4305486679077148\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 482, Training loss = 1.4269461631774902\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 483, Training loss = 1.4274308681488037\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 484, Training loss = 1.424630880355835\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 485, Training loss = 1.424933910369873\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 486, Training loss = 1.4228136539459229\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 487, Training loss = 1.4217629432678223\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 488, Training loss = 1.4188650846481323\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 489, Training loss = 1.4196138381958008\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 490, Training loss = 1.4181089401245117\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 491, Training loss = 1.4159090518951416\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 492, Training loss = 1.415693998336792\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 493, Training loss = 1.4131757020950317\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 494, Training loss = 1.4141665697097778\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 495, Training loss = 1.4095585346221924\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 496, Training loss = 1.4097414016723633\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 497, Training loss = 1.4079053401947021\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 498, Training loss = 1.4099706411361694\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 499, Training loss = 1.4055309295654297\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 500, Training loss = 1.4034996032714844\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 501, Training loss = 1.4036457538604736\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 502, Training loss = 1.4020600318908691\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 503, Training loss = 1.402364730834961\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 504, Training loss = 1.3993444442749023\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 505, Training loss = 1.398590326309204\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 506, Training loss = 1.398197889328003\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 507, Training loss = 1.3959882259368896\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 508, Training loss = 1.393858551979065\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 509, Training loss = 1.3922499418258667\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 510, Training loss = 1.3908380270004272\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 511, Training loss = 1.3906183242797852\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 512, Training loss = 1.387851357460022\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 513, Training loss = 1.3869140148162842\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 514, Training loss = 1.3873552083969116\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 515, Training loss = 1.382890224456787\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 516, Training loss = 1.3820080757141113\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 517, Training loss = 1.382277011871338\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 518, Training loss = 1.381946325302124\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 519, Training loss = 1.3788797855377197\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 520, Training loss = 1.3777313232421875\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 521, Training loss = 1.3755813837051392\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 522, Training loss = 1.3762972354888916\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 523, Training loss = 1.3748493194580078\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 524, Training loss = 1.3724679946899414\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 525, Training loss = 1.3694970607757568\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 526, Training loss = 1.3708833456039429\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 527, Training loss = 1.3689199686050415\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 528, Training loss = 1.368518352508545\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 529, Training loss = 1.3660447597503662\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 530, Training loss = 1.3642319440841675\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 531, Training loss = 1.3652522563934326\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 532, Training loss = 1.361860752105713\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 533, Training loss = 1.3626492023468018\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 534, Training loss = 1.3611648082733154\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 535, Training loss = 1.360508680343628\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 536, Training loss = 1.3602733612060547\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 537, Training loss = 1.3585426807403564\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 538, Training loss = 1.353592038154602\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 539, Training loss = 1.3562849760055542\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 540, Training loss = 1.356818675994873\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 541, Training loss = 1.352275013923645\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 542, Training loss = 1.351173758506775\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 543, Training loss = 1.3488647937774658\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 544, Training loss = 1.3478753566741943\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 545, Training loss = 1.3493294715881348\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 546, Training loss = 1.3481462001800537\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 547, Training loss = 1.3450032472610474\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 548, Training loss = 1.3440017700195312\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 549, Training loss = 1.344327688217163\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 550, Training loss = 1.3436508178710938\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 551, Training loss = 1.3420038223266602\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 552, Training loss = 1.3394067287445068\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 553, Training loss = 1.3410890102386475\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 554, Training loss = 1.3402855396270752\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 555, Training loss = 1.3380448818206787\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 556, Training loss = 1.3339903354644775\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 557, Training loss = 1.3328635692596436\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 558, Training loss = 1.3340567350387573\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 559, Training loss = 1.3358006477355957\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 560, Training loss = 1.3320897817611694\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 561, Training loss = 1.3330096006393433\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 562, Training loss = 1.32889723777771\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 563, Training loss = 1.3269832134246826\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 564, Training loss = 1.3269710540771484\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 565, Training loss = 1.3264780044555664\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 566, Training loss = 1.3254337310791016\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 567, Training loss = 1.3215734958648682\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 568, Training loss = 1.3226702213287354\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 569, Training loss = 1.3234243392944336\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 570, Training loss = 1.3184893131256104\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 571, Training loss = 1.318251371383667\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 572, Training loss = 1.3212435245513916\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 573, Training loss = 1.3190293312072754\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 574, Training loss = 1.3129589557647705\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 575, Training loss = 1.3157793283462524\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 576, Training loss = 1.3136417865753174\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 577, Training loss = 1.3116235733032227\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 578, Training loss = 1.313936471939087\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 579, Training loss = 1.310364007949829\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 580, Training loss = 1.3118062019348145\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 581, Training loss = 1.3102867603302002\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 582, Training loss = 1.3090285062789917\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 583, Training loss = 1.3065228462219238\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 584, Training loss = 1.3073546886444092\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 585, Training loss = 1.3083784580230713\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 586, Training loss = 1.307661533355713\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 587, Training loss = 1.3062831163406372\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 588, Training loss = 1.3032143115997314\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 589, Training loss = 1.3021914958953857\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 590, Training loss = 1.2993437051773071\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 591, Training loss = 1.2964661121368408\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 592, Training loss = 1.2975068092346191\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 593, Training loss = 1.2957781553268433\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 594, Training loss = 1.2965402603149414\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 595, Training loss = 1.295326828956604\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 596, Training loss = 1.2936749458312988\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 597, Training loss = 1.2950913906097412\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 598, Training loss = 1.293286919593811\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 599, Training loss = 1.2928996086120605\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 600, Training loss = 1.2887797355651855\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 601, Training loss = 1.2929056882858276\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 602, Training loss = 1.2926304340362549\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 603, Training loss = 1.2876476049423218\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 604, Training loss = 1.2884951829910278\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 605, Training loss = 1.2888294458389282\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 606, Training loss = 1.2866450548171997\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 607, Training loss = 1.2846659421920776\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 608, Training loss = 1.2824864387512207\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 609, Training loss = 1.2829668521881104\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 610, Training loss = 1.2805373668670654\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 611, Training loss = 1.281357765197754\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 612, Training loss = 1.2758662700653076\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 613, Training loss = 1.2785208225250244\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 614, Training loss = 1.2780508995056152\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 615, Training loss = 1.2797554731369019\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 616, Training loss = 1.2740259170532227\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 617, Training loss = 1.2762022018432617\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 618, Training loss = 1.2717015743255615\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 619, Training loss = 1.274878978729248\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 620, Training loss = 1.2726118564605713\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 621, Training loss = 1.2699172496795654\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 622, Training loss = 1.2731008529663086\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 623, Training loss = 1.2700984477996826\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 624, Training loss = 1.270026445388794\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 625, Training loss = 1.2672522068023682\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 626, Training loss = 1.2665808200836182\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 627, Training loss = 1.263798475265503\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 628, Training loss = 1.267029047012329\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 629, Training loss = 1.2628380060195923\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 630, Training loss = 1.265073299407959\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 631, Training loss = 1.2612149715423584\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 632, Training loss = 1.262122631072998\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 633, Training loss = 1.2599754333496094\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 634, Training loss = 1.2620325088500977\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 635, Training loss = 1.258927345275879\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 636, Training loss = 1.2560460567474365\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 637, Training loss = 1.2566072940826416\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 638, Training loss = 1.2602880001068115\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 639, Training loss = 1.2562999725341797\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 640, Training loss = 1.2568182945251465\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 641, Training loss = 1.2554504871368408\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 642, Training loss = 1.2531094551086426\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 643, Training loss = 1.2544775009155273\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 644, Training loss = 1.2498739957809448\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 645, Training loss = 1.247645616531372\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 646, Training loss = 1.2513606548309326\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 647, Training loss = 1.246832013130188\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 648, Training loss = 1.2480627298355103\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 649, Training loss = 1.2481682300567627\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 650, Training loss = 1.245009422302246\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 651, Training loss = 1.2440104484558105\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 652, Training loss = 1.2469911575317383\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 653, Training loss = 1.2451090812683105\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 654, Training loss = 1.244877576828003\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 655, Training loss = 1.2411267757415771\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 656, Training loss = 1.2393808364868164\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 657, Training loss = 1.2429978847503662\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 658, Training loss = 1.2404510974884033\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 659, Training loss = 1.2411317825317383\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 660, Training loss = 1.2391972541809082\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 661, Training loss = 1.2389695644378662\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 662, Training loss = 1.2392241954803467\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 663, Training loss = 1.2378461360931396\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 664, Training loss = 1.234039545059204\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 665, Training loss = 1.2339115142822266\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 666, Training loss = 1.2333886623382568\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 667, Training loss = 1.23154616355896\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 668, Training loss = 1.2329802513122559\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 669, Training loss = 1.2295116186141968\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 670, Training loss = 1.2267825603485107\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 671, Training loss = 1.230944037437439\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 672, Training loss = 1.2285398244857788\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 673, Training loss = 1.2290290594100952\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 674, Training loss = 1.2327150106430054\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 675, Training loss = 1.2283565998077393\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 676, Training loss = 1.2268624305725098\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 677, Training loss = 1.225670576095581\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 678, Training loss = 1.2199536561965942\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 679, Training loss = 1.222695231437683\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 680, Training loss = 1.2234585285186768\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 681, Training loss = 1.224139928817749\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 682, Training loss = 1.2210650444030762\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 683, Training loss = 1.2202749252319336\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 684, Training loss = 1.2167682647705078\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 685, Training loss = 1.2201144695281982\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 686, Training loss = 1.2205102443695068\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 687, Training loss = 1.2203702926635742\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 688, Training loss = 1.2151200771331787\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 689, Training loss = 1.2152206897735596\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 690, Training loss = 1.213770866394043\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 691, Training loss = 1.2103734016418457\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 692, Training loss = 1.214573860168457\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 693, Training loss = 1.2149670124053955\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 694, Training loss = 1.2108638286590576\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 695, Training loss = 1.2143617868423462\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 696, Training loss = 1.2143722772598267\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 697, Training loss = 1.212579369544983\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 698, Training loss = 1.2097150087356567\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 699, Training loss = 1.2072659730911255\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 700, Training loss = 1.2067400217056274\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 701, Training loss = 1.2111918926239014\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 702, Training loss = 1.2070327997207642\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 703, Training loss = 1.2030143737792969\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 704, Training loss = 1.2066164016723633\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 705, Training loss = 1.205415964126587\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 706, Training loss = 1.1998307704925537\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 707, Training loss = 1.2039189338684082\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 708, Training loss = 1.1990495920181274\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 709, Training loss = 1.200014591217041\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 710, Training loss = 1.197742223739624\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 711, Training loss = 1.2019052505493164\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 712, Training loss = 1.1958887577056885\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 713, Training loss = 1.200931191444397\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 714, Training loss = 1.1963775157928467\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 715, Training loss = 1.1986613273620605\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 716, Training loss = 1.1944994926452637\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 717, Training loss = 1.1935436725616455\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 718, Training loss = 1.1910443305969238\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 719, Training loss = 1.1914300918579102\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 720, Training loss = 1.1973614692687988\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 721, Training loss = 1.1939895153045654\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 722, Training loss = 1.1914503574371338\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 723, Training loss = 1.1956636905670166\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 724, Training loss = 1.1902756690979004\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 725, Training loss = 1.1871559619903564\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 726, Training loss = 1.1888374090194702\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 727, Training loss = 1.189192295074463\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 728, Training loss = 1.1892898082733154\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 729, Training loss = 1.1912033557891846\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 730, Training loss = 1.186356544494629\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 731, Training loss = 1.1873515844345093\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 732, Training loss = 1.183227777481079\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 733, Training loss = 1.181910753250122\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 734, Training loss = 1.18423593044281\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 735, Training loss = 1.1828184127807617\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 736, Training loss = 1.1847976446151733\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 737, Training loss = 1.1840779781341553\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 738, Training loss = 1.1819450855255127\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 739, Training loss = 1.1788809299468994\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 740, Training loss = 1.1783227920532227\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 741, Training loss = 1.1775684356689453\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 742, Training loss = 1.1780544519424438\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 743, Training loss = 1.1798499822616577\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 744, Training loss = 1.178912878036499\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 745, Training loss = 1.1737196445465088\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 746, Training loss = 1.1778388023376465\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 747, Training loss = 1.1756742000579834\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 748, Training loss = 1.175689935684204\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 749, Training loss = 1.1759753227233887\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 750, Training loss = 1.1668373346328735\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 751, Training loss = 1.1722692251205444\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 752, Training loss = 1.1673665046691895\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 753, Training loss = 1.1733437776565552\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 754, Training loss = 1.1654272079467773\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 755, Training loss = 1.1671185493469238\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 756, Training loss = 1.1687736511230469\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 757, Training loss = 1.166050910949707\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 758, Training loss = 1.1706328392028809\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 759, Training loss = 1.1635351181030273\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 760, Training loss = 1.16566801071167\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 761, Training loss = 1.1649091243743896\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 762, Training loss = 1.159610390663147\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 763, Training loss = 1.1675505638122559\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 764, Training loss = 1.1635053157806396\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 765, Training loss = 1.16743004322052\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 766, Training loss = 1.1614372730255127\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 767, Training loss = 1.15700101852417\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 768, Training loss = 1.1598091125488281\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 769, Training loss = 1.1609575748443604\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 770, Training loss = 1.1624646186828613\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 771, Training loss = 1.159498691558838\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 772, Training loss = 1.1568045616149902\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 773, Training loss = 1.1551910638809204\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 774, Training loss = 1.1581681966781616\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 775, Training loss = 1.1615792512893677\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 776, Training loss = 1.1570932865142822\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 777, Training loss = 1.157700777053833\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 778, Training loss = 1.1580767631530762\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 779, Training loss = 1.1535930633544922\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 780, Training loss = 1.1513028144836426\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 781, Training loss = 1.1507909297943115\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 782, Training loss = 1.1517770290374756\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 783, Training loss = 1.1537132263183594\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 784, Training loss = 1.1502562761306763\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 785, Training loss = 1.1487295627593994\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 786, Training loss = 1.1513941287994385\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 787, Training loss = 1.1481130123138428\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 788, Training loss = 1.150361180305481\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 789, Training loss = 1.1495294570922852\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 790, Training loss = 1.1474905014038086\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 791, Training loss = 1.148019790649414\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 792, Training loss = 1.1443049907684326\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 793, Training loss = 1.143749475479126\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 794, Training loss = 1.1448888778686523\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 795, Training loss = 1.138932228088379\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 796, Training loss = 1.1453819274902344\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 797, Training loss = 1.143917202949524\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 798, Training loss = 1.1404176950454712\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 799, Training loss = 1.1385314464569092\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 800, Training loss = 1.1391937732696533\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 801, Training loss = 1.1414813995361328\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 802, Training loss = 1.1398015022277832\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 803, Training loss = 1.1368284225463867\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 804, Training loss = 1.1391050815582275\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 805, Training loss = 1.1371017694473267\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 806, Training loss = 1.1380538940429688\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 807, Training loss = 1.1345000267028809\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 808, Training loss = 1.1300280094146729\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 809, Training loss = 1.1294975280761719\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 810, Training loss = 1.1340556144714355\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 811, Training loss = 1.1336920261383057\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 812, Training loss = 1.1334798336029053\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 813, Training loss = 1.1316943168640137\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 814, Training loss = 1.1271631717681885\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 815, Training loss = 1.1313344240188599\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 816, Training loss = 1.131314754486084\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 817, Training loss = 1.1281042098999023\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 818, Training loss = 1.1293660402297974\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 819, Training loss = 1.128536581993103\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 820, Training loss = 1.123727560043335\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 821, Training loss = 1.1250170469284058\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 822, Training loss = 1.128489375114441\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 823, Training loss = 1.1236364841461182\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 824, Training loss = 1.1260885000228882\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 825, Training loss = 1.1229469776153564\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 826, Training loss = 1.1251721382141113\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 827, Training loss = 1.1246156692504883\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 828, Training loss = 1.1203765869140625\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 829, Training loss = 1.1239577531814575\n",
            "Test Accuracy: 73.33\n",
            "Epoch: 830, Training loss = 1.1179087162017822\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 831, Training loss = 1.1232035160064697\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 832, Training loss = 1.1231849193572998\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 833, Training loss = 1.1161794662475586\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 834, Training loss = 1.1193166971206665\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 835, Training loss = 1.1196067333221436\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 836, Training loss = 1.117370367050171\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 837, Training loss = 1.1182512044906616\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 838, Training loss = 1.1184070110321045\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 839, Training loss = 1.1188712120056152\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 840, Training loss = 1.1134796142578125\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 841, Training loss = 1.114361047744751\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 842, Training loss = 1.1179752349853516\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 843, Training loss = 1.1109765768051147\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 844, Training loss = 1.112912893295288\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 845, Training loss = 1.1160283088684082\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 846, Training loss = 1.1139068603515625\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 847, Training loss = 1.1111819744110107\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 848, Training loss = 1.1096367835998535\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 849, Training loss = 1.1093485355377197\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 850, Training loss = 1.1103088855743408\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 851, Training loss = 1.1099793910980225\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 852, Training loss = 1.110154151916504\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 853, Training loss = 1.110073447227478\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 854, Training loss = 1.1067159175872803\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 855, Training loss = 1.1038975715637207\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 856, Training loss = 1.1067700386047363\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 857, Training loss = 1.106642484664917\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 858, Training loss = 1.1110728979110718\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 859, Training loss = 1.1069974899291992\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 860, Training loss = 1.1013691425323486\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 861, Training loss = 1.1036229133605957\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 862, Training loss = 1.0988757610321045\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 863, Training loss = 1.0996747016906738\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 864, Training loss = 1.0995981693267822\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 865, Training loss = 1.1021007299423218\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 866, Training loss = 1.1000899076461792\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 867, Training loss = 1.0952105522155762\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 868, Training loss = 1.0973844528198242\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 869, Training loss = 1.0948586463928223\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 870, Training loss = 1.098501443862915\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 871, Training loss = 1.0987894535064697\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 872, Training loss = 1.0962949991226196\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 873, Training loss = 1.0954294204711914\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 874, Training loss = 1.092995047569275\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 875, Training loss = 1.0957677364349365\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 876, Training loss = 1.0896347761154175\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 877, Training loss = 1.0892627239227295\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 878, Training loss = 1.0892246961593628\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 879, Training loss = 1.090286135673523\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 880, Training loss = 1.0922768115997314\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 881, Training loss = 1.0921878814697266\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 882, Training loss = 1.0915039777755737\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 883, Training loss = 1.0903983116149902\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 884, Training loss = 1.083355188369751\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 885, Training loss = 1.0861996412277222\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 886, Training loss = 1.0868213176727295\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 887, Training loss = 1.0804164409637451\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 888, Training loss = 1.0838916301727295\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 889, Training loss = 1.0822210311889648\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 890, Training loss = 1.082165002822876\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 891, Training loss = 1.0809061527252197\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 892, Training loss = 1.0804784297943115\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 893, Training loss = 1.0791382789611816\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 894, Training loss = 1.078368902206421\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 895, Training loss = 1.0818579196929932\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 896, Training loss = 1.0819447040557861\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 897, Training loss = 1.0866618156433105\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 898, Training loss = 1.0809398889541626\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 899, Training loss = 1.0780665874481201\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 900, Training loss = 1.0780282020568848\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 901, Training loss = 1.0765728950500488\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 902, Training loss = 1.0777175426483154\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 903, Training loss = 1.0708658695220947\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 904, Training loss = 1.0741615295410156\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 905, Training loss = 1.0720628499984741\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 906, Training loss = 1.075303316116333\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 907, Training loss = 1.074376106262207\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 908, Training loss = 1.0729732513427734\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 909, Training loss = 1.0701165199279785\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 910, Training loss = 1.065629005432129\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 911, Training loss = 1.0687191486358643\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 912, Training loss = 1.0692155361175537\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 913, Training loss = 1.0691862106323242\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 914, Training loss = 1.0716378688812256\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 915, Training loss = 1.0655293464660645\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 916, Training loss = 1.0643279552459717\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 917, Training loss = 1.0630924701690674\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 918, Training loss = 1.0641920566558838\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 919, Training loss = 1.064092993736267\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 920, Training loss = 1.0612621307373047\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 921, Training loss = 1.064858078956604\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 922, Training loss = 1.0573716163635254\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 923, Training loss = 1.0634061098098755\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 924, Training loss = 1.0610800981521606\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 925, Training loss = 1.0579135417938232\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 926, Training loss = 1.0567196607589722\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 927, Training loss = 1.058976411819458\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 928, Training loss = 1.0583200454711914\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 929, Training loss = 1.0595290660858154\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 930, Training loss = 1.0602179765701294\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 931, Training loss = 1.0580154657363892\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 932, Training loss = 1.0537035465240479\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 933, Training loss = 1.056204080581665\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 934, Training loss = 1.0575788021087646\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 935, Training loss = 1.0521111488342285\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 936, Training loss = 1.0579596757888794\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 937, Training loss = 1.0540196895599365\n",
            "Test Accuracy: 76.67\n",
            "Epoch: 938, Training loss = 1.0515620708465576\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 939, Training loss = 1.0514886379241943\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 940, Training loss = 1.0529417991638184\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 941, Training loss = 1.047111988067627\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 942, Training loss = 1.052863359451294\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 943, Training loss = 1.0523861646652222\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 944, Training loss = 1.0472768545150757\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 945, Training loss = 1.0458571910858154\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 946, Training loss = 1.04775869846344\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 947, Training loss = 1.0424139499664307\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 948, Training loss = 1.0490424633026123\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 949, Training loss = 1.0518678426742554\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 950, Training loss = 1.0431208610534668\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 951, Training loss = 1.0400662422180176\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 952, Training loss = 1.044027328491211\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 953, Training loss = 1.0353437662124634\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 954, Training loss = 1.0404796600341797\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 955, Training loss = 1.0424063205718994\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 956, Training loss = 1.0395169258117676\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 957, Training loss = 1.0428640842437744\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 958, Training loss = 1.0391812324523926\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 959, Training loss = 1.037061333656311\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 960, Training loss = 1.036360502243042\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 961, Training loss = 1.0334399938583374\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 962, Training loss = 1.033956527709961\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 963, Training loss = 1.0310289859771729\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 964, Training loss = 1.0343762636184692\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 965, Training loss = 1.0348035097122192\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 966, Training loss = 1.035468339920044\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 967, Training loss = 1.0303643941879272\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 968, Training loss = 1.031467080116272\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 969, Training loss = 1.0307673215866089\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 970, Training loss = 1.028290033340454\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 971, Training loss = 1.0287871360778809\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 972, Training loss = 1.0273845195770264\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 973, Training loss = 1.0266315937042236\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 974, Training loss = 1.0262811183929443\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 975, Training loss = 1.0366196632385254\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 976, Training loss = 1.0261714458465576\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 977, Training loss = 1.0292195081710815\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 978, Training loss = 1.0171682834625244\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 979, Training loss = 1.025119423866272\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 980, Training loss = 1.0212476253509521\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 981, Training loss = 1.0223982334136963\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 982, Training loss = 1.0165910720825195\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 983, Training loss = 1.021218180656433\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 984, Training loss = 1.0221998691558838\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 985, Training loss = 1.019943356513977\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 986, Training loss = 1.02186119556427\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 987, Training loss = 1.0166492462158203\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 988, Training loss = 1.013220191001892\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 989, Training loss = 1.016723871231079\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 990, Training loss = 1.0155879259109497\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 991, Training loss = 1.0124198198318481\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 992, Training loss = 1.0121885538101196\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 993, Training loss = 1.0139744281768799\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 994, Training loss = 1.008508563041687\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 995, Training loss = 1.0146790742874146\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 996, Training loss = 1.012709379196167\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 997, Training loss = 1.0074138641357422\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 998, Training loss = 1.0111565589904785\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 999, Training loss = 1.0042778253555298\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1000, Training loss = 1.0132288932800293\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1001, Training loss = 1.0076359510421753\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1002, Training loss = 1.003784418106079\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1003, Training loss = 1.0103923082351685\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1004, Training loss = 1.0047307014465332\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1005, Training loss = 0.9996025562286377\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1006, Training loss = 0.9997224807739258\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1007, Training loss = 1.002665638923645\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1008, Training loss = 0.99756920337677\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1009, Training loss = 1.0062273740768433\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1010, Training loss = 0.9988329410552979\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1011, Training loss = 0.9979756474494934\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1012, Training loss = 0.9963003396987915\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1013, Training loss = 0.9967316389083862\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1014, Training loss = 0.9952835440635681\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1015, Training loss = 0.9932402968406677\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1016, Training loss = 0.9931204319000244\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1017, Training loss = 0.9890285730361938\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1018, Training loss = 0.9957584142684937\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1019, Training loss = 0.9957728385925293\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1020, Training loss = 0.9909298419952393\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1021, Training loss = 0.9943950176239014\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1022, Training loss = 0.990155816078186\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1023, Training loss = 0.991657018661499\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1024, Training loss = 0.9823944568634033\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1025, Training loss = 0.9857422113418579\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1026, Training loss = 0.9889507293701172\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1027, Training loss = 0.9878331422805786\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1028, Training loss = 0.9822851419448853\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1029, Training loss = 0.9840792417526245\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1030, Training loss = 0.9768413305282593\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1031, Training loss = 0.9767720699310303\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1032, Training loss = 0.9811557531356812\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1033, Training loss = 0.9805311560630798\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1034, Training loss = 0.9777692556381226\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1035, Training loss = 0.9821332097053528\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1036, Training loss = 0.9804062843322754\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1037, Training loss = 0.9761600494384766\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1038, Training loss = 0.974899172782898\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1039, Training loss = 0.9788414239883423\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1040, Training loss = 0.9732367992401123\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1041, Training loss = 0.9706436991691589\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1042, Training loss = 0.9696044921875\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1043, Training loss = 0.9696846008300781\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1044, Training loss = 0.968354344367981\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1045, Training loss = 0.9640450477600098\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1046, Training loss = 0.9643057584762573\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1047, Training loss = 0.9684723019599915\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1048, Training loss = 0.964317798614502\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1049, Training loss = 0.9614166021347046\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1050, Training loss = 0.9612842798233032\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1051, Training loss = 0.9637362957000732\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1052, Training loss = 0.961558997631073\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1053, Training loss = 0.9581114053726196\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1054, Training loss = 0.9561147093772888\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1055, Training loss = 0.9541324377059937\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1056, Training loss = 0.9540048241615295\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1057, Training loss = 0.9547817707061768\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1058, Training loss = 0.9477355480194092\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1059, Training loss = 0.9525673389434814\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1060, Training loss = 0.9503961205482483\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1061, Training loss = 0.9535700082778931\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1062, Training loss = 0.9473632574081421\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1063, Training loss = 0.9486937522888184\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1064, Training loss = 0.9443478584289551\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1065, Training loss = 0.9466235637664795\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1066, Training loss = 0.944328248500824\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1067, Training loss = 0.9407230615615845\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1068, Training loss = 0.9372045397758484\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1069, Training loss = 0.9359833002090454\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1070, Training loss = 0.9425870776176453\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1071, Training loss = 0.9376859664916992\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1072, Training loss = 0.9347517490386963\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1073, Training loss = 0.9326164722442627\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1074, Training loss = 0.938700795173645\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1075, Training loss = 0.9346983432769775\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1076, Training loss = 0.9329371452331543\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1077, Training loss = 0.9310824275016785\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1078, Training loss = 0.9284207224845886\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1079, Training loss = 0.9251788854598999\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1080, Training loss = 0.9267070293426514\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1081, Training loss = 0.9255819320678711\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1082, Training loss = 0.9219669103622437\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1083, Training loss = 0.9238210320472717\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1084, Training loss = 0.9217733144760132\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1085, Training loss = 0.918687105178833\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1086, Training loss = 0.9159603118896484\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1087, Training loss = 0.9157811403274536\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1088, Training loss = 0.9172606468200684\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1089, Training loss = 0.9179383516311646\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1090, Training loss = 0.9117937088012695\n",
            "Test Accuracy: 80.0\n",
            "Epoch: 1091, Training loss = 0.912993848323822\n",
            "Test Accuracy: 83.33\n",
            "Epoch: 1092, Training loss = 0.9110168218612671\n",
            "Test Accuracy: 83.33\n",
            "Epoch: 1093, Training loss = 0.9068471193313599\n",
            "Test Accuracy: 83.33\n",
            "Epoch: 1094, Training loss = 0.9055285453796387\n",
            "Test Accuracy: 83.33\n",
            "Epoch: 1095, Training loss = 0.9039407968521118\n",
            "Test Accuracy: 83.33\n",
            "Epoch: 1096, Training loss = 0.9050835371017456\n",
            "Test Accuracy: 83.33\n",
            "Epoch: 1097, Training loss = 0.9045331478118896\n",
            "Test Accuracy: 83.33\n",
            "Epoch: 1098, Training loss = 0.8999263048171997\n",
            "Test Accuracy: 83.33\n",
            "Epoch: 1099, Training loss = 0.9032865762710571\n",
            "Test Accuracy: 83.33\n",
            "Epoch: 1100, Training loss = 0.9088045358657837\n",
            "Test Accuracy: 83.33\n",
            "Epoch: 1101, Training loss = 0.9004909992218018\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1102, Training loss = 0.901768147945404\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1103, Training loss = 0.8976918458938599\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1104, Training loss = 0.8933120965957642\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1105, Training loss = 0.8969447612762451\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1106, Training loss = 0.8940013647079468\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1107, Training loss = 0.8966002464294434\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1108, Training loss = 0.8943386077880859\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1109, Training loss = 0.8865439295768738\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1110, Training loss = 0.8883839845657349\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1111, Training loss = 0.888084888458252\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1112, Training loss = 0.8910256624221802\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1113, Training loss = 0.890332818031311\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1114, Training loss = 0.8870824575424194\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1115, Training loss = 0.8830468058586121\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1116, Training loss = 0.8867381811141968\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1117, Training loss = 0.8781607747077942\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1118, Training loss = 0.8796536922454834\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1119, Training loss = 0.8831124305725098\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1120, Training loss = 0.8751602172851562\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1121, Training loss = 0.8794138431549072\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1122, Training loss = 0.881624698638916\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1123, Training loss = 0.8753990530967712\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1124, Training loss = 0.8771425485610962\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1125, Training loss = 0.8732300996780396\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1126, Training loss = 0.8775749206542969\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1127, Training loss = 0.8693684935569763\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1128, Training loss = 0.8695005774497986\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1129, Training loss = 0.8697279691696167\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1130, Training loss = 0.8637294173240662\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1131, Training loss = 0.8666658401489258\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1132, Training loss = 0.8661794662475586\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1133, Training loss = 0.8595420122146606\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1134, Training loss = 0.8623045086860657\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1135, Training loss = 0.8595417141914368\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1136, Training loss = 0.859483003616333\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1137, Training loss = 0.8527636528015137\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1138, Training loss = 0.8559197187423706\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1139, Training loss = 0.8557681441307068\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1140, Training loss = 0.8527944684028625\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1141, Training loss = 0.8495669364929199\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1142, Training loss = 0.8501572608947754\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1143, Training loss = 0.8486186265945435\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1144, Training loss = 0.847327709197998\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1145, Training loss = 0.8507512807846069\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1146, Training loss = 0.8429466485977173\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1147, Training loss = 0.8505899310112\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1148, Training loss = 0.8471119403839111\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1149, Training loss = 0.8428473472595215\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1150, Training loss = 0.8443260192871094\n",
            "Test Accuracy: 86.67\n",
            "Epoch: 1151, Training loss = 0.8423396348953247\n",
            "Test Accuracy: 90.0\n",
            "Epoch: 1152, Training loss = 0.839083194732666\n",
            "Test Accuracy: 90.0\n",
            "Epoch: 1153, Training loss = 0.8342178463935852\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1154, Training loss = 0.8364236950874329\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1155, Training loss = 0.8386576771736145\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1156, Training loss = 0.8338363170623779\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1157, Training loss = 0.8335552215576172\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1158, Training loss = 0.8296176195144653\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1159, Training loss = 0.826295018196106\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1160, Training loss = 0.825933575630188\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1161, Training loss = 0.828197717666626\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1162, Training loss = 0.8288344144821167\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1163, Training loss = 0.8228135704994202\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1164, Training loss = 0.8235058784484863\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1165, Training loss = 0.8210844397544861\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1166, Training loss = 0.8177543878555298\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1167, Training loss = 0.8211247324943542\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1168, Training loss = 0.8205581903457642\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1169, Training loss = 0.8125488758087158\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1170, Training loss = 0.8162797093391418\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1171, Training loss = 0.813925564289093\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1172, Training loss = 0.8161724805831909\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1173, Training loss = 0.8126978874206543\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1174, Training loss = 0.8116365075111389\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1175, Training loss = 0.8069734573364258\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1176, Training loss = 0.8103039264678955\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1177, Training loss = 0.807955265045166\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1178, Training loss = 0.802925705909729\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1179, Training loss = 0.8028841018676758\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1180, Training loss = 0.8057280778884888\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1181, Training loss = 0.800102949142456\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1182, Training loss = 0.7956427335739136\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1183, Training loss = 0.7982311248779297\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1184, Training loss = 0.793852686882019\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1185, Training loss = 0.7945363521575928\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1186, Training loss = 0.7919385433197021\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1187, Training loss = 0.7910462021827698\n",
            "Test Accuracy: 93.33\n",
            "Epoch: 1188, Training loss = 0.7910572290420532\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1189, Training loss = 0.7862217426300049\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1190, Training loss = 0.786781907081604\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1191, Training loss = 0.7821691632270813\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1192, Training loss = 0.7901709079742432\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1193, Training loss = 0.78067946434021\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1194, Training loss = 0.7845604419708252\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1195, Training loss = 0.7823879718780518\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1196, Training loss = 0.782372236251831\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1197, Training loss = 0.7778638005256653\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1198, Training loss = 0.7802746891975403\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1199, Training loss = 0.7764290571212769\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1200, Training loss = 0.7774670124053955\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1201, Training loss = 0.7724074125289917\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1202, Training loss = 0.7731101512908936\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1203, Training loss = 0.7696497440338135\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1204, Training loss = 0.7701259851455688\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1205, Training loss = 0.7679916024208069\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1206, Training loss = 0.770124077796936\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1207, Training loss = 0.7679124474525452\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1208, Training loss = 0.7560943365097046\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1209, Training loss = 0.763722836971283\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1210, Training loss = 0.7601128816604614\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1211, Training loss = 0.7600095868110657\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1212, Training loss = 0.7617686986923218\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1213, Training loss = 0.7590769529342651\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1214, Training loss = 0.7496073246002197\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1215, Training loss = 0.7507545948028564\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1216, Training loss = 0.752568244934082\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1217, Training loss = 0.7528929710388184\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1218, Training loss = 0.7487853169441223\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1219, Training loss = 0.7488117218017578\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1220, Training loss = 0.7445403337478638\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1221, Training loss = 0.7441563606262207\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1222, Training loss = 0.7425938844680786\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1223, Training loss = 0.7440242767333984\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1224, Training loss = 0.7430065870285034\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1225, Training loss = 0.7415353059768677\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1226, Training loss = 0.7360948324203491\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1227, Training loss = 0.7367398738861084\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1228, Training loss = 0.734068751335144\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1229, Training loss = 0.7347294688224792\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1230, Training loss = 0.7302733659744263\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1231, Training loss = 0.7292815446853638\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1232, Training loss = 0.7286039590835571\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1233, Training loss = 0.7323031425476074\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1234, Training loss = 0.7283451557159424\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1235, Training loss = 0.7253984212875366\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1236, Training loss = 0.7188486456871033\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1237, Training loss = 0.7298969626426697\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1238, Training loss = 0.7198190689086914\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1239, Training loss = 0.7152801752090454\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1240, Training loss = 0.7201672792434692\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1241, Training loss = 0.7184023857116699\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1242, Training loss = 0.712895393371582\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1243, Training loss = 0.7165985107421875\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1244, Training loss = 0.7128559350967407\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1245, Training loss = 0.7096366286277771\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1246, Training loss = 0.710544228553772\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1247, Training loss = 0.7081189155578613\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1248, Training loss = 0.7045103311538696\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1249, Training loss = 0.7033251523971558\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1250, Training loss = 0.7024704217910767\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1251, Training loss = 0.7049283981323242\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1252, Training loss = 0.699936032295227\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1253, Training loss = 0.702409565448761\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1254, Training loss = 0.6976436972618103\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1255, Training loss = 0.6964497566223145\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1256, Training loss = 0.6933327913284302\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1257, Training loss = 0.6926679611206055\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1258, Training loss = 0.6927251815795898\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1259, Training loss = 0.6835218667984009\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1260, Training loss = 0.6846228241920471\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1261, Training loss = 0.6842201352119446\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1262, Training loss = 0.6844732761383057\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1263, Training loss = 0.6829898357391357\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1264, Training loss = 0.6790728569030762\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1265, Training loss = 0.6852767467498779\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1266, Training loss = 0.6818670034408569\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1267, Training loss = 0.6791728734970093\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1268, Training loss = 0.6766643524169922\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1269, Training loss = 0.6739530563354492\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1270, Training loss = 0.6749235391616821\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1271, Training loss = 0.674020528793335\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1272, Training loss = 0.6703221201896667\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1273, Training loss = 0.6687799692153931\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1274, Training loss = 0.6724812984466553\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1275, Training loss = 0.6639082431793213\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1276, Training loss = 0.6620339155197144\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1277, Training loss = 0.664419412612915\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1278, Training loss = 0.6607562899589539\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1279, Training loss = 0.6583181619644165\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1280, Training loss = 0.659585177898407\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1281, Training loss = 0.6571835279464722\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1282, Training loss = 0.6533166170120239\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1283, Training loss = 0.6518908739089966\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1284, Training loss = 0.654204249382019\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1285, Training loss = 0.652576744556427\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1286, Training loss = 0.6509770750999451\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1287, Training loss = 0.6548671722412109\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1288, Training loss = 0.6504607200622559\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1289, Training loss = 0.6459202170372009\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1290, Training loss = 0.6429494023323059\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1291, Training loss = 0.6411459445953369\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1292, Training loss = 0.6410325765609741\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1293, Training loss = 0.6415073871612549\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1294, Training loss = 0.6404769420623779\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1295, Training loss = 0.6376147270202637\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1296, Training loss = 0.6332683563232422\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1297, Training loss = 0.6354827284812927\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1298, Training loss = 0.6336796879768372\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1299, Training loss = 0.630078911781311\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1300, Training loss = 0.6349647045135498\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1301, Training loss = 0.6286843419075012\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1302, Training loss = 0.6308902502059937\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1303, Training loss = 0.6321516036987305\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1304, Training loss = 0.6259317398071289\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1305, Training loss = 0.6240075826644897\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1306, Training loss = 0.6247289776802063\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1307, Training loss = 0.6216012239456177\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1308, Training loss = 0.6206011176109314\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1309, Training loss = 0.6189642548561096\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1310, Training loss = 0.6201130151748657\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1311, Training loss = 0.6178587675094604\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1312, Training loss = 0.6132806539535522\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1313, Training loss = 0.6102200746536255\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1314, Training loss = 0.6087815761566162\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1315, Training loss = 0.6118593215942383\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1316, Training loss = 0.6097331047058105\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1317, Training loss = 0.6109338998794556\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1318, Training loss = 0.6077631711959839\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1319, Training loss = 0.607367753982544\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1320, Training loss = 0.6045849323272705\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1321, Training loss = 0.6019644141197205\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1322, Training loss = 0.5999602675437927\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1323, Training loss = 0.5991822481155396\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1324, Training loss = 0.5958027839660645\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1325, Training loss = 0.5998339056968689\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1326, Training loss = 0.5928525924682617\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1327, Training loss = 0.5894285440444946\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1328, Training loss = 0.5890875458717346\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1329, Training loss = 0.5911953449249268\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1330, Training loss = 0.5894965529441833\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1331, Training loss = 0.5869017839431763\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1332, Training loss = 0.5896424055099487\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1333, Training loss = 0.5822091102600098\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1334, Training loss = 0.5894014835357666\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1335, Training loss = 0.5822882652282715\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1336, Training loss = 0.5848062038421631\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1337, Training loss = 0.5816038846969604\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1338, Training loss = 0.5798633694648743\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1339, Training loss = 0.5806793570518494\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1340, Training loss = 0.5742668509483337\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1341, Training loss = 0.5755501389503479\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1342, Training loss = 0.5746846199035645\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1343, Training loss = 0.5710784196853638\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1344, Training loss = 0.5737888216972351\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1345, Training loss = 0.5690176486968994\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1346, Training loss = 0.5682361721992493\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1347, Training loss = 0.5676131844520569\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1348, Training loss = 0.567252516746521\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1349, Training loss = 0.5652522444725037\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1350, Training loss = 0.5632361173629761\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1351, Training loss = 0.5615682601928711\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1352, Training loss = 0.5600427389144897\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1353, Training loss = 0.5557891726493835\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1354, Training loss = 0.5562411546707153\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1355, Training loss = 0.5579162836074829\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1356, Training loss = 0.5555902719497681\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1357, Training loss = 0.5556380748748779\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1358, Training loss = 0.5520018339157104\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1359, Training loss = 0.548042356967926\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1360, Training loss = 0.5489988327026367\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1361, Training loss = 0.5507797002792358\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1362, Training loss = 0.5481458902359009\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1363, Training loss = 0.546136736869812\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1364, Training loss = 0.5416620373725891\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1365, Training loss = 0.5433005094528198\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1366, Training loss = 0.5414204597473145\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1367, Training loss = 0.541549563407898\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1368, Training loss = 0.53944993019104\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1369, Training loss = 0.5402436256408691\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1370, Training loss = 0.5350278615951538\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1371, Training loss = 0.5383704304695129\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1372, Training loss = 0.5376394391059875\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1373, Training loss = 0.5378568172454834\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1374, Training loss = 0.5348958373069763\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1375, Training loss = 0.5320049524307251\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1376, Training loss = 0.5324188470840454\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1377, Training loss = 0.5263556838035583\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1378, Training loss = 0.5291129350662231\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1379, Training loss = 0.526444673538208\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1380, Training loss = 0.526452898979187\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1381, Training loss = 0.5271785259246826\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1382, Training loss = 0.5199877619743347\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1383, Training loss = 0.5219742059707642\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1384, Training loss = 0.5188839435577393\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1385, Training loss = 0.5192026495933533\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1386, Training loss = 0.5204008221626282\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1387, Training loss = 0.5194447040557861\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1388, Training loss = 0.5142661333084106\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1389, Training loss = 0.5142727494239807\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1390, Training loss = 0.5106511116027832\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1391, Training loss = 0.5149165987968445\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1392, Training loss = 0.509727418422699\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1393, Training loss = 0.5125594735145569\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1394, Training loss = 0.5069200992584229\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1395, Training loss = 0.5096408128738403\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1396, Training loss = 0.506913959980011\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1397, Training loss = 0.5039082765579224\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1398, Training loss = 0.5065447092056274\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1399, Training loss = 0.5006116628646851\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1400, Training loss = 0.5005500912666321\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1401, Training loss = 0.5006449818611145\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1402, Training loss = 0.5012869834899902\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1403, Training loss = 0.5011842846870422\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1404, Training loss = 0.5005700588226318\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1405, Training loss = 0.49576669931411743\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1406, Training loss = 0.4934145212173462\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1407, Training loss = 0.4903338551521301\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1408, Training loss = 0.49498191475868225\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1409, Training loss = 0.48829185962677\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1410, Training loss = 0.49258869886398315\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1411, Training loss = 0.48891180753707886\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1412, Training loss = 0.4904961884021759\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1413, Training loss = 0.48683643341064453\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1414, Training loss = 0.48344093561172485\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1415, Training loss = 0.4847087860107422\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1416, Training loss = 0.4839271903038025\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1417, Training loss = 0.48244112730026245\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1418, Training loss = 0.4853234589099884\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1419, Training loss = 0.47781306505203247\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1420, Training loss = 0.48416852951049805\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1421, Training loss = 0.4744473695755005\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1422, Training loss = 0.4797680974006653\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1423, Training loss = 0.47763609886169434\n",
            "Test Accuracy: 96.67\n",
            "Epoch: 1424, Training loss = 0.47700637578964233\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1425, Training loss = 0.4754274785518646\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1426, Training loss = 0.47740042209625244\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1427, Training loss = 0.47036319971084595\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1428, Training loss = 0.4732399582862854\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1429, Training loss = 0.4680778980255127\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1430, Training loss = 0.46720588207244873\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1431, Training loss = 0.4652630090713501\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1432, Training loss = 0.47328153252601624\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1433, Training loss = 0.46599671244621277\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1434, Training loss = 0.4622267782688141\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1435, Training loss = 0.4612961411476135\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1436, Training loss = 0.46627798676490784\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1437, Training loss = 0.46143838763237\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1438, Training loss = 0.46098604798316956\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1439, Training loss = 0.4634963274002075\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1440, Training loss = 0.45606908202171326\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1441, Training loss = 0.45854002237319946\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1442, Training loss = 0.4591781497001648\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1443, Training loss = 0.45941269397735596\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1444, Training loss = 0.45317527651786804\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1445, Training loss = 0.45163097977638245\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1446, Training loss = 0.45018213987350464\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1447, Training loss = 0.4531962275505066\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1448, Training loss = 0.44884830713272095\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1449, Training loss = 0.45208752155303955\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1450, Training loss = 0.4516255259513855\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1451, Training loss = 0.44735878705978394\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1452, Training loss = 0.4500805735588074\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1453, Training loss = 0.4443204998970032\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1454, Training loss = 0.4432539939880371\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1455, Training loss = 0.44589173793792725\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1456, Training loss = 0.43981754779815674\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1457, Training loss = 0.4410174489021301\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1458, Training loss = 0.44021186232566833\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1459, Training loss = 0.4414401650428772\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1460, Training loss = 0.43856871128082275\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1461, Training loss = 0.43678051233291626\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1462, Training loss = 0.4348907470703125\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1463, Training loss = 0.4396066963672638\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1464, Training loss = 0.4403398334980011\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1465, Training loss = 0.43316715955734253\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1466, Training loss = 0.43461596965789795\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1467, Training loss = 0.4311120808124542\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1468, Training loss = 0.42928338050842285\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1469, Training loss = 0.4350239634513855\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1470, Training loss = 0.4294748306274414\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1471, Training loss = 0.4297460615634918\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1472, Training loss = 0.4255552291870117\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1473, Training loss = 0.4309336543083191\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1474, Training loss = 0.4282916188240051\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1475, Training loss = 0.4226018488407135\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1476, Training loss = 0.42626500129699707\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1477, Training loss = 0.42258942127227783\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1478, Training loss = 0.425234317779541\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1479, Training loss = 0.42039546370506287\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1480, Training loss = 0.4198421239852905\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1481, Training loss = 0.4207618236541748\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1482, Training loss = 0.41646116971969604\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1483, Training loss = 0.42068612575531006\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1484, Training loss = 0.41875705122947693\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1485, Training loss = 0.4168427586555481\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1486, Training loss = 0.41420847177505493\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1487, Training loss = 0.4131793975830078\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1488, Training loss = 0.4146101474761963\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1489, Training loss = 0.41398489475250244\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1490, Training loss = 0.41318434476852417\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1491, Training loss = 0.41509801149368286\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1492, Training loss = 0.4100331664085388\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1493, Training loss = 0.41406911611557007\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1494, Training loss = 0.40668752789497375\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1495, Training loss = 0.40687036514282227\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1496, Training loss = 0.410357803106308\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1497, Training loss = 0.4052588939666748\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1498, Training loss = 0.4079519510269165\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1499, Training loss = 0.4067338705062866\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1500, Training loss = 0.4061982035636902\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1501, Training loss = 0.4019581377506256\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1502, Training loss = 0.40426355600357056\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1503, Training loss = 0.4008888006210327\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1504, Training loss = 0.39897698163986206\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1505, Training loss = 0.40111100673675537\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1506, Training loss = 0.40126660466194153\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1507, Training loss = 0.3967263102531433\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1508, Training loss = 0.3990967273712158\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1509, Training loss = 0.3939144015312195\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1510, Training loss = 0.3983200192451477\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1511, Training loss = 0.3933032155036926\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1512, Training loss = 0.392249196767807\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1513, Training loss = 0.3952155113220215\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1514, Training loss = 0.39260196685791016\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1515, Training loss = 0.3954445719718933\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1516, Training loss = 0.3897553086280823\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1517, Training loss = 0.3915504813194275\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1518, Training loss = 0.39208829402923584\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1519, Training loss = 0.3897136151790619\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1520, Training loss = 0.38722896575927734\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1521, Training loss = 0.3910835385322571\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1522, Training loss = 0.3926635980606079\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1523, Training loss = 0.3906329572200775\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1524, Training loss = 0.3858599066734314\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1525, Training loss = 0.383664608001709\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1526, Training loss = 0.3828962743282318\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1527, Training loss = 0.3862360119819641\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1528, Training loss = 0.38508933782577515\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1529, Training loss = 0.3852314352989197\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1530, Training loss = 0.378059059381485\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1531, Training loss = 0.3808361291885376\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1532, Training loss = 0.37793397903442383\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1533, Training loss = 0.3825291395187378\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1534, Training loss = 0.3787956237792969\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1535, Training loss = 0.3811905086040497\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1536, Training loss = 0.3746430277824402\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1537, Training loss = 0.37532341480255127\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1538, Training loss = 0.37570369243621826\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1539, Training loss = 0.3771718144416809\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1540, Training loss = 0.37275248765945435\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1541, Training loss = 0.3711871802806854\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1542, Training loss = 0.377330482006073\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1543, Training loss = 0.3735993802547455\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1544, Training loss = 0.37251919507980347\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1545, Training loss = 0.3693133592605591\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1546, Training loss = 0.3725702166557312\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1547, Training loss = 0.37026190757751465\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1548, Training loss = 0.366793155670166\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1549, Training loss = 0.37047910690307617\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1550, Training loss = 0.36908844113349915\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1551, Training loss = 0.3710477352142334\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1552, Training loss = 0.3658934235572815\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1553, Training loss = 0.3673684298992157\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1554, Training loss = 0.364469051361084\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1555, Training loss = 0.3617951273918152\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1556, Training loss = 0.3616999387741089\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1557, Training loss = 0.3633735179901123\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1558, Training loss = 0.3620879054069519\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1559, Training loss = 0.35799646377563477\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1560, Training loss = 0.36086174845695496\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1561, Training loss = 0.361397922039032\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1562, Training loss = 0.3576290011405945\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1563, Training loss = 0.3591875433921814\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1564, Training loss = 0.3592669367790222\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1565, Training loss = 0.3602122962474823\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1566, Training loss = 0.361613929271698\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1567, Training loss = 0.3588668704032898\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1568, Training loss = 0.3580765724182129\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1569, Training loss = 0.3552960753440857\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1570, Training loss = 0.3557567596435547\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1571, Training loss = 0.35451775789260864\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1572, Training loss = 0.35762739181518555\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1573, Training loss = 0.35265669226646423\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1574, Training loss = 0.3544906675815582\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1575, Training loss = 0.34708261489868164\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1576, Training loss = 0.35096901655197144\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1577, Training loss = 0.35341233015060425\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1578, Training loss = 0.3478403091430664\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1579, Training loss = 0.3517909348011017\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1580, Training loss = 0.3506224751472473\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1581, Training loss = 0.34815865755081177\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1582, Training loss = 0.34874802827835083\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1583, Training loss = 0.34519973397254944\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1584, Training loss = 0.3478795886039734\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1585, Training loss = 0.3440992534160614\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1586, Training loss = 0.34866863489151\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1587, Training loss = 0.34247374534606934\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1588, Training loss = 0.34251606464385986\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1589, Training loss = 0.3401234745979309\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1590, Training loss = 0.3410150110721588\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1591, Training loss = 0.34698107838630676\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1592, Training loss = 0.3438715934753418\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1593, Training loss = 0.34022897481918335\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1594, Training loss = 0.3415399193763733\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1595, Training loss = 0.3364730179309845\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1596, Training loss = 0.3398975133895874\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1597, Training loss = 0.34225478768348694\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1598, Training loss = 0.3359578549861908\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1599, Training loss = 0.34018492698669434\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1600, Training loss = 0.33364593982696533\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1601, Training loss = 0.3346104323863983\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1602, Training loss = 0.33454108238220215\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1603, Training loss = 0.3317071199417114\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1604, Training loss = 0.33932408690452576\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1605, Training loss = 0.3345876932144165\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1606, Training loss = 0.33675140142440796\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1607, Training loss = 0.3300841450691223\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1608, Training loss = 0.33059900999069214\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1609, Training loss = 0.33244508504867554\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1610, Training loss = 0.3355863690376282\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1611, Training loss = 0.3281012177467346\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1612, Training loss = 0.330552339553833\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1613, Training loss = 0.333541601896286\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1614, Training loss = 0.33263224363327026\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1615, Training loss = 0.32780367136001587\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1616, Training loss = 0.32957300543785095\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1617, Training loss = 0.3280249834060669\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1618, Training loss = 0.3259041905403137\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1619, Training loss = 0.3291184902191162\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1620, Training loss = 0.32541728019714355\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1621, Training loss = 0.326222687959671\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1622, Training loss = 0.3239257335662842\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1623, Training loss = 0.3266972303390503\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1624, Training loss = 0.3276178538799286\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1625, Training loss = 0.3235015273094177\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1626, Training loss = 0.32137322425842285\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1627, Training loss = 0.324786901473999\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1628, Training loss = 0.32176122069358826\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1629, Training loss = 0.32066720724105835\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1630, Training loss = 0.32437998056411743\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1631, Training loss = 0.3241269588470459\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1632, Training loss = 0.3235298693180084\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1633, Training loss = 0.32121264934539795\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1634, Training loss = 0.32069844007492065\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1635, Training loss = 0.32200053334236145\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1636, Training loss = 0.3209351897239685\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1637, Training loss = 0.31480473279953003\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1638, Training loss = 0.3167768716812134\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1639, Training loss = 0.3173888623714447\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1640, Training loss = 0.3170129656791687\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1641, Training loss = 0.3187212347984314\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1642, Training loss = 0.3161681592464447\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1643, Training loss = 0.3204967975616455\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1644, Training loss = 0.3166072368621826\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1645, Training loss = 0.3175280690193176\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1646, Training loss = 0.31543922424316406\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1647, Training loss = 0.31417256593704224\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1648, Training loss = 0.3159962594509125\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1649, Training loss = 0.31337636709213257\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1650, Training loss = 0.3116878271102905\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1651, Training loss = 0.3099239766597748\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1652, Training loss = 0.30565333366394043\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1653, Training loss = 0.30683308839797974\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1654, Training loss = 0.31008419394493103\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1655, Training loss = 0.3099290132522583\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1656, Training loss = 0.3091352880001068\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1657, Training loss = 0.3076092600822449\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1658, Training loss = 0.30782032012939453\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1659, Training loss = 0.3048344552516937\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1660, Training loss = 0.3059094548225403\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1661, Training loss = 0.3103710412979126\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1662, Training loss = 0.3033295273780823\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1663, Training loss = 0.30536895990371704\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1664, Training loss = 0.30654263496398926\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1665, Training loss = 0.30281543731689453\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1666, Training loss = 0.3018472194671631\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1667, Training loss = 0.3039952516555786\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1668, Training loss = 0.30566203594207764\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1669, Training loss = 0.30525657534599304\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1670, Training loss = 0.30660611391067505\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1671, Training loss = 0.3069199025630951\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1672, Training loss = 0.299593985080719\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1673, Training loss = 0.30105364322662354\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1674, Training loss = 0.2984171211719513\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1675, Training loss = 0.3016398847103119\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1676, Training loss = 0.30247095227241516\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1677, Training loss = 0.30069249868392944\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1678, Training loss = 0.3034438490867615\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1679, Training loss = 0.30210280418395996\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1680, Training loss = 0.29842063784599304\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1681, Training loss = 0.29617518186569214\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1682, Training loss = 0.29840004444122314\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1683, Training loss = 0.29471731185913086\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1684, Training loss = 0.2965584397315979\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1685, Training loss = 0.299088716506958\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1686, Training loss = 0.29782634973526\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1687, Training loss = 0.2977880835533142\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1688, Training loss = 0.2948629856109619\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1689, Training loss = 0.291678786277771\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1690, Training loss = 0.29886990785598755\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1691, Training loss = 0.2920911908149719\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1692, Training loss = 0.29483550786972046\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1693, Training loss = 0.29240769147872925\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1694, Training loss = 0.29370319843292236\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1695, Training loss = 0.295784592628479\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1696, Training loss = 0.29055243730545044\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1697, Training loss = 0.29151833057403564\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1698, Training loss = 0.2927709221839905\n",
            "Test Accuracy: 100.0\n",
            "Epoch: 1699, Training loss = 0.2902933657169342\n",
            "Test Accuracy: 100.0\n"
          ]
        }
      ]
    }
  ]
}